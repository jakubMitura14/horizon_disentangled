1) ordinal clasifiers
##############################
Step 1: Incorporating the Ordinal Nature of Classes via Learning Paradigm
The core design challenge for inferring ordinal classes (e.g., cancer grades, PI-RADS scores) is that conventional categorical classification methods, which typically employ Cross-Entropy (CE) loss, fail to utilize the inherent ordering relationship (i.e., higher grade implies worse prognosis) \cite{LeeByeon2025,GrisiKartasalo2025}.
1.1 Differential Ordinal Learning Framework
A highly effective approach is to reformulate the grading task using a differential ordinal learning framework, as demonstrated by the DIOR-ViT model \cite{LeeByeon2025}.
1. Multi-Task Integration: The model should simultaneously perform two classification tasks \cite{LeeByeon2025}:
    ◦ Categorical Classification: Predicting the specific grade/class label ($y_i$) for a given input image ($x_i$).
    ◦ Differential Ordinal Classification: Predicting the degree of difference in class labels between a pair of samples ($x_m$ and $x_s$), thereby explicitly retaining the ordering relationship \cite{LeeByeon2025}.
2. Ordinal Loss Functions: To address the limitations of standard categorical loss, specialized loss functions that acknowledge class order must be employed \cite{GrisiKartasalo2025}.
    ◦ Regression Approach: Treating the prediction task as a regression problem using Mean Squared Error (MSE) loss has proven effective, yielding high macro-averaged quadratic weighted kappa scores in prostate cancer grading tasks \cite{GrisiKartasalo2025}.
    ◦ Differential Ordinal Loss ($\mathcal{L}_{diff}$): For the differential ordinal classification component, the Negative Absolute Difference Log-likelihood ($\mathcal{L}_{NAD}$) loss is proposed. This loss function is explicitly tailored to differential ordinal classification, penalizing incorrect predictions on a logarithmic scale and avoiding the non-smoothness and two-step complexity associated with conventional ordinal cross-entropy functions \cite{LeeByeon2025}.
    ◦ Hybrid Total Loss: The total loss ($\mathcal{L}{total}$) should combine the categorical classification loss ($\mathcal{L}{cat}$, e.g., standard Cross-Entropy) and the differential ordinal loss ($\mathcal{L}_{diff}$), balanced by a weight parameter ($\lambda$) \cite{LeeByeon2025}.
3. Alternative Ordinal Encoding: If pure ordinal classification is preferred over differential learning, the Ordinal Cross Entropy (Ordinal CE) approach (using sigmoid activation coupled with Binary Cross Entropy (BCE) loss) ensures that the loss decreases as the prediction moves closer to the correct ordinal class \cite{GrisiKartasalo2025}. Conventional CE loss generally yields inferior results compared to methods leveraging label order (Ordinal CE, MSE, or CORN) \cite{GrisiKartasalo2025}.

--------------------------------------------------------------------------------
Step 2: Designing Architectures for 3D Medical Imaging
Processing 3D medical images (like volumetric MRI or PET scans) is computationally challenging due to hardware memory limits \cite{XieGan2025,PuglisiAlexander2025}. Therefore, architectures must be optimized for efficiency while retaining critical 3D context.
2.1 Managing Computational and Memory Constraints
1. Latent Representations: Utilizing Latent Diffusion Models (LDMs) can reduce memory demands by processing a compressed latent space derived from the 3D scans, supporting widespread adoption even on consumer-grade hardware \cite{PuglisiAlexander2025}.
2. 2.5D Conditional Strategy: For tasks like SPECT reconstruction (which is analogous to handling 3D medical volume features), a 2.5D conditional strategy can be adopted. This involves conditioning the model on the entire 3D volume (e.g., CT image volume as anatomical prior) but training the model to predict individual 2D slices sequentially \cite{XieGan2025}. This approach allows the network to observe 3D information without incurring the massive memory burden of direct 3D convolutional layers \cite{XieGan2025}.
3. Efficient 3D CNNs: While Transformers and Mamba architectures are powerful, their high memory requirements may restrict input dimensions, limiting the ability to process volumetric information at the entire volume-level (which is necessary in tasks like radiotherapy segmentation) \cite{KimOh2025}. In such cases, adopting highly optimized 3D Convolutional Neural Networks (CNNs), such as a 3D Residual U-Net, may be preferred for balancing performance and memory efficiency for full-volume input processing \cite{KimOh2025}.
2.2 Leveraging Diffusion and Transformer Architectures
Modern generative models, including diffusion models and specialized Transformers, offer powerful features for handling 3D structure and detailed information.
1. Diffusion-Embedded Networks: If boundary or small structure delineation is critical (e.g., identifying tiny lesions or ambiguous tumor boundaries), integrating diffusion modeling capabilities within a traditional architecture can enhance robustness \cite{XingWan2025}. For 3D segmentation, the Diff-UNet employs two branches (denoising and boundary prediction) and incorporates a Multi-granularity Boundary Aggregation (MBA) module to fuse multi-level boundary features \cite{XingWan2025}. While focused on segmentation, the inclusion of uncertainty estimation (via Monte Carlo Diffusion) and boundary constraints can improve classification robustness by ensuring feature extraction focuses on anatomically plausible areas \cite{XingWan2025}.
2. Vision Transformers (ViT): The architecture of choice for ordinal classification (DIOR-ViT) is based on the Vision Transformer \cite{LeeByeon2025}. ViTs excel at mapping input samples into a high-dimensional feature space where ordering relationships can be retained \cite{LeeByeon2025}. ViT architectures, particularly those with localized self-attention mechanisms like Swin Transformer, are computationally efficient compared to standard ViTs, making them suitable for real-time processing \cite{MenZhao2025}.

--------------------------------------------------------------------------------
Step 3: Implementing Robust Data Augmentation Strategies
Data augmentation is essential for improving generalizability, mitigating domain shift (common in multi-center medical data), and addressing class imbalance, especially in the minority ordinal classes \cite{ZhouZhou2025,YeWang2025}.
3.1 Augmentation for Robustness and Generalization
1. Simulating Realistic Domain Shifts: Traditional geometric (rotation, flips, shifts) and intensity augmentations (contrast, brightness, noise) are standard practice \cite{UllahGuzmnAroca2025,ChinaMacLean2025}. Crucially, to enhance robustness against domain shifts caused by scanner differences (common in MRI/PET), Counterfactual Contrastive Learning can be used. This technique leverages causal image synthesis to create contrastive positive pairs that accurately mimic relevant domain variations, improving representation quality for downstream tasks \cite{RoschewitzRibeiro2025}.
2. Frequency Domain Perturbation: To efficiently increase sample diversity without corrupting anatomical structures, Frequency Domain Perturbation (amplitude-based augmentation) is recommended. This method allows diverse stylistic distributions (brightness, contrast) to be incorporated by manipulating the amplitude spectrum, while preserving the inherent semantics encoded in the phase spectrum \cite{LiuNi2025}.
3. Region-Specific Augmentation: For focusing learning on specific anatomical areas relevant to the grade (e.g., tumor boundaries), use specialized augmentation like the 3D random regional switch strategy to enhance supervision variability in critical volumetric regions \cite{ZhouZhou2025}.
3.2 Augmentation for Class Imbalance
Ordinal classes, particularly the rare, highly aggressive grades (e.g., TNM stage IV), suffer from scarcity.
1. Synthetic Data Generation: Utilize diffusion models to synthesize high-quality training instances for rare positive classes \cite{LinHolste2025,MiZhang2025}. Diffusion models are preferred over Generative Adversarial Networks (GANs) for medical image synthesis because they generally yield superior fidelity and structural realism, addressing concerns about generating non-existent or inconsistent content \cite{MiZhang2025}.
2. Post-Screening: Generated synthetic images should undergo a post-discrimination mechanism (or screening strategy) based on classification confidence and feature-space similarity. This step is necessary to filter out noisy or low-quality synthetic instances that could otherwise degrade model performance \cite{MiZhang2025}.

--------------------------------------------------------------------------------
Step 4: Leveraging and Fine-tuning Foundation Models
Foundation models (FMs) pre-trained on vast, diverse datasets offer significant generalization capabilities that can be transferred to specialized tasks like cancer grading \cite{MiZhang2025}.
1. Full Fine-Tuning over Parameter-Efficient Methods: When adapting FMs to highly specialized medical domains, such as radiation oncology or specific grading systems, a full fine-tuning approach is generally recommended. Parameter-efficient fine-tuning methods (e.g., LoRA) have shown significant performance drops in specialized medical contexts, proving insufficient for capturing domain knowledge \cite{KimOh2025}.
2. Foundation Models for Feature Extraction: Integrating FMs like UNI or CONCH (large-scale models for pathology/medical imaging) into the classification framework can enhance performance by leveraging their robust, hierarchical feature representations \cite{MiZhang2025}.
3. Pre-training Strategy Alignment: The selection of pre-trained weights should be validated against the specific learning task. While multi-stage pre-training (general domain followed by medical domain) is effective \cite{LinHolste2025}, research on differential ordinal learning suggests that ImageNet pre-trained weights might be more beneficial for this specific paradigm than pathology-specific pre-training, depending on the subsequent optimization strategy \cite{LeeByeon2025}.
4. Foundation Models as Generalist Guides: In low-resource settings, FMs (like SAM-Med3D for 3D segmentation) can function as generalist models within a collaborative learning framework (e.g., SemiSAM+) to generate reliable pseudo-labels for unlabeled data, thereby guiding the training of the specialized classification/segmentation model \cite{ZhangLv2025}. This is particularly useful when annotations are extremely limited \cite{ZhangLv2025}.

I. Foundational Importance of Data Preparation and Harmonization
Before model training, robust data preparation and harmonization are essential, particularly because AI models struggle with variability arising from multi-centric and multi-device studies \cite{SeoniShahini2024}. This variability often introduces inconsistency in image intensity, pixel spacing, hardware specifications, and environmental conditions \cite{SeoniShahini2024}.
1. Image Harmonization for Consistency: Harmonization techniques standardize appearance and characteristics across different sources, ensuring a fair and unbiased representation of the dataset \cite{SeoniShahini2024}. Given that MRI and PET/SPECT imaging often involve volumetric data, key harmonization steps include:
    ◦ Grayscale Normalization: This is paramount for modalities like MRI and PET/SPECT, where pixel/voxel intensity often relates to physical properties \cite{SeoniShahini2024}. Techniques such as z-score normalization (which improved classification accuracy substantially in MRI studies \cite{SeoniShahini2024}) and histogram normalization address differences in voxel intensities across scanners and protocols, enhancing comparability \cite{SeoniShahini2024}. Grayscale normalization is the most common technique for PET/SPECT imaging to standardize pixel-level intensities \cite{SeoniShahini2024}.
    ◦ Resampling: This process rectifies disparities in pixel spacing \cite{SeoniShahini2024}. It is a necessary pre-processing step for convolutional deep models operating on 2D or 3D images to harmonize spacing, although caution must be exercised as it can substantially affect underlying hidden patterns \cite{DimitriadisTrivizakis2022}. Resampling enhances segmentation performance by addressing spatial resolution inconsistencies \cite{SeoniShahini2024}.
    ◦ Contrast Enhancement and Bias Field Correction: Techniques like N4 bias field correction, often combined with normalization methods like WhiteStripe or z-score, significantly enhance the generalizability of predictions in modalities like MRI \cite{SeoniShahini2024}.
2. Data Augmentation to Enhance Robustness and Fairness:
    ◦ Traditional Augmentations: Standard augmentations are necessary to avoid overfitting and improve generalizability \cite{WangKuo2024,BehzadTabatabaei2024}. These include horizontal flipping, rotation (random rotation up to 10° or 15° mentioned for CXR and skin lesions, respectively) \cite{MehtaShui2023,YangZhang2023}, translation, resizing, and cropping \cite{KtenaWiles2023,SeoniShahini2024}.
    ◦ Generative AI for Diversity and Bias Mitigation: Advanced generative models—particularly Diffusion Models and Generative Adversarial Networks (GANs)—are highly effective for generating synthetic data, crucial for augmenting scarce datasets and addressing class imbalance in oncology and other medical fields \cite{YangLin2024,LiXu2024}.
        ▪ Steerable Generation: Conditional diffusion models can be trained on diagnostic labels and/or sensitive attribute labels (e.g., sex, age, race) to "steer" the distribution of synthetic examples, enriching the training dataset in a configurable and targeted manner \cite{KtenaWiles2023,KtenaWiles2024}. This approach improves robustness and increases fairness, especially for underrepresented groups or conditions \cite{KtenaWiles2024,KtenaWiles2023}.
        ▪ Synthetic data augmentation reduces spurious correlations (shortcut learning), allowing the diagnostic model to focus more capacity on disease-specific features rather than domain- or demographic-specific features \cite{KtenaWiles2023,KtenaWiles2024}.
II. Model Architectures and Handling Volumetric (3D) Data
For processing volumetric data inherent in MRI and PET/SPECT, architectural decisions must account for the 3D structure:
1. 3D Architectures: Directly applying 3D convolutional operations is recognized as superior for capturing global structure information, although it is often computationally more challenging than 2D methods \cite{BentoFantini2022}. Dedicated 3D CNNs are used for MRI classification tasks (e.g., AD classification) \cite{PetersenFeragen2022,LuoKhan2023}. Specialized architectures like the modified 3D-BU-Net are employed for multi-modal brain tumor segmentation, taking multi-modal MR images as input \cite{MehtaShui2023}.
2. 2D Approximations for Efficiency: Historically, due to computational limitations, 3D models were restricted to 2D realizations where series of image slices were processed, effectively increasing the perceived data size but losing volumetric information \cite{BentoFantini2022}. Modern implementations handle 3D data by applying 2D convolutional filters along axial, coronal, and sagittal axes separately to input voxels (e.g., modified ResNet9) \cite{ArastehZiller2024}.
3. Foundation Model Adaptation: If utilizing pre-trained Foundation Models (FMs), which are often 2D models (Vision Models or Vision-Language Models) \cite{JinXu2024}, adaptation methods are required for 3D data:
    ◦ 2.5D Loading/Processing: Volumes are pre-processed (e.g., resized along the longitudinal axis) and slices are processed independently through the 2D pipeline. The final volume-wise prediction is obtained by maximizing the predictions of all slices in the volume \cite{JinXu2024}.
III. Loss Functions for Ordinal and Fair Classification
Since TNM and PI-RADS represent ordinal classes (i.e., they have a meaningful rank order, not just distinct categories), the choice of loss function is critical to optimize for this ranking. While the sources do not name specific ordinal regression losses, they detail relevant approaches for maximizing performance in high-risk/ordinal scenarios and mitigating bias:
1. Marginal Ranking Loss (Proxy for Ordinality): This loss function is particularly useful for optimizing predictions that have incorrect ranking orders \cite{LinLi2023}. The goal of training using ranking loss is to directly optimize the model to focus on instances where the prediction ranking is incorrect, especially for groups with the lowest fairness performance, thereby encouraging fair learning and consistent improvement across all groups \cite{LinLi2023}.
2. Minimax Loss (Addressing Imbalance/Worst-Case Performance): The concept of minimax fairness (maximizing the performance of the worst-case group) is central to high-stakes medical tasks where underperformance in a specific high-risk subgroup (e.g., a specific TNM stage) could be devastating \cite{ZhangDullerud2022}.
    ◦ An AUC-based minimax loss function has demonstrated superiority in handling label imbalance and improving classification performance for the minority class, outperforming standard cross-entropy loss \cite{LiShi2023}.
3. Standard Classification Losses: For multi-class prediction, the most commonly used function is categorical cross-entropy loss \cite{MehtaShui2023,WangKuo2024}. When dealing with heavy class imbalance (often true for rare or advanced TNM stages), Weighted Cross-Entropy or Focal Loss are preferred \cite{MehtaShui2023,LinXiao2023}. Weighted cross-entropy adjusts weights to increase whenever there are fewer samples in a particular class \cite{MehtaShui2023,LinXiao2023}.
IV. Fine-Tuning and Foundation Models (FMs)
The paradigm of using large pre-trained FMs followed by fine-tuning is highly effective, especially when labeled medical datasets are small \cite{BentoFantini2022,DuttBohdal2023}.
1. Transfer Learning/Feature Extraction: FMs provide robust backbones for task-agnostic feature extraction \cite{AdamsonSmith2018,GlockerJones2023}. The pre-trained features serve as inputs for subsequent, data-efficient training of task-specific prediction models (classifiers) \cite{AdamsonSmith2018}.
2. Fine-Tuning Strategy:
    ◦ Parameter-Efficient Fine-Tuning (PEFT): Methods like FairTune optimize the choice of parameters to update within the fine-tuning process to constrain model updates, thereby yielding a high degree of fairness in validation data and mitigating the fairness generalization gap that arises when models overfit to training nuances \cite{DuttBohdal2023}.
    ◦ Bias Risk in Freezing: In a practical, low-data setting, it is often appealing to freeze the FM backbone features and train only simple prediction heads (e.g., linear layers or MLPs) \cite{AdamsonSmith2018,GlockerJones2023}. However, this approach is more likely to carry forward inherent biases encoded in the foundation model's features, leading to poorer performance and fairness gaps in protected subgroups compared to standard models \cite{AdamsonSmith2018,GlockerJones2023}.
    ◦ The Global Optimality Principle: Remarkably, research suggests that models with less encoding of demographic attributes in their representations are often the most "globally optimal," exhibiting better fairness when evaluated in new, external test settings \cite{YangZhang2023,YangZhang2024}. Therefore, mitigating demographic shortcuts during training is crucial for models intended for widespread clinical deployment beyond their original training context \cite{YangZhang2023,YangZhang2024}.
In conclusion, for designing high-performance and fair AI models for ordinal classification tasks like TNM or PI-RADS, you should prioritize robust image harmonization (especially grayscale normalization and resampling), leverage generative models (diffusion models) for steerable data augmentation to enhance subgroup representation, employ 3D architectures adapted for volumetric data, and utilize loss functions (such as marginal ranking loss or minimax loss) that prioritize both classification performance and fairness across high-risk or underrepresented ordinal groups \cite{LinLi2023}. Crucially, when employing FMs, be wary of strategies that preserve inherent biases, and aim for models that minimize the encoding of sensitive attributes \cite{YangZhang2023,YangZhang2024}. 
##############################

2)base regressors



Since MRI and PSMA PET/CT data are inherently volumetric (3D), the architecture must efficiently process spatial and contextual information.
1. Dedicated 3D Convolutional Neural Networks (CNNs):
    ◦ Directly using 3D CNNs (such as 3D ResNet-18 or 3D ResNet-34) is the recommended approach for capturing the global structure and spatial dependencies essential for 3D data \cite{ZongYang2022,MehtaShui2023}. These models explicitly capture volumetric context, which is lost when converting 3D data to 2D slices \cite{FerreiraLi2024}.
    ◦ For tasks like predicting clinical scores (a form of regression) from MRI, multi-task 3D ResNet-18 models have been implemented \cite{MehtaShui2023}.
2. Adapting Foundation Models (FMs) via 2.5D Loading:
    ◦ If leveraging large pre-trained 2D Vision Models (VMs) as backbones (which is common, as FMs are often 2D-based), a 2.5D loading approach must be used \cite{JinXu2024}.
    ◦ In this method, the volumetric data is pre-processed (e.g., resized along the longitudinal axis), and individual slices are passed independently through the 2D FM backbone \cite{JinXu2024}. The final regression output for the entire volume is then obtained by combining the predictions of all slices, often by maximizing or averaging the predictions \cite{JinXu2024}.
3. Feature Robustness: If the dataset size is small, a logistic regression model built upon manually selected volumetric features has been shown to be more robust to dataset composition shifts and may outperform a standard 3D CNN, highlighting the value of feature engineering informed by domain expertise \cite{PetersenFeragen2022}.
III. Loss Functions and Considering the Ordinal Nature
Age prediction is fundamentally a continuous regression task, but the output structure (e.g., age groups, or scores like PI-RADS/TNM) often benefits from methods acknowledging severity ranking.
A. Core Regression Loss
For age prediction as a continuous value, standard regression objectives are used:
• Mean Absolute Error (MAE or L1): Frequently employed in regression problems, helping to stabilize GAN training and often used over MSE in generative tasks \cite{FerreiraLi2024}. An MAE of 8 years was reported for age prediction from mammograms \cite{KilimOlar2022,WeberIngrisch2023}.
• Mean Squared Error (MSE or L2) / Root Mean Squared Error (RMSE): MSE is a common regression loss \cite{MehtaShui2023,FerreiraLi2024}, and RMSE is a standard evaluation metric for regression tasks like ADAS-13 and MMSE score prediction \cite{MehtaShui2023}.
B. Incorporating Fairness (In-Processing Debiasing)
Since sensitive attributes (like age, sex, or race) are often highly encoded in medical images and lead to performance disparities \cite{YangZhang2024,YangZhang2023}, integrating fairness constraints during optimization is essential:
1. Distributionally Robust Optimization (GroupDRO): This strategy focuses on maximizing the performance of the worst-off subgroup (e.g., the oldest age group, if they perform poorly). GroupDRO models are highly effective at mitigating unfairness gaps across demographics while maintaining strong overall performance \cite{YangZhang2023,MehtaShui2023}.
2. Adversarial Loss: An effective technique is embedding a fairness constraint in the loss function \cite{YangLin2024,XuLi2022}. This involves training an adversarial component (a discriminator) to predict the sensitive attribute (e.g., age bracket) from the primary model's latent features. The primary model is penalized (via a negative coefficient loss) for allowing the prediction of the sensitive attribute, forcing it to learn a representation that is invariant to that attribute ($Z \perp A$), thereby reducing bias \cite{XuLi2022,PetersenFerrante2023}.
C. Addressing Ordinal Classification (If age is binned)
If the task is simplified to predicting ordinal age categories (e.g., 60-70, 70-80), or genuine ordinal classes like PI-RADS or TNM:
• Cross-Entropy Variants: Categorical cross-entropy loss is used for multi-class problems \cite{MehtaShui2023}. If there is severe class imbalance (common in staging), specialized versions like Weighted Cross-Entropy or Focal Loss are recommended to improve performance on underrepresented classes \cite{LinXiao2023,AlbuquerqueMonteiro2019}.
IV. Augmentations and Fine-Tuning of Foundation Models
A. Data Augmentation to Mitigate Shortcut Learning
Data augmentation is a critical tool to expand diversity and combat the risk of shortcut learning, where models exploit spurious correlations \cite{WangKuo2024,BehzadTabatabaei2024}.
1. Traditional Augmentations: Include random rotation (e.g., between $-10^\circ$ and $10^\circ$ for brain MRI), horizontal flipping, translation, resizing, and cropping \cite{MehtaShui2023,WangKuo2024}.
2. Physics-Inspired Augmentations: For 3D volumetric data, deliberately introducing common artifacts that vary across scanners helps models learn stable features:
    ◦ Adding random Gaussian noise \cite{PiarraGlocker2023,PetersenFeragen2022}.
    ◦ Applying random elastic deformation, blurring, or adding simulated MRI bias field, spike, ghosting, or motion artifacts \cite{PetersenFeragen2022}.
3. Advanced Generative Augmentation: Generative AI, especially Denoising Diffusion Probabilistic Models (DDPMs) and Latent Diffusion Models (LDMs), offers superior capacity for generating diverse and steerable synthetic data \cite{KtenaWiles2023}.
    ◦ Conditional Synthesis: Models can be trained conditional on sensitive attributes (age, sex) to generate images targeted to enrich underrepresented subgroups (e.g., older age brackets or specific racial groups) \cite{PengBosschieter2023,AlbuquerqueMonteiro2019}.
    ◦ Synthetic data augmentation has been shown to significantly increase the accuracy of downstream age prediction tasks and reduce fairness gaps \cite{PengBosschieter2023,IbrahimKhalil2025}.
B. Fine-Tuning of Foundation Models (FMs)
Foundation models (FMs) provide robust feature extractors, often initialized by massive natural image datasets.
1. Transfer Learning: Use pre-trained models (e.g., ResNet-18 or ResNet-34 initialized with ImageNet or Kinetics pre-trained weights) as the backbone, and fine-tune them on the medical task \cite{ZongYang2022,YangZhang2023}. This is particularly useful given the computational cost and data scarcity of 3D medical data \cite{BentoFantini2022}.
2. Parameter-Efficient Fine-Tuning (PEFT): PEFT methods, such as LoRA or layer pruning, are highly efficient, requiring minimal computational overhead by only updating a small subset of parameters while freezing the backbone \cite{DuttBohdal2023}. PEFT is designed to prevent the model from overfitting to training nuances and can facilitate the optimization for validation fairness \cite{DuttBohdal2023}.
3. Caution regarding Bias: If adopting FMs, be aware that freezing the backbone might propagate demographic biases encoded during large-scale pre-training \cite{YangZhang2023}. Strategies that result in representations with less encoding of demographic attributes are generally found to be more "globally optimal," performing better and maintaining fairness when deployed in new, out-of-distribution environments \cite{WeberIngrisch2023,YangZhang2023}.


Step 1: Architectures and Handling 3D Volumetric Data
Processing full 3D medical scans presents a major challenge due to the computational complexity and significant memory demands associated with high-dimensional imaging data \cite{PuglisiAlexander2025}. Therefore, efficient architectural strategies must be implemented.
1.1 Leveraging Latent Representations
A highly effective method to mitigate memory demands and computational challenges is to operate in a compressed, low-dimensional latent space \cite{PuglisiAlexander2025}.
1. Variational Autoencoders (VAEs): VAEs are fundamental in learning a low-dimensional latent space from high-dimensional data, such as images or segmentations \cite{YuanStojanovski2025}. They can be adapted for regression tasks (predicting age/volume) directly from this latent space. For instance, the End-to-end Regression VAE (RVAE) approach specifically includes additional network layers in the latent space to perform volume estimation (analogous to age estimation) in an end-to-end training manner, optimizing for the potentially non-linear relationship between the latent embeddings and the target value \cite{YuanStojanovski2025}.
2. Latent Diffusion Models (LDMs): LDMs can reduce memory demands by processing a compressed latent space derived from 3D scans \cite{PuglisiAlexander2025}. This approach supports widespread adoption, even potentially on consumer-grade hardware \cite{PuglisiAlexander2025}. Models designed for longitudinal progression (like Brain Latent Progression, BrLP) utilize LDMs in combination with ControlNet to generate individualized 3D brain MRIs conditioned on subject metadata, which is highly relevant for age prediction/progression modeling \cite{PuglisiAlexander2025}.
1.2 Addressing 3D Memory Constraints via Conditional Strategies
If traditional 3D models (like 3D Diffusion or deep 3D CNNs) are used, memory constraints must be managed:
1. 2.5D Conditional Strategy: Directly training a full 3D diffusion model is impracticable due to hardware memory limits \cite{XieGan2025}. A robust strategy is the 2.5D conditional approach. This involves conditioning the network on the entire 3D volume (e.g., using CT volume as anatomical prior for SPECT reconstruction, or similar principles for MRI/PET) while training the model to predict individual 2D slices sequentially \cite{XieGan2025}. By embedding the entire 3D volume in the channel dimension of a primarily 2D model structure, the network observes 3D context without incurring the immense memory burden of full 3D convolutional layers \cite{XieGan2025}.
2. Optimized 3D Architectures: If full 3D context is necessary, selecting architectures optimized for efficiency is critical.
    ◦ While high-end transformer/Mamba architectures (like 3D SegMamba or 3D UNETR) demonstrate power, they significantly increase computational memory requirements, which may constrain the input image dimensions for volumetric processing \cite{KimOh2025}.
    ◦ For maximizing the 3D input dimensions under computational constraints, a robust 3D Residual U-Net might be preferred as a backbone architecture over more memory-intensive Transformers/Mamba networks for tasks requiring full volume processing \cite{KimOh2025}.
Step 2: Selecting Loss Functions for Continuous Regression
Since age inference is a continuous regression task, the loss function must be adapted away from categorical classification objectives (like Cross-Entropy or Ordinal Loss).
1. Mean Squared Error (MSE): The foundational loss function for regression is Mean Squared Error (MSE) \cite{RuizCrdenas2025}. In VAE-based frameworks specifically adapted for regression (RVAE), MSE loss is the component used to train the network to estimate the continuous target value (age, volume, etc.) \cite{YuanStojanovski2025}. MSE measures the residual in the intensity space \cite{HouZhu2025,ZhangJia2025} and is also used for evaluating reconstruction performance \cite{DuanTan2025,GaoChen2025}.
2. Incorporating Robustness (T-Loss/MAE): Medical image data often contains noise or outliers, which can affect MSE-based training \cite{GonzalezJimenezLionetti2025}.
    ◦ T-Loss: A highly robust option is the T-Loss, derived from the negative log-likelihood of the Student-t distribution \cite{GonzalezJimenezLionetti2025}. This loss dynamically controls its sensitivity through a single adaptive parameter, allowing it to adjust to varying levels of noise without requiring precise prior knowledge of outlier distribution \cite{GonzalezJimenezLionetti2025}. While primarily validated for segmentation, the underlying principle of robustness against outliers (like physiological outliers or label inaccuracies common in age data) is beneficial \cite{GonzalezJimenezLionetti2025}.
    ◦ Mean Absolute Error (MAE): MAE is theoretically robust to label noise \cite{GonzalezJimenezLionetti2025}. However, MAE has proven challenging in practice due to slow convergence caused by gradient saturation \cite{GonzalezJimenezLionetti2025}.
Step 3: Leveraging Pre-training and Foundation Models
Utilizing large-scale pre-training methods and foundation model concepts is crucial for generalizability and data efficiency in complex medical domains \cite{ZhangHager2025}.
3.1 Pre-training and Feature Representation
1. Foundation Model Architecture: Using architectures like the Vision Transformer (ViT), particularly those with hierarchical structures (e.g., Swin Transformer), is recommended as they excel at capturing long-range dependencies and multi-scale features, making them suitable backbones for feature extraction \cite{XingWan2025,PangMa2025}.
2. Anatomy-Aware Self-Supervised Learning (SSL): Pre-training the encoder on large, unannotated datasets using specialized SSL tasks enhances feature quality and generalizability \cite{PangMa2025}. For medical images, which are highly structured, SSL methods should focus on spatial and contextual relationships.
    ◦ POPAR (Patch Order Prediction and Appearance Recovery): This framework is designed to learn high-level anatomical structures and spatial relationships (via Patch Order Prediction) alongside fine-grained details (via Appearance Recovery), making the resultant representations highly proficient for anatomical tasks \cite{PangMa2025}.
3.2 Multimodal Context and Individualization
Since age estimation is a patient-specific task, conditioning the model on demographic information improves accuracy \cite{PuglisiAlexander2025}.
1. Covariate Integration in Generative Models: When using LDM/VAE approaches, subject-specific metadata (covariates, $s$) such as age, sex, and cognitive status should be explicitly integrated to condition the model's generation process or feature space \cite{PuglisiAlexander2025}. This helps individualize the predictions, rather than relying solely on population averages \cite{PuglisiAlexander2025}.
2. Contrastive Alignment (ViTa): For robust representation learning, image features (from MRI/PET/CT) can be aligned with tabular patient-level factors using a contrastive loss function (inspired by CLIP) \cite{ZhangHager2025}. This alignment pulls the image embeddings and tabular embeddings (e.g., containing detailed health or demographic factors related to the biological age) into a shared latent space, creating a comprehensive, information-enriched representation foundation that can be fine-tuned for the age prediction task \cite{ZhangHager2025}.
Step 4: Robustness through Augmentation and Domain Generalization
To ensure the model performs reliably across different acquisition protocols and scanners (a necessity when combining MRI, CT, or PET/PSMA data), augmentation strategies must target domain shift.
1. Simulating Domain Shift (Counterfactuals): To improve robustness against domain shifts stemming from varying scanner manufacturers or imaging protocols \cite{KumariChauhan2025}, Counterfactual Contrastive Learning (CF-SimCLR or CF-DINO) is recommended during pre-training \cite{RoschewitzRibeiro2025}. This technique generates contrastive positive pairs that mimic relevant domain variations, resulting in learned embeddings that are substantially less domain-separated (i.e., less dependent on scanner specifics) compared to standard contrastive methods \cite{RoschewitzRibeiro2025}.
2. Standard and Regional Augmentation: Standard data augmentation techniques (random flips, affine transformations, intensity transformations) should be applied \cite{SpinatAudelan2025}. For localized feature learning, region-specific augmentations (like the 3D random regional switch strategy) can be used to increase supervision variability in critical volumetric regions \cite{ZhouZhou2025}.
3. Synthesizing Longitudinal Data: If predicting a future age trajectory (a common application for age prediction models), generative models (like InBrainSyn) can synthesize individualized 3D spatiotemporal scans that simulate neurodegeneration, ensuring topological consistency through diffeomorphic transformations \cite{FuZheng2025}. Using such generative models for data augmentation can be an efficient strategy, especially when longitudinal data is scarce \cite{LiuSeguin2025,FuZheng2025}.

##############################

3) censored data - predict risk of progression 

Step 1: Data Preparation and Preprocessing
The primary goal is to standardize the 3D images and define the progression endpoint for survival analysis \cite{HolsteLin2024,GaoLi2019}.
1. Input Data Structuring: Organize the data at the patient level. For each patient/scan ($i$), record the 3D volume ($\mathbf{X}_i$), the time interval until the event or censoring ($T_i$), and the event indicator ($\delta_i$ or $e_i$), where $\delta_i = 1$ indicates progression (uncensored) and $\delta_i = 0$ indicates censoring (no progression observed within $T_i$) \cite{ZhuYao2016,ShahinZhao2023}. Given the requirement for a minimum 6-month observation time, this framework naturally supports discrete or right-censored survival analysis \cite{RivailVogl2023,ZhuYao2016}.
2. Isotropic Resampling and Registration: Resample all 3D volumes (MRI, PET PSMA) to a fixed isotropic resolution (e.g., $1 \times 1 \times 1 \text{ mm}^3$) using techniques like spline interpolation of order 3 \cite{GaoLi2019,NaserWahid2021}. This is crucial for consistent 3D CNN input. If multiple modalities (e.g., PET/MRI) are used, ensure they are co-registered \cite{NaserWahid2021}.
3. Intensity Normalization and Windowing: Convert raw data to standardized units (e.g., Hounsfield Units (HU) for CT, although MRI/PET have different scaling) \cite{GaoLi2019}. Apply clipping or windowing to focus on relevant tissue contrast, if applicable (e.g., CT volumes clipped to $[-1200, 600]$ HU for lung tissue \cite{GaoLi2019}, or $[-200, 200]$ HU for HNSCC soft tissue contrast in CT \cite{NaserWahid2021}). Normalize intensities, such as using z-score normalization for PET images \cite{NaserWahid2021} or normalization to a fixed range (e.g., $[-1, 1]$ or $ \cite{ZhuYao2016}$) \cite{GaoLi2019,NaserWahid2021}.
4. Region Definition (Optional but Recommended): Utilize image masks (e.g., tumour segmentation or organ mask) to focus analysis. This can be achieved through nodule detection/segmentation methods, potentially generating a two-channel input (image data and mask) \cite{GaoLi2019}.
5. Multi-Modal Input: If relevant clinical/demographic data (e.g., age, staging, treatment history) is available, it should be processed and concatenated with the image features or integrated as a separate input channel \cite{NaserWahid2021,SaeedRidzuan2024}.
Step 2: Data Augmentations
To improve generalization and robustness, especially given potentially small or heterogenous medical datasets \cite{NaserWahid2021,ChakravartyEmre2024}, standard 3D augmentations should be applied to the training data.
• Spatial Transformations: Include random translations \cite{ChakravartyEmre2024}, random cropping (e.g., to a fixed $144 \times 144 \times 144$ volume \cite{NaserWahid2021}), and random rotation (e.g., axial rotation range of 12 degrees or up to 15 degrees) \cite{ShahinZhao2023,NaserWahid2021}.
• Flip: Apply random horizontal flips (50\\\\% probability) \cite{NaserWahid2021} or flips across multiple axes (x, y, z) with a lower probability (e.g., 10\\\\%) \cite{SaeedRidzuan2024}.
• Intensity/Noise: Apply minor intensity transformations, contrast augmentation, or Gaussian noise \cite{ChakravartyEmre2024,RivailVogl2023}.
Step 3: Model Architecture
The architecture should be optimized for 3D volumetric data and structured for prediction over time (survival analysis).
Feature Extraction Backbone (3D CNN Encoder)
A 3D Convolutional Neural Network (CNN) is essential for extracting features from volumetric data \cite{FooHsu2022}.
• Choice: Use a proven deep 3D architecture like DenseNet121 \cite{NaserWahid2021} or 3D ResNet18 \cite{RivailVogl2023}. Pre-training on large non-medical datasets (like Kinetics-400 for 3D ResNet) can be beneficial \cite{RivailVogl2023}.
• Input Handling: The input should be a multi-channel 3D tensor. If using PET/MRI/Clinical data, the input volume shape might be $(C, D, H, W)$, where $C$ is the number of channels (e.g., PET, MRI, and reformatted clinical data) \cite{NaserWahid2021}.
• Sequential/Longitudinal Modeling (If multi-visit data is used): If you have longitudinal 3D scans, consider methodologies specialized for sequences, such as:
    ◦ DP-GAT Framework: This uses a 3D CNN to extract features, identifies Regions of Interest (ROIs) (e.g., via 2D UNet), and then uses a Graph Attention Network (GAT) for reasoning across these regions over time, which is effective for fine-grained biological structures and long-range relationships \cite{FooHsu2022}.
    ◦ Longitudinal Transformer (LTSA): Represents longitudinal images as a sequence and uses a Transformer encoder with causal temporal attention, integrating visit time embeddings \cite{HolsteLin2024}.
Survival Prediction Head
The head should map the final 3D feature representation ($\mathbf{v}$) to the predicted time outcome, designed to handle censoring. We recommend a distribution-based or discrete-hazard approach over simple regression, as these inherently model censoring.
• Discrete Hazard/Survival Model (DeepHit/LH/LTSA): The model outputs a vector representing the hazard probabilities across discrete time intervals \cite{RivailVogl2023,NaserWahid2021}. The total duration should cover the maximum observed TTP, divided into discrete intervals (e.g., 20 intervals of $164.25$ days \cite{NaserWahid2021}). Given the 6-month minimum observation time, 6-month or 12-month intervals are clinically sensible bins \cite{RivailVogl2023}.
• Accelerated Failure Time (AFT) Model (SAVAE/CenTime): The network outputs the parameters (e.g., $\mu_\theta(x)$ and $\sigma_\theta(x)$) of a chosen survival distribution (e.g., Weibull or discrete Gaussian) \cite{ShahinZhao2023,ApellnizParras2024}. This approach directly estimates the time distribution and is flexible regarding the proportional hazards assumption \cite{ShahinZhao2023,ApellnizParras2024}.
Step 4: Loss Functions and Training Strategy
The primary requirement is maximizing the utility of censored data and ensuring the model learns accurate ranking (risk ordering) and time estimation.
Core Loss Function (Survival/Time Regression)
Since censored data is present, traditional Mean Squared Error (MSE) is insufficient.
1. Censored Regression Loss (CRL): This combined objective function explicitly handles censored data in a regression framework, often paired with Cross Entropy Loss (CEL) for multi-task learning (diagnosis + prognosis) \cite{GaoLi2019}.
2. Logistic Hazard (LH) Loss: Defined as the negative log-likelihood of observed events, suitable for discrete-time models, and uses a specific censoring mask to ignore hazards after the event/censoring time \cite{RivailVogl2023}. This is effective for predicting progression risk over fixed time windows \cite{RivailVogl2023}.
3. AFT Log-Likelihood Loss: Used in models like SAVAE and CenTime. It calculates the log-likelihood based on the chosen parametric distribution (e.g., Weibull), accounting for whether the observation is censored or uncensored \cite{ApellnizParras2024,ShahinZhao2023}.
Regularization and Ranking Loss
To ensure robust feature representation and correct risk ordering, add a regularization loss.
1. Survival Rank-N-Contrast (SurvRNC): This loss functions as a regularizer applied in the latent embedding space. It enforces an ordinal representation based on true time-to-event differences, crucial for handling censored data and improving concordance performance \cite{SaeedRidzuan2024}.
2. Censor-Aware Ranking Loss ($\mathcal{L}_{ca_rnk}$): This loss explicitly encourages the network to produce a correct sorting of samples based on predicted survival time \cite{ZhuYao2016}.
Training Strategy
• Total Loss: Combine the survival/time loss ($L_{Prognosis}$) and the ranking loss ($L_{SurvRNC}$) using a hyperparameter $\beta$ to balance the two objectives: $L_{Total} = L_{Prognosis} + \beta \cdot L_{SurvRNC}$ \cite{SaeedRidzuan2024}.
• Handling Imbalance/Censoring:
    ◦ Under-sampling: If censored cases heavily outnumber progressors, randomly under-sample the censored patients in the training set \cite{RivailVogl2023}.
    ◦ Pseudo Labels (Advanced): For highly censored datasets, estimate pseudo labels for the censored samples (lower-bounded by the annotated censoring time) and use them to semi-supervise the regressor. This maximizes data utility but requires careful scheduling (e.g., cosine annealing) to handle noisy labels \cite{ZhuYao2016}.
Step 5: Evaluation and Deployment
1. Evaluation Metrics:
    ◦ Primary: Concordance Index (C-index), which measures the model's ability to rank patients correctly based on their predicted risk versus their observed time \cite{SaeedRidzuan2024,NaserWahid2021}.
    ◦ Time-Dependent Metrics: Dynamic AUC (Area Under the ROC Curve) at specified time horizons (e.g., 6, 12, 24 months) \cite{RivailVogl2023}. For regression models predicting exact time, Mean Absolute Error (MAE) can be used, adjusted for censoring \cite{ZhuYao2016}.
2. Cross-Validation and Ensembling: Use five-fold cross-validation (or 10-fold) performed at the patient level to ensure scans from the same patient do not appear in different folds \cite{NaserWahid2021,GaoLi2019}. Model ensembling (e.g., CONSENSUS approach, averaging predictions from multiple folds) can enhance stability and generalization \cite{NaserWahid2021}.
3. Interpretability (Post-Hoc): If interpretation is necessary for clinical use, employ techniques like Class Activation Maps (CAM) or occlusion sensitivity analysis to visualize the 3D regions that contributed most significantly to the progression prediction \cite{RivailVogl2023}. 


##################################
Lab and binary clinical data encoder 


--------------------------------------------------------------------------------
Step 1: Input Definition and Categorization
The input data ($\mathbf{T}$) is defined by two primary types of features:
1. Numerical Features ($\mathbf{T}_n$): Continuous values like PSA and hemoglobin measurements. These require standardization/normalization before embedding \cite{ZhangHager2025}.
2. Categorical Features ($\mathbf{T}_c$): Binary presence/ absence of comorbidities.
Step 2: Modality-Specific Feature Embedding
To manage the inherent differences in data types (heterogeneity), we employ distinct embedding strategies for numerical and categorical features, a methodology validated in multi-modal systems like ViTa and cVAE models \cite{LiuSeguin2025,ZhangHager2025}.
1. Numerical Feature Embedding ($\Theta_n$): For continuous variables (PSA, hemoglobin), linear-scaled embeddings ($\Theta_n$) are utilized \cite{ZhangHager2025}. The numerical data fields should first be standardized, for instance, using z-score normalization, followed by a simple linear layer to map them to an initial embedding dimension $D_n$.
2. Categorical Feature Embedding ($\Theta_c$): For binary comorbidities, learnable lookup table embeddings ($\Theta_c$) are ideal \cite{ZhangHager2025}. Alternatively, one-hot encoding can be applied, followed by a Multi-Layer Perceptron (MLP) projection \cite{ZhangHager2025,DingLi2025}. This step transforms the sparse binary features into a dense, initial embedding of dimension $D_c$.
Step 3: Feature Fusion via Concatenation
The distinct initial feature embeddings (the numerical embedding $\mathbf{X}_n$ and the categorical embedding $\mathbf{X}_c$) are combined to form a single initial tabular representation $\mathbf{X}_T$ by concatenation \cite{ZhangHager2025}:
$$\mathbf{X}_T = \mathbf{X}_n \oplus \mathbf{X}_c$$
where $\mathbf{X}T \in \mathbb{R}^{D{initial}}$, and $D_{initial}$ is the sum of the embedded dimensions $D_n$ and $D_c$. This initial fusion creates a high-level, informative feature vector \cite{ZhangHager2025}.
Step 4: Latent Space Projection (The Encoder Backbone)
To guarantee the fixed, pre-specified tensor shape and generate a dense, information-enriched representation $\mathbf{Z}$ for downstream tasks, the concatenated input $\mathbf{X}_T$ is fed into a core encoder, referred to in the literature as a "profile projector" or a dedicated encoder for non-image modalities \cite{LiuSeguin2025,SchoutenNicoletti2025}.
Architecture Choice (Simplicity & Efficacy): MLPs or small Transformer networks are preferred for encoding non-image data due to their ability to handle varied data and output fixed-dimensional vectors \cite{SchoutenNicoletti2025,LiuSeguin2025}.
• Implementation: We propose a shallow Multi-Layer Perceptron (MLP) structure, which is computationally efficient and commonly used for structured inputs \cite{LiuSeguin2025}. Alternatively, a lightweight Transformer-based encoder ($\mathcal{F}_T$) can be applied to learn relationships among the concatenated features \cite{ZhangHager2025}.
• Process: The MLP (or Transformer encoder) compresses the high-dimensional initial representation $\mathbf{X}T$ into the target latent representation $\mathbf{Z}$:$$\mathbf{Z} = \mathcal{F}{\text{Tabular}}(\mathbf{X}_T)$$
The profile projector (MLP) utilized in cVAE models, for example, converts measures into a hidden representation $\mathbf{t}$ through fully connected layers \cite{LiuSeguin2025}. Similarly, the final layer of our encoder dictates the fixed output shape, ensuring the tensor $\mathbf{Z}$ meets the downstream model's requirement.
Step 5: Output Tensor Specification
The output $\mathbf{Z}$ is the dense latent vector that serves as the foundation for predicting TNM and time to progression.
• Fixed Shape Constraint: If the required pre-specified tensor shape is $1 \times C$, where $C$ is the latent feature dimension (e.g., $C=128$ as seen in connectome generation \cite{LiuSeguin2025} or latent diffusion models \cite{PuglisiAlexander2025}), the final layer of the encoder must project the features to this exact size: $\mathbf{Z} \in \mathbb{R}^{1 \times C}$.
• Utility for Downstream Tasks: This dense representation $\mathbf{Z}$ can be used in prognostic prediction models, such as those leveraging multimodal data (e.g., combining $\mathbf{Z}$ with image features if available) for cancer survival prediction, which inherently relies on combining clinical information for assessment \cite{DingLi2025}. It provides a comprehensive feature foundation for predicting outcomes like TNM classification and survival hazards \cite{DingLi2025}.
The resultant structure is a simple yet robust feature encoder that effectively transforms heterogeneous clinical data into a dense, fixed-size latent representation $\mathbf{Z}$.


##########################################
reports, clinical notes (free text) encoders 

Optimal Architectural Strategy for Capturing Clinically Meaningful Free Text
The optimal architecture for processing free-text clinical data should be built upon the Transformer neural network architecture, which forms the backbone of modern LLMs. The Transformer architecture employs self-attention mechanisms, enabling a deep, bidirectional understanding of language by discerning the meanings of words and their sequential context, which is crucial for handling complex clinical narratives.
To ensure the representation is clinically meaningful, the encoder must address the gap between general language knowledge (on which many foundational LLMs are trained) and the specialized medical domain. Since radiology and pathology reports rely on specific terminology and patterns, using a domain-specific LLM provides a strong foundation.
Leveraging Large Language Models (LLMs)
Frozen vs. Fine-Tuning
For the critical task of generating an informative embedding for downstream disease trajectory modeling (NODE), fine-tuning the domain-specific LLM (e.g., Med-GEMMA) is generally preferred and necessary over using it as a frozen, off-the-shelf feature extractor.
While LLMs inherently possess strong generalization and few-shot learning capabilities, adapting them to specific clinical applications—where precision and accuracy are paramount—is typically achieved through fine-tuning. Fine-tuning refines pre-trained models using labeled, task-specific examples, adjusting the model’s behavior and aligning it with the intended function without needing to introduce substantial new domain knowledge from scratch. This process can lead to specialized models that match or exceed the performance of larger proprietary models for specific tasks, offering a more computationally efficient and privacy-preserving solution.
To mitigate the computational cost of training the entire LLM, Parameter-Efficient Fine-Tuning (PEFT) techniques such as Low-Rank Adaptation (LoRA) can be employed. LoRA reduces the model’s memory footprint and computational requirements by introducing and training small, trainable rank decomposition matrices while keeping most original LLM parameters fixed.
Optimal Intermediate Task Objectives for Fine-Tuning
To yield the most informative representation for the downstream disease trajectory modeling task, the fine-tuning objective should force the LLM to structure and contextualize clinical findings relevant to disease progression.
1. Named Entity Recognition (NER) and Structured Information Extraction:
    ◦ A primary objective should be the extraction of structured clinical information (e.g., template filling, NER of key findings, or relation extraction) from the free text. Fine-tuning the LLM to output key features as a structured report (e.g., using predefined templates or categorical labels like PSMA-RADS scores or Gleason grades derived from the text) ensures that the essential clinical data points required for NODE input are accurately identified.
    ◦ This extraction task directly converts complex textual inputs (like radiology reports) into discrete, quantitative data points that integrate smoothly with the tabular data.
2. Domain Adaptation and Alignment (Contrastive Learning):
    ◦ Objectives designed for domain adaptation, such as Contrastive Semantic Ranking, can align the LLM's feature space to the medical domain and task specifically. This involves training the LLM to generate outputs similar to high-ranked, relevant clinical reports while distancing itself from less correlated reports retrieved from other medical sources.
3. Longitudinal Consistency Constraints (Predicting Trajectory):
    ◦ If the system incorporates historical reports (as implied by disease evolution modeling), the fine-tuning loss should include constraints that capture disease progression. This involves extracting and aligning time-shared (stability) and time-specific (progression/emergence) features between sequential reports, using constraints like intra-modality similarity and multimodal structural constraints to ensure the text embeddings accurately reflect the change in disease status over time.
Data Fusion Strategy
Given the disparate nature of the inputs—a high-dimensional, dense embedding from the LLM (text) and low-dimensional, sparse data (PSA values)—a simple concatenation followed by an MLP may be insufficient as it risks confusing the model and failing to explicitly model crucial interactions.
More sophisticated fusion mechanisms are recommended:
1. Cross-Attention Mechanisms:
    ◦ A cross-attention mechanism should be employed to explicitly model the interactions between the dense text embedding and the tabular feature vector. This method, standard in multimodal Transformer architectures, allows the text features to selectively attend to the most relevant quantitative values (e.g., associating the presence of specific findings mentioned in the report with the precise numerical PSA score). This contrasts with standard self-attention, which operates within a single modality, or simple concatenation.
2. Modality-wise Fusion (Mixture of Experts):
    ◦ Inspired by Mixture-of-Experts (MoE) architectures, a modality-wise fusion strategy may be beneficial. This involves treating the text embedding and the tabular data as inputs to distinct, specialized expert networks. A soft router module then dynamically computes weights to allocate the contributions of each expert's output for the final fused vector. This method has been shown to be superior to element-wise fusion for integrating different feature sets.
3. Latent Space Alignment:
    ◦ Regardless of the initial fusion technique (attention or expert networks), the combined output must be projected into a standardized, low-dimensional latent space suitable as input for the downstream NODE. A linear projection layer can be used efficiently to align the resulting fused vector with the dimensional requirements of the subsequent model.
Handling Clinical Nuances
The encoder architecture can be designed to be robust to clinical complexities like negation, uncertainty, and abbreviations by leveraging the inherent capabilities of LLMs and incorporating specific design choices:
1. Inherent LLM Contextualization: LLMs based on the Transformer architecture inherently possess a deep contextual understanding that aids in complex language tasks. This contextualized representation learning helps implicitly resolve ambiguities such as co-references and abbreviations by processing them within their specific report context.
2. Prompt Engineering and Few-Shot Learning: The fine-tuning process or inference procedure should utilize advanced prompt engineering, specifically few-shot prompting, which significantly enhances the model's performance on complex tasks. The prompt can include examples that explicitly demonstrate:
    ◦ Negation handling: E.g., interpreting "no evidence of extraprostatic extension" as a negative finding that must be accurately retained in the derived clinical representation.
    ◦ Uncertainty/Specificity: E.g., distinguishing between a tentative finding ("suspicious for...") and a definitive finding, perhaps by mapping the language to a confidence score or likelihood inherent in standardized reporting frameworks.
3. Intermediate Structured Extraction (Pre-processing): Utilizing the LLM to perform Information Extraction (IE) as an intermediate step forces the model to resolve ambiguities and map findings to standardized terminology. This involves training the model to consistently extract clinical findings and their associated modifiers (like negation status or certainty level), effectively converting the nuances into structured data points (e.g., using a knowledge graph structure that explicitly labels entities and their attributes like 'acute' or 'abnormality').
4. Retrieval-Augmented Generation (RAG) for Grounding: Incorporating a RAG component, which links the LLM to external, verified clinical knowledge bases (e.g., specialized medical terminologies or domain-specific protocols), helps ground the model's interpretation. This enhances the model’s ability to correctly resolve ambiguous abbreviations and ensure the clinical findings accurately reflect real medical terminology, thus addressing a known limitation of LLMs in the medical context.

###################################
disentangling latent space in VAE - mutual information and kl divergence with appropriate underlying probability distribution how to best design loss functions 

Step 1: The Variational Autoencoder (VAE) Objective and Latent Space
Variational Autoencoders are deep generative models consisting of an encoder and a decoder, designed to learn a low-dimensional, continuous latent representation ($Z$) of high-dimensional data ($X$) \cite{HeSarwal2024,FriedrichFrisch2024}. The challenge in VAEs, particularly in medical imaging, is that the latent space typically exhibits entangled behavior, meaning a single dimension maps to multiple underlying data attributes, complicating interpretation and control \cite{CetinStephens2022}.
The Evidence Lower Bound (ELBO)
The fundamental training objective of a VAE is to maximize the Evidence Lower Bound (ELBO) on the data log-likelihood, which serves as the loss function \cite{FragemannArdizzone2022,FriedrichFrisch2024}. The VAE formulation introduces an inference model (encoder) $q_{\phi}(Z|X)$ to approximate the intractable true posterior $p(Z|X)$ \cite{FriedrichFrisch2024,FragemannArdizzone2022}.
The ELBO equation is defined as \cite{FragemannArdizzone2022,CetinStephens2022}: $$ \log p_{\theta}(X) \geq E_{Z \sim q_{\phi}(Z|X)}[\log p_{\theta}(X|Z)] - D_{KL}(q_{\phi}(Z|X)||p(Z)) $$
The VAE loss function minimizes the negative ELBO, consisting of two primary terms:
1. Reconstruction Loss ($\mathcal{L}_{recon}$): $E_{Z \sim q_{\phi}(Z|X)}[-\log p_{\theta}(X|Z)]$. This term ensures the decoded output ($\hat{X}$) resembles the input ($X$), typically implemented using Mean Squared Error (MSE) or Binary Cross-Entropy (BCE) \cite{FriedrichFrisch2024,CetinStephens2022}.
2. Regularization Loss ($\mathcal{L}_{KL}$): $D_{KL}(q_{\phi}(Z|X)||p(Z))$. This term measures the Kullback-Leibler (KL) divergence between the approximate posterior distribution $q_{\phi}(Z|X)$ inferred by the encoder and a predefined prior distribution $p(Z)$ \cite{CetinStephens2022}.
Underlying Probability Distributions
For standard VAEs, the latent variable distributions are assumed to follow \cite{FriedrichFrisch2024,SanchezKascenas2022}:
• Prior Distribution $p(Z)$: Assumed to be a simple distribution, typically a factorized standard normal distribution, such as $N(0, I)$ \cite{FragemannArdizzone2022,HavaeiMao2021}. This factorization (independence between latent dimensions) is crucial for interpretability.
• Approximate Posterior Distribution $q_{\phi}(Z|X)$: Assumed to be a multivariate Gaussian distribution $N(\mu, \Sigma)$, where the encoder networks predict the mean ($\mu$) and variance ($\Sigma$) parameters \cite{FriedrichFrisch2024,SanchezKascenas2022}.
Step 2: Linking KL Divergence and Mutual Information for Disentanglement
The goal of disentanglement is to ensure semantic changes in the data correspond separately to individual dimensions in the latent space \cite{FragemannArdizzone2022}. The regularization loss $\mathcal{L}_{KL}$ is the key component manipulated for disentanglement.
Decomposition of the KL Term
The expected value of the KL divergence term, averaged over the data distribution $p(X)$, can be precisely decomposed into two terms related to Mutual Information (MI) \cite{FragemannArdizzone2022}: $$ E_{X \sim p(X)}[D_{KL}(q_{\phi}(Z|X)||p(Z))] = I(X, Z) + D_{KL}(q_{\phi}(Z)||p(Z)) $$ Where:
• $I(X, Z)$ is the Mutual Information between the input $X$ and the latent code $Z$. MI measures the dependence between two random variables \cite{Hanigutyt2024,Hanigutyt2023}. Maximizing $I(X, Z)$ means the latent representation $Z$ is highly informative about the input $X$ \cite{Hanigutyt2024,Hanigutyt2023}.
• $D_{KL}(q_{\phi}(Z)||p(Z))$ is the KL divergence between the aggregate posterior $q_{\phi}(Z) = E_{X}[q_{\phi}(Z|X)]$ and the prior $p(Z)$.
The Role of Total Correlation (TC)
A further decomposition of $D_{KL}(q_{\phi}(Z)||p(Z))$ highlights the statistical independence among the latent dimensions: $$ D_{KL}(q_{\phi}(Z)||p(Z)) = \underbrace{D_{KL}(q_{\phi}(Z)||\prod_{j} q_{\phi}(Z_j))}{\text{Total Correlation (TC)}} + \sum{j} D_{KL}(q_{\phi}(Z_j)||p(Z_j)) $$ The Total Correlation (TC) term specifically measures the dependence between the individual latent dimensions $Z_j$ in the aggregate posterior $q_{\phi}(Z)$ \cite{FragemannArdizzone2022}. Minimizing the TC pushes the individual dimensions of $Z$ toward independence.
Step 3: Designing Loss Functions for Disentanglement
Effective VAE-based disentanglement relies on designing a loss function that intelligently weights or replaces terms related to $I(X, Z)$ and TC.
3.1 $\beta$-VAE: Weighting the Global Regularization
The $\beta$-VAE approach modifies the VAE loss by introducing a hyperparameter $\beta > 1$ that weights the KL term \cite{FragemannArdizzone2022,CetinStephens2022}: $$ \mathcal{L}{\beta\text{-VAE}} = \mathcal{L}{recon} + \beta \cdot D_{KL}(q_{\phi}(Z|X)||p(Z)) $$ By increasing $\beta$, the model places more emphasis on forcing $q_{\phi}(Z|X)$ to match the factorized prior $p(Z)$ \cite{FragemannArdizzone2022}. This encourages the latent dimensions $Z_j$ to become independent (disentangled).
Technical Trade-off: Increasing $\beta$ also increases the penalty on the entire KL term, which, based on the decomposition in Step 2, effectively reduces the mutual information $I(X, Z)$ \cite{FragemannArdizzone2022}. This means the latent representation stores less information about the input, which often leads to a degradation in image reconstruction quality (blurry images) \cite{FragemannArdizzone2022}.
3.2 Total Correlation (TC) Variants (FactorVAE and $\beta$-TCVAE)
To mitigate the side effect of reducing $I(X, Z)$ while still enforcing independence (disentanglement), advanced models focus specifically on minimizing the TC term \cite{FragemannArdizzone2022}.
Loss Function Design: These methods typically keep the reconstruction loss and the mutual information term ($I(X, Z)$) minimally penalized, while heavily penalizing the Total Correlation term $TC(Z)$.
• FactorVAE and $\beta$-TCVAE introduce a regularization term focused on minimizing $TC(Z)$ \cite{FragemannArdizzone2022}. $\beta$-TCVAE explicitly decomposes the expected KL term and weights the TC term heavily \cite{FragemannArdizzone2022}. This approach aims to achieve a disentangled latent space structure without sacrificing representation fidelity \cite{FragemannArdizzone2022}.
3.3 Attribute-Based Regularization (Attri-VAE)
For medical generative models, particularly when specific clinical or imaging attributes are known, a supervised approach is highly effective. Attri-VAE incorporates domain knowledge directly into the loss function by enforcing known attributes to be encoded along specific latent dimensions \cite{CetinStephens2022,FolcoBercea2023}.
Loss Function Design (Attri-VAE): The loss function adds two crucial components to the standard $\beta$-VAE framework: a classification loss ($\mathcal{L}{MLP}$) and an attribute regularization loss ($\mathcal{L}{AR}$) \cite{CetinStephens2022}: $$ \mathcal{L} = \mathcal{L}{recon} + \beta\mathcal{L}{KL} + \mathcal{L}{MLP} + \gamma\mathcal{L}{AR} $$
• Attribute Regularization Loss ($\mathcal{L}_{AR}$): This loss term enforces an attribute $a$ to be encoded along a chosen dimension $d$ of the latent space (a regularized dimension) \cite{CetinStephens2022}. $\gamma$ is a tunable hyperparameter weighting the strength of this regularization \cite{CetinStephens2022}.
• Classification Loss ($\mathcal{L}_{MLP}$): A Multi-Layer Perceptron (MLP) classification network connected to the latent vector $Z$ enforces class separation in the latent space, often using Binary Cross-Entropy (BCE) loss \cite{CetinStephens2022}.
Attri-VAE leverages the $\beta$-VAE backbone to encourage general disentanglement, and $\mathcal{L}_{AR}$ provides explicit, targeted control over specific, meaningful attributes (e.g., heart volume, clinical conditions) \cite{CetinStephens2022}. This results in highly interpretable representations \cite{CetinStephens2022}.
Step 4: Further Loss Components for Robust Latent Space Design
In modern medical generative models, additional technical constraints are added to the loss function to improve robustness, quality, and control.
4.1 Incorporating Adversarial Training
To address the blurry reconstruction issue inherent in VAEs, techniques combine VAEs with Generative Adversarial Networks (GANs) using adversarial losses \cite{FriedrichFrisch2024,FolcoBercea2024}.
• Soft Introspective Variational Autoencoder (SIVAE): SIVAE incorporates an adversarial loss within the VAE framework, utilizing the encoder and decoder adversarially \cite{FolcoBercea2024}.
• AR-SIVAE: This model combines the $\mathcal{L}_{AR}$ attribute regularization loss (from Attri-VAE) into the SIVAE framework. This approach mitigates blurry reconstruction issues while preserving latent space interpretability \cite{FolcoBercea2023,FolcoBercea2024}. The SIVAE encoder objective is maximized to distinguish between real and generated samples, while the decoder aims to deceive the encoder \cite{FolcoBercea2023}.
4.2 Mutual Information Minimization for Confounder Control
In causal inference and medical imaging, sometimes the goal is to minimize MI to decouple features associated with confounders or spurious correlations from the primary task \cite{FayCobos2023}.
• Mutual Information Minimization Model (MIMM): This framework separates the feature vector $F$ into two parts: one for the primary task ($F_Y$) and one for the spuriously correlated factors ($F_Z$). MIMM minimizes the mutual information $I(F_Y; F_Z)$ to ensure that the primary prediction does not rely on shortcuts provided by the confounders $Z$ \cite{FayCobos2023}. This MI is typically estimated using a Mutual Information Neural Estimator (MINE) \cite{FayCobos2023}.
4.3 Consistency and Proximity Losses
Consistency losses ensure reliability and adherence to the data manifold:
• Cycle-Consistency Loss ($\mathcal{L}_{cyc}$): Used in generative models (e.g., GANs and VAEs) to ensure that a transformation and its inverse result in the original input, or that latent codes remain consistent across translations \cite{ZiaWahab2023,HuangZhou2024}. In Visual Attribution (VA2LT), $\mathcal{L}{cyc}$ ensures the latent codes for abnormal and normal classes are consistent with each other, defined as $\mathcal{L}{cyc} = |Z_x - Z_{\acute{x}}|_1$ \cite{ZiaWahab2023}.
• Proximity Loss ($\mathcal{L}_{prx}$): Encourages the generated counterfactual image ($\acute{x}$) to be close to the original input ($x$) in image space or feature space, maintaining faithfulness \cite{ZiaWahab2023,VermaBoonsanong2020}. In VA2LT, this can include $\mathcal{L}_{prx} = |x - \acute{x}|_1$ plus additional terms for entropy and smoothness \cite{ZiaWahab2023}.
• Sparsity Constraints: Often incorporated using $\ell_1$ regularization on the perturbation or difference ($|X - X_{CF}|_1$) to ensure minimal and interpretable feature changes in the counterfactual explanation \cite{NageshMishra2023}.

The objective of Disentangled Representation Learning (DRL) is to separate the main factors of variation present in the data distribution into distinct, meaningful, and independent latent dimensions \cite{LiuSanchez2022,FragemannArdizzone2022}. VAEs are fundamental deep generative models used for this purpose \cite{FragemannArdizzone2022,AbbasiMonadjemi2018}. Modifying the loss function is a common and critical practice to guide the deep framework toward better image-to-image translation and latent space organization in medical applications \cite{KhojasteSarakhsiHaghighi2024}.
Step 1: Understanding the Standard VAE Objective and Latent Space Priors
The standard Variational Autoencoder (VAE) objective focuses on maximizing the Evidence Lower-Bound Optimisation (ELBO) \cite{LiuSanchez2022,FragemannArdizzone2022}. The ELBO loss function naturally promotes learning a latent representation by balancing reconstruction fidelity and adherence to a prior distribution \cite{FriedrichFrisch2024}.
The general VAE loss function is defined based on the negative ELBO, which is minimized during training \cite{FragemannArdizzone2022,AbbasiMonadjemi2018}: $$L(\theta, \varphi) = \sum_{i=1}^{N} E_{z \sim q_{\varphi}(Z \mid x^{(i)})} (-\log(p_{\theta}(x^{(i)} \mid z))) + KL(q_{\varphi}(Z \mid x^{(i)}) \mid \mid p(Z))$$
1. Reconstruction/Likelihood Term: The first term, $E_{z \sim q_{\varphi}(Z \mid x^{(i)})} (-\log(p_{\theta}(x^{(i)} \mid z)))$, serves as a reconstruction error, ensuring the decoded image $x'$ resembles the input $x$ \cite{FragemannArdizzone2022,AbbasiMonadjemi2018}.
2. Regularization Term (KL Divergence): The second term, $KL(q_{\varphi}(Z \mid x^{(i)}) \mid \mid p(Z))$, is the KL divergence between the variational approximation of the posterior distribution $q_{\varphi}(Z \mid x^{(i)})$ and the latent prior distribution $p(Z)$ \cite{FragemannArdizzone2022,AbbasiMonadjemi2018}. This term is crucial for DRL.
Appropriate Underlying Probability Distributions
For standard VAEs aiming for unsupervised disentanglement, the following probability distributions are typically defined:
• Latent Prior Distribution $p(Z)$: This is almost universally chosen as a standard Gaussian distribution, $N(0, I)$ \cite{LiuSanchez2022,FriedrichFrisch2024}. The choice of a normal distribution with an identity covariance matrix enforces an orthogonal factorisation of the latent space, which is analogous to techniques like Principal Component Analysis (PCA) and contributes to initial disentanglement capabilities \cite{LiuSanchez2022}.
• Variational Posterior $q_{\varphi}(Z \mid X)$: This approximates the true posterior $p(Z \mid X)$ and is often parametrized as a Gaussian distribution with learned mean $\mu$ and variance $\sigma^2$ (i.e., $N(\mu, \sigma^2)$) derived from the encoder \cite{FriedrichFrisch2024}.
Step 2: Designing the Loss Function for Controlled Disentanglement using $\beta$-VAE
A primary technique for encouraging disentanglement is to manipulate the weight assigned to the KL divergence term, leading to the $\beta$-VAE \cite{LiuSanchez2022,FragemannArdizzone2022}.
The $\beta$-VAE loss function modifies the standard VAE loss by introducing a regularization coefficient $\beta > 0$ \cite{LiuSanchez2022,GautierBousse2024}: $$L_{\beta} = E_{z \sim q_{\varphi}(\cdot \mid x)} [\log p_{\theta} (x \mid z)] - \beta KL(q_{\varphi} (\cdot \mid x) \mid \mid p_{0})$$ \cite{GautierBousse2024,AbbasiMonadjemi2018}
By setting $\beta > 1$, more weight is given to the KL term \cite{LiuSanchez2022,FragemannArdizzone2022}. This strong constraint encourages the latent variables $Z_i$ to become independent (by aligning the posterior $q(Z \mid X)$ more closely with the factorized prior $p(Z)$) \cite{FragemannArdizzone2022,AbbasiMonadjemi2018}. This process forces $q(z \mid X)$ to carry less total information about the input $X$ \cite{LiuSanchez2022}.
The Trade-off: While increasing $\beta$ enhances disentanglement, it often leads to a decrease in image reconstruction quality, resulting in blurry generated samples \cite{FriedrichFrisch2024,LeShitiri2024}.
Step 3: Understanding the Connection between KL Divergence and Mutual Information
To design more sophisticated disentanglement losses, it is crucial to understand how the KL divergence term relates to information theory, specifically Mutual Information (MI) and Total Correlation (TC).
The expected value of the KL divergence term (averaged over the training data $X$) can be decomposed to highlight the roles of MI and TC \cite{FragemannArdizzone2022,AbbasiMonadjemi2018}: $$E_{X}[KL(q_{\varphi}(Z \mid X) \mid \mid p(Z))] = I(X, Z) + KL(q_{\varphi}(Z) \mid \mid p(Z)) - \sum_{j} KL(q_{\varphi}(Z_j) \mid \mid p(Z_j)) + TC$$ (This decomposition highlights that the expected KL term is related to the MI between the data $X$ and the latent variable $Z$, and the total correlation among the latent dimensions.)
Specifically, the term $\frac{1}{N} \sum_{i=1}^{N} KL(q_{\varphi}(Z \mid x^{(i)}) \mid \mid p(Z))$ can be related to the Mutual Information $I(X, Z)$ \cite{FragemannArdizzone2022,AbbasiMonadjemi2018}. Weighting this KL term more (i.e., using a large $\beta$) decreases the mutual information $I(X, Z)$ between the data and the latent representation \cite{FragemannArdizzone2022,AbbasiMonadjemi2018}. This reduction is what causes the latent space $z$ to store less overall information about the input $x$, thereby forcing it to only encode highly salient, often disentangled, factors—but at the cost of fidelity \cite{FragemannArdizzone2022,AbbasiMonadjemi2018}.
Step 4: Designing Advanced VAE Loss Functions by Targeting Total Correlation
To preserve reconstruction fidelity while still encouraging independence, advanced methods focus on controlling only the part of the KL divergence that strictly enforces independence, often termed Total Correlation (TC).
The Total Correlation term measures the dependence between the individual dimensions $Z_j$ of the latent vector $Z$ \cite{FragemannArdizzone2022,AbbasiMonadjemi2018}: $$TC = KL(q(Z) \mid \mid \prod_{j=1}^{d} q(Z_j))$$ where $q(Z) = \frac{1}{N} \sum_{i=1}^{N} q_{\varphi}(Z \mid x^{(i)})$ is the aggregate posterior, and $\prod_{j=1}^{d} q(Z_j)$ is the factorized aggregate posterior.
By isolating and weighting the TC term, methods like FactorVAE seek to minimize the correlation among latent dimensions without sacrificing the overall information capacity (MI) needed for good reconstruction \cite{FragemannArdizzone2022,AbbasiMonadjemi2018}.
The FactorVAE loss includes the normal ELBO structure augmented by a weighted TC term $\gamma \cdot TC$: $$L_{FactorVAE} = \frac{1}{N} \sum_{i=1}^{N} [ E_{q_{\varphi}(Z \mid x^{(i)})} (-\log p_{\theta}(x^{(i)})) + KL(q_{\varphi}(Z \mid x^{(i)}) \mid \mid p(Z)) ] + \gamma \cdot TC$$ \cite{FragemannArdizzone2022,AbbasiMonadjemi2018}
By increasing the weight $\gamma$, the model is explicitly constrained to reduce the interdependence between the latent dimensions, achieving disentanglement while retaining the overall necessary complexity for accurate image generation \cite{FragemannArdizzone2022,AbbasiMonadjemi2018}.
Step 5: Incorporating Other Constraints in Hybrid Loss Functions
In complex medical imaging tasks, hybrid loss functions are often employed, supplementing the VAE objective with additional constraints to ensure high fidelity, robustness, and application-specific feature separation.
1. Reconstruction Loss Variants (Pixel/Voxel-wise losses): While the VAE log-likelihood term acts as a reconstruction error, specific distance metrics are used to implement it:
    ◦ L1 (Mean Absolute Error, MAE): Often preferred over Mean Squared Error (MSE/L2) as it encourages less blurring and better visual results in generative tasks \cite{LeShitiri2024,FerreiraLi2024}. L1 loss is commonly applied to enforce a close resemblance between generated and real images \cite{ZhangPeng2025,CuiWang2024}.
    ◦ L2 (Mean Squared Error, MSE): Used for calculating the distance between the target image and the generated structure image, sometimes after applying filtering to extract only the structure \cite{FriedrichFrisch2024,WangWang2024}.
    ◦ Multi-Scale Structural Similarity Measure (MS-SSIM): Integrated into hybrid losses to preserve structural similarities while mitigating blurriness \cite{KhojasteSarakhsiHaghighi2024}.
2. Latent Consistency and Regression Losses: These enforce constraints directly on the learned latent codes:
    ◦ Latent Regression Loss ($L_{z rec}$): Minimizes the distance between the original latent vector $z$ and a new latent vector $z'$ encoded from the reconstructed image $X'$ \cite{LiuSanchez2022}. This ensures that information encoded in $z$ is contained in the reconstruction, preventing the decoder from ignoring the latent code \cite{LiuSanchez2022,ChartsiasPapanastasiou2021}.
    ◦ Distance Correlation (dCor) Loss: Used to explicitly minimize the dependence (linear and non-linear) between distinct latent subspaces ($w_i, w_j$) that are meant to be independent (e.g., separating camera factors from patient attributes) \cite{MllerKoch2025,ChartsiasPapanastasiou2021}. The loss $L_{DC}$ is minimized when $dCor(w_i, w_j) \approx 0$ \cite{MllerKoch2025}.
    ◦ Divergence Constraints for Feature Decoupling: In multi-modal analysis, KL divergence or Jensen-Shannon (JS) divergence $J_{JS}(\cdot)$ can be used to minimize the distribution gap between decoupled dose-invariant features from different modalities (e.g., $L_{SI, align} = J_{JS}(l_{inv}^{p}, s_{inv}^{p})$) to maximize shared invariant information \cite{GuoXue2022}.
3. Adversarial Regularization: VAEs can be combined with discriminators (VAEs/GANs hybrids) to improve image quality and regularization \cite{FriedrichFrisch2024}.
    ◦ Adversarial Loss ($L_{adv}$): Used to ensure the distribution of synthesized images is closer to that of real images \cite{KhojasteSarakhsiHaghighi2024,CuiWang2024}. In some VAE-GAN variants, a discriminator is trained to distinguish between positive samples (real data and corresponding latent code) and negative samples (reconstructed data and corresponding latent code) \cite{AbbasiMonadjemi2018}. This helps stabilize training and prevents mode collapse \cite{IslamAziz2024,FerreiraLi2024}.
    ◦ Feature-Level Adversarial Loss: Adversarial loss can be constrained to intermediate feature layers to compare high and low-level features, rather than just the final output \cite{FerreiraLi2024}.
In summary, designing effective VAE loss functions for disentanglement typically involves: (1) maintaining the core ELBO framework; (2) applying a strategic weighting ($\beta$ or $\gamma$) to the KL divergence term, often specifically targeting the Total Correlation (TC) to enforce independence among latent factors; and (3) incorporating hybrid terms (L1/L2 reconstruction, structural similarity, latent regression, or distribution alignment metrics like dCor or JS divergence) to preserve image quality and enforce domain-specific constraints critical for medical applications.

Disentangled Representation Learning (DRL) requires explicitly designing loss functions to constrain the information flow within the latent space, encouraging factors of variation to be independent \cite{LiuSanchez2022}.
Step 1: Refining VAE Loss Functions via KL Divergence and Total Correlation
While standard VAEs utilize the KL divergence term to enforce adherence to a simple prior (usually Gaussian $N(0, I)$ with identity covariance, which forces orthogonal factorisation) \cite{LiuSanchez2022,GautierBousse2024}, advanced VAE approaches specifically target component terms derived from the expected KL divergence to achieve fine-grained control over disentanglement.
A. Targeting Mutual Information (MI) using $\beta$-VAE
The standard VAE loss term, averaged over the dataset, can be decomposed to include the Mutual Information $I(X, Z)$ between the input data $X$ and the latent variable $Z$ \cite{AbbasiMonadjemi2018}.
The $\beta$-VAE modifies the ELBO objective by introducing a weight $\beta > 1$ to the KL term ($D_{KL}(q_{\varphi}(Z \mid X) || p_z)$) \cite{LiuSanchez2022,AbbasiMonadjemi2018}. Increasing $\beta$ increases the weight of the KL divergence term, which consequently decreases the Mutual Information $I(X, Z)$ \cite{LiuSanchez2022,AbbasiMonadjemi2018}. This forces the conditional posterior $q(z \mid X)$ to carry less overall information about the reconstruction, promoting disentanglement but potentially degrading image quality, leading to blurry images \cite{LiuSanchez2022,AbbasiMonadjemi2018}.
B. Targeting Total Correlation (TC) using FactorVAE and $\beta$-TCVAE
To mitigate the impact of reduced information capacity $I(X, Z)$ while maintaining independence, methods like FactorVAE and $\beta$-TCVAE focus on isolating and penalizing the component responsible purely for independence: the Total Correlation (TC) \cite{AbbasiMonadjemi2018}.
The TC measures the statistical dependency among the individual dimensions $Z_j$ of the latent vector $Z$ \cite{AbbasiMonadjemi2018}. It is defined as a KL divergence between the aggregate posterior $q(Z)$ and the product of its marginals $\prod_{j} q(Z_j)$: $$TC = KL(q(Z) \mid \mid \prod_{j=1}^{d} q(Z_j))$$
The FactorVAE loss function incorporates this term with a weight $\gamma$: $$L_{FactorVAE} = L_{ELBO} + \gamma \cdot KL( \frac{1}{N}\sum_{i=1}^{N} q_{\varphi}(Z \mid x^{(i)}) \mid \mid \prod_{j=1}^{d} q_{\varphi}(Z_j) )$$ The term $KL( \frac{1}{N}\sum_{i=1}^{N} q_{\varphi}(Z \mid x^{(i)}) \mid \mid \prod_{j=1}^{d} q_{\varphi}(Z_j) )$ is the Total Correlation \cite{AbbasiMonadjemi2018}. By weighting the TC term more strongly ($\gamma$), the model explicitly reduces statistical dependencies among the latent dimensions, which is considered the source of a disentangled representation \cite{AbbasiMonadjemi2018}. The $\beta$-TCVAE approach uses a decomposition of the expected KL divergence to isolate and weight the TC term for minimization \cite{AbbasiMonadjemi2018}.
Step 2: Utilizing Mutual Information Maximization in GANs
In Generative Adversarial Networks (GANs), the core adversarial loss typically minimizes the Jensen-Shannon (JS) divergence between the real data distribution and the generator's distribution \cite{FerreiraLi2024,FragemannArdizzone2022}. Disentanglement in GANs is often achieved by employing information-theoretic regularization to maximize the amount of control information retained in specific latent variables \cite{LiuSanchez2022,AbbasiMonadjemi2018}.
A. InfoGAN (Information Maximizing GAN)
InfoGAN maximizes the mutual information (MI) lower bound between a set of structured latent variables (control variables $c$) and the observed generated data \cite{LiuSanchez2022,AbbasiMonadjemi2018}. This approach guides the learning process so that changes in the control variables $c$ result in predictable, meaningful semantic changes in the generated image, thereby separating these interpretable features from unstructured noise ($z$) \cite{LiuSanchez2022}.
B. Adversarial Regularization for Distribution Matching
Adversarial modules (discriminators/critics) can be incorporated into VAE or GAN architectures to explicitly enforce specific disentanglement goals by matching latent distributions to predefined priors or known healthy distributions.
1. VAE-GAN Hybrids: In models like the Multi-Scale Adversarial Regularized Autoencoder (MSARAE), an adversarial training module (discriminator) is introduced to identify the potential representation of the VAE encoder, thereby forcing the latent representation to match the prior distribution (e.g., simple Gaussian $p_z$) \cite{ZhuZhou2025}. This helps build a more continuous and controllable embedding space and enhances robustness \cite{ZhuZhou2025}. The adversarial loss corresponding to minimizing the Jensen-Shannon divergence is used for this regularization \cite{ZhuZhou2025}.
2. Disease Disentanglement (e.g., PET-Disentangler): To separate healthy anatomical features ($z_h$) from disease features, a critic network (e.g., a Wasserstein GAN with gradient penalty) can be used to ensure that the healthy latent features match a specific healthy distribution \cite{GatsakAbhishek2024}. This distribution matching eliminates leakage of disease features into the healthy component \cite{GatsakAbhishek2024}.
Step 3: Employing Arbitrary Independence Measures
Some sophisticated approaches leverage statistical dependence measures that are specifically robust to non-linear correlations and arbitrary dimensionality, moving beyond standard KL/MI bounds.
A. Distance Correlation (dCor)
Distance Correlation (dCor) is a highly effective, non-parametric measure used to quantify the dependence between two random vectors of arbitrary dimensions \cite{MllerKoch2025,ChartsiasPapanastasiou2021}.
1. Measuring Independence: dCor measures both linear and non-linear dependencies and is zero if and only if the random vectors are independent \cite{MllerKoch2025,ChartsiasPapanastasiou2021}. This makes it suitable for minimizing dependence between desired disentangled subspaces ($w_i, w_j$) \cite{MllerKoch2025}.
2. Designing the Loss Function: The Disentanglement Loss ($L_{DC}$) minimizes the average distance correlation between unique pairs of decoupled latent subspaces ($\hat{w}_k$) \cite{MllerKoch2025}. This is crucial in medical imaging applications, such as retinal fundus image analysis, where it is used to disentangle factors like patient attributes (e.g., ethnicity) from confounding technical factors (e.g., camera effects) by enforcing statistical independence between the corresponding latent subspaces \cite{MllerKoch2025}.
3. Application in Content-Style Disentanglement (CSD): Distance correlation has also been proposed as a metric for factor independence in CSD frameworks, which typically handle latent variables of different dimensionalities (spatial anatomy factors $s$ and vector modality factors $z$) \cite{ChartsiasPapanastasiou2021}.
B. Other Distribution Distance Measures
Other distribution distance measures are used to ensure latent distributions align or diverge as required for disentanglement:
• Maximum Mean Discrepancy (MMD): MMD measures the distance between two distributions and is sometimes used instead of KL divergence in VAE variants (MMD-VAE) to encourage disentanglement by matching the aggregate posterior $q(z)$ to a factorized normal distribution $p(z)$ \cite{MllerKoch2025,AbbasiMonadjemi2018}.
• Jensen-Shannon Distance (JSD) / JS-Divergence: JSD is utilized in complex hybrid loss functions, such as enforcing dose-invariant alignment in PET image reconstruction, to minimize the distribution gap between decoupled dose-invariant features from low-dose and standard-dose PET images \cite{KhojasteSarakhsiHaghighi2024,GuoXue2022}. JSD is also equivalent to the adversarial loss used in vanilla GANs \cite{FerreiraLi2024,AbbasiMonadjemi2018}.
Step 4: Hybrid Loss Functions for Targeted Feature Decoupling
In many modern medical image applications, especially image-to-image translation and multimodal analysis, disentanglement is achieved by explicitly partitioning the latent space into domain-specific factors (e.g., content/anatomy, style/modality, disease/healthy) and implementing a suite of hybrid losses to manage reconstruction, consistency, and independence \cite{LiChen2024,AbbasiMonadjemi2018}.
A. Content and Style/Modality Disentanglement
In multi-modal image synthesis frameworks, images $X$ are encoded into anatomical content features ($s$) and modality/style features ($z$) \cite{ChartsiasPapanastasiou2021,SanchezVilaplana2018}.
1. Anatomy Consistency Loss: This constraint promotes similarity between the anatomical latent representation ($s$) derived from different modalities of the same input (or same patient), arguing that the anatomical structure should be independent of the imaging modality \cite{FragemannArdizzone2022,AbbasiMonadjemi2018}.
2. Alignment Loss for Geometry Preservation: For medical image synthesis dealing with misalignment, an anatomy consistency disentanglement module (ACDS) decomposes anatomical and style features \cite{LiChen2024}. An alignment loss can be formulated (e.g., using $L1$ distance) to minimize the discrepancy between the synthetic image output before and after applying a known deformation field, encouraging the synthetic module to be geometry preserving \cite{LiChen2024}.
3. Latent Regression/Reconstruction Loss ($L_{rec, z}$): This loss ensures that the information encoded in the modality factor $z$ is explicitly used for reconstruction \cite{ChartsiasPapanastasiou2021}. It minimizes the distance between the original modality factor $z$ and a new modality factor $z'$ re-encoded from the reconstructed image $X'$ \cite{ChartsiasPapanastasiou2021,LiuSanchez2022}. This is critical to prevent "posterior collapse," where the decoder ignores the $z$ factor, relying only on the anatomical factor $s$ for image synthesis \cite{ChartsiasPapanastasiou2021}.
B. Information Flow Constraints (Minimization and Maximization)
In dose reduction or image processing tasks, constraints can be placed on deep network features to govern the type of information encoded at specific layers \cite{PainGeorge2024}.
1. Mutual Information Minimization Constraint ($L_{min}$): A discriminator network is trained to determine if shallow kernel features ($f^l_k$) and deep PET features ($f^L_\lambda$) were sampled from the joint distribution or independently from marginal distributions \cite{PainGeorge2024}. The loss $L_{min}$ minimizes the MI between these features, penalizing deep PET features for encoding information already available to shallow kernel features \cite{PainGeorge2024}. This encourages preference for shallow representations, which might be more robust to corruption (e.g., low-dose noise) \cite{PainGeorge2024}.
2. Mutual Information Maximization Constraint ($L_{max}$): A discriminator is used to constrain deep PET features ($f^L_\lambda$) to encode global information by maximizing the MI between $f^L_\lambda$ and patches extracted from shallow PET features ($p^l_\lambda$) \cite{PainGeorge2024}.
The total information constraint ($L_I$) combines $L_{min}$ and $L_{max}$ and is propagated only through the PET encoding branch to control feature encoding \cite{PainGeorge2024}.
Summary of Loss Function Design Principles
To summarize how loss functions are designed for disentanglement:
Method Category
Goal
Key Loss Term(s)
Role of KL/MI/dCor
Source(s)
VAE $\beta$-Regularization
Enforce latent factor independence.
$L_{\beta} = L_{Recon} + \beta \cdot KL(q(Z \mid X) \mid \mid p(Z))$
Large $\beta$ decreases $I(X, Z)$, forcing salience. \cite{LiuSanchez2022,AbbasiMonadjemi2018}
VAE Total Correlation
Enforce independence while preserving reconstruction.
$L_{FactorVAE} = L_{ELBO} + \gamma \cdot TC$ (where $TC$ is $KL(\cdot \mid \mid \prod q(Z_j))$)
Explicitly minimize TC to decouple dimensions. \cite{AbbasiMonadjemi2018}
GAN Information Max.
Ensure specific latent codes control features.
Maximize $I(c, G(z, c))$ lower bound.
Maximize MI between latent control code and output. \cite{LiuSanchez2022,AbbasiMonadjemi2018}
Statistical Independence
Ensure subspaces are statistically independent.
$L_{DC} = \lambda_{DC} \cdot \sum dCor(w_i, w_j)$
Minimizes Distance Correlation (linear & non-linear dependence). \cite{MllerKoch2025,ChartsiasPapanastasiou2021}
Hybrid/Auxiliary
Prevent latent collapse, ensure quality, or align distributions.
$L_{rec, z}$, $L_{adv}$, $L_{align}$, $L_{min}$, $L_{max}$
MI/JSD/MMD/Adversarial loss used for aligning/repelling specific latent distributions. \cite{GatsakAbhishek2024,MllerKoch2025}

Disentanglement aims to ensure that distinct factors of variation in the data correspond to individual, controllable dimensions in the latent space \cite{FragemannArdizzone2022}.
I. Advanced VAE-Based Loss Functions (Supervised and Hybrid)
While the $\beta$-VAE minimizes the KL divergence term, $D_{KL}(q_{\phi}(Z|X)||p(Z))$, to enforce independence among latent dimensions \cite{CetinStephens2022,FragemannArdizzone2022}, supervised and hybrid approaches refine the loss function to achieve targeted disentanglement while improving reconstruction fidelity.
1. Attribute-Regularized VAE (Attri-VAE)
Attri-VAE focuses on establishing a direct correspondence between known data attributes ($A$) of interest (e.g., clinical measurements or shape features) and specific, predefined latent dimensions ($Z_r$) \cite{CetinStephens2022}.
Loss Function Design: The Attri-VAE objective function is composed of four primary terms \cite{CetinStephens2022}: $$ \mathcal{L} = L_{recon} + \beta L_{KL} + L_{MLP} + \gamma L_{AR} \quad (1) $$
• KL Divergence Term ($\beta L_{KL}$): The standard KL divergence term is included, often weighted by $\beta$, based on the $\beta$-VAE backbone to encourage general disentanglement \cite{CetinStephens2022}.
• Attribute Regularization Loss ($L_{AR}$): This term guides the network to encode an attribute $a$ along a dimension $r$ of the latent space $Z$ \cite{FolcoBercea2023}. It enforces a monotonic relationship between the latent dimension $Z_r$ and the attribute value $a$ \cite{CetinStephens2022}. This is typically computed by minimizing the Mean Absolute Error (MAE) between distance matrices calculated in the input attribute space ($D_a$) and the latent space ($D_r$): $$ L_{r,a} = \gamma_{reg} \times MAE(\tanh(\delta D_r) - sgn(D_a)) \quad (2) $$ where $\gamma$ (or $\gamma_{reg}$) weights the strength of regularization \cite{CetinStephens2022,FolcoBercea2023}, and $\delta$ controls the spread of the posterior distribution \cite{FolcoBercea2023}.
• Classification Loss ($L_{MLP}$): Estimates the Binary Cross-Entropy (BCE) loss for classification tasks, using a Multi-Layer Perceptron (MLP) connected to the latent representation \cite{CetinStephens2022}.
This approach resulted in improved scores for disentanglement metrics like Mutual Information Gap (MIG) and Separated Attribute Predictability (SAP) compared to $\beta$-VAE \cite{CetinStephens2022}.
2. Attribute-Regularized Soft Introspective VAE (AR-SIVAE/Attri-SIVAE)
To address the blurry reconstructions often associated with VAE-based methods \cite{FolcoBercea2024,FolcoBercea2023}, hybrid models combine VAE interpretability with Generative Adversarial Network (GAN) capabilities. AR-SIVAE integrates the attribute regularization loss ($L_{attr}$) into the Soft Introspective VAE (SIVAE) framework \cite{FolcoBercea2024,FolcoBercea2023}.
Loss Function Mechanism: SIVAE is an adversarially trained VAE that utilizes its own encoder and decoder in an adversarial manner (instead of requiring an additional discriminator network) \cite{FolcoBercea2024,FolcoBercea2023}.
• The encoder is trained to distinguish between real and generated samples.
• The decoder aims to deceive the encoder by generating samples using the standard Evidence Lower Bound (ELBO) and minimizing KL divergence of generated samples embedded by the encoder \cite{FolcoBercea2024}.
• Attribute Loss Integration: AR-SIVAE adds the attribute regularization loss ($L_{attr}$ or $L_{AR}$) to the SIVAE objective \cite{FolcoBercea2024}. The combination generates non-blurry samples while maintaining latent space interpretability and demonstrating improved performance in disentanglement metrics like SCC and Interpretability Score compared to $\beta$-VAE and SIVAE \cite{FolcoBercea2024,FolcoBercea2023}.
II. Disentanglement through Mutual Information Maximization (GAN-based)
GAN-based approaches often achieve disentanglement by explicitly maximizing the mutual information between parts of the latent code and the generated output, thereby encouraging certain dimensions to encode specific features \cite{FragemannArdizzone2022}.
1. InfoGAN
InfoGAN modifies the GAN objective by dividing the latent code into two parts: a compressed code $c$ (containing meaningful features) and standard noise $z$ \cite{FragemannArdizzone2022}.
Loss Function Design: InfoGAN adds a regularization term to the standard GAN loss $V(D, G)$ which maximizes the mutual information $I(G(c, z), c)$ between the generated image $G(c, z)$ and the corresponding component of the latent code $c$: $$ \mathcal{L}_{InfoGAN} = V(D, G) - \lambda I(G(c, z), c) \quad (3) $$ This mutual information $I(G(c, z), c)$ is estimated by training an encoder network $Q$ to predict $c$ from the generated image, maximizing a variational lower bound on $I(c; x)$ \cite{HavaeiMao2021}. Maximizing MI ensures that the specific latent code $c$ used is reflected in the generated output, promoting controlled feature variation \cite{DravidSchiffers2022}.
2. Dual Regularized Adversarial Inference (DRAI)
DRAI applies adversarial methods to explicitly disentangle content and style in medical images \cite{FragemannArdizzone2022,HavaeiMao2021}.
Loss Function Mechanisms: DRAI incorporates several objectives \cite{HavaeiMao2021}:
• Adversarial Training for Content-Style Minimization: DRAI minimizes the mutual information $I(z; c)$ between the inferred content ($c$) and style ($z$) variables using a novel application of the Gradient Reversal Layer (GRL) strategy \cite{HavaeiMao2021}. The objective function minimizes a lower bound on $I(z; c)$, constraining the latent feature generation to disregard features belonging to the other variable \cite{HavaeiMao2021}. This GRL-based term aims to minimize the information shared between content and style: $$ \min_G \max_{F_z} -E_{\hat{c} \sim q(c|x),\hat{z} \sim q(z|x)} [||\hat{z} - F_z(\hat{c})||] \quad (4) $$ where $F_z$ attempts to predict style $\hat{z}$ from content $\hat{c}$ \cite{HavaeiMao2021}.
• Self-Supervised Regularization: DRAI employs self-supervised consistency to ensure that content codes remain invariant to content-preserving transformations (e.g., rotation or flip) while style codes are sensitive to them, thereby further enhancing disentanglement \cite{HavaeiMao2021}.
• Latent Code Cycle-Consistency: This term maximizes the mutual information between the latent variables and the generated image, ensuring the generated output retains the information from the original codes \cite{HavaeiMao2021}. The corresponding loss function minimizes the $\ell_1$ distance between the inferred code ($z', c'$) from the generated image and the original code ($z, c$) \cite{HavaeiMao2021}.
3. MedXGAN (Conditional GAN for Pathology Disentanglement)
MedXGAN uses a Conditional GAN to disentangle medical images into an anatomical structure vector ($z_1$) and a pathology vector ($z_2$) \cite{DravidSchiffers2022}.
Loss Function Mechanism: This model maximizes the mutual information $I(y; G(z_1, y))$ between the class code ($y$) (which represents the pathology state, e.g., positive or negative) and the generated image $G(z_1, y)$. Maximizing this MI is achieved by minimizing a negative log-likelihood/cross-entropy term involving the classifier's output $p_c(y|G(z_1, y))$ \cite{DravidSchiffers2022}. This explicit maximization of MI guides the latent dimension $z_2$ to exclusively encode the pathological features \cite{DravidSchiffers2022}.
III. Disentanglement through Mutual Information Minimization (Causality/Confounder Mitigation)
Some methods utilize MI specifically to minimize the dependency between representations, particularly to remove spurious correlations (confounders) from the primary task features \cite{FayCobos2023}.
1. Mutual Information Minimization Model (MIMM)
MIMM addresses shortcut learning by partitioning the feature vector $F$ into two independent components: $F_Y$ (for the primary task $Y$) and $F_Z$ (for the spuriously correlated factor $Z$) \cite{FayCobos2023}.
Loss Function Design: The central goal is to minimize the mutual information $I(F_Y; F_Z)$ \cite{FayCobos2023}.
• MI Estimation: Since MI is difficult to compute directly, MIMM uses a Mutual Information Neural Estimator (MINE) network to provide a maximized lower bound approximation of the MI \cite{FayCobos2023}.
• Loss Penalty: The overall loss function for the feature encoder includes the cross-entropy losses for both $Y$ and $Z$, and an additional penalty term based on the estimated MI \cite{FayCobos2023}: $$ \mathcal{L}{MIMM} = \mathcal{L}{CE}(Y, \hat{Y}) + \mathcal{L}_{CE}(Z, \hat{Z}) + \lambda \cdot I(F_Y; F_Z) \quad (5) $$ Minimizing this combined loss forces $F_Y$ and $F_Z$ to become statistically independent, thereby ensuring the primary task prediction $Y$ is not dependent on the confounded factor $Z$, leading to counterfactually invariant predictions \cite{FayCobos2023}.
IV. Disentanglement in Normalizing Flow and Diffusion Models
Methods based on Normalizing Flows (NFs) and Diffusion Models (DMs) approach disentanglement via invertibility constraints or semantic latent space conditioning.
1. Normalizing Flow Approaches
Normalizing flows (NFs) are fundamentally invertible neural networks that map data to a simple latent distribution \cite{FragemannArdizzone2022,MelistasSpyrou2024}.
• GIN (General Incompressible-Flow Networks): This approach formally equates disentanglement to nonlinear Independent Component Analysis (nonlinear ICA) \cite{FragemannArdizzone2022}. GIN networks are designed to perform identifiable disentanglement if supplementary information, like class labels, is provided \cite{FragemannArdizzone2022}.
• GLOWin: Uses a standard GLOW normalizing flow and applies an existing disentanglement factor loss (model-independent) directly to a subset of the latent dimensions deemed semantically relevant \cite{FragemannArdizzone2022}.
2. Diffusion Model Approaches
Diffusion models often lack semantically meaningful representations in their latent space \cite{KazerouniAghdam2022}. Recent work addresses this by adding auxiliary structures or latent conditioning.
• DiffChest: This framework explicitly introduces an additional, lower-dimensional semantic latent space $p_{\phi}(z|x_0)$ that conditions the reverse diffusion process \cite{Hanigutyt2023}. It is mathematically proven that optimizing the simplified diffusion objective while conditioning on $z$ is equivalent to maximizing both the data likelihood and the mutual information $I(z; x)$ between the input $x$ and its latent representation $z$ \cite{Hanigutyt2023,Hanigutyt2024}. This maximization of MI promotes compressed and informative representations \cite{Hanigutyt2023}.
• Latent Drifting (LD): LD is an approach for adapting a pre-trained diffusion model to a target domain, enabling conditioning for tasks like counterfactual image generation \cite{YeganehFarshad2024}. It optimizes the latent space to enhance distribution matching during fine-tuning \cite{YeganehFarshad2024}.
• Promptable Counterfactual Diffusion: This method extends counterfactual diffusion sampling by using a Transformer-based denoising network and incorporating mask prompts to guide the generation of desired regions, ensuring semantic consistency and disentanglement between healthy and pathological features \cite{ShenHe2024}.
V. Model-Agnostic and Latent-Space Manipulation Approaches
These techniques manipulate the latent space of any generative model (or even a classifier's latent features) to enforce interpretability and disentanglement characteristics.
1. Hessian Penalty (Model-Independent)
The Hessian Penalty approach assumes that a disentangled representation exists if the change in the generated output, when varying one latent dimension, is independent of the remaining fixed factors \cite{FragemannArdizzone2022}. This is achieved by adding a regularization term (the Hessian Penalty) to an arbitrary loss function, making it model-agnostic \cite{FragemannArdizzone2022}.
2. Disentanglement via Contrast (DisCo)
DisCo is a model-independent technique that assumes disentangled directions already exist in the latent space of pretrained models \cite{FragemannArdizzone2022}.
• Method: It uses Contrastive Learning to find semantically meaningful directions ($r$) in the latent space \cite{FragemannArdizzone2022}. By shifting a latent vector $z$ in direction $r$ to produce $z'$, the resulting images $G(z)$ and $G(z')$ are expected to differ only in the semantic aspect corresponding to $r$ \cite{FragemannArdizzone2022}.
3. Visual Attribution using Adversarial Latent Transformations (VA2LT)
VA2LT addresses visual attribution by performing image-to-image translation in the latent space, aiming to generate counterfactual (CF) normal images from abnormal images by finding and modifying discrepancies in the latent space \cite{ZiaWahab2023}.
Loss Component: VA2LT enforces constraints via:
• Cycle-Consistency Loss ($\mathcal{L}_{cyc}$): Ensures that the latent codes for the abnormal ($z_x$) and corresponding counterfactual normal ($z_{\acute{x}}$) classes are consistent \cite{ZiaWahab2023}. This loss is formulated using the $\ell_1$ norm between the latent vectors: $\mathcal{L}{cyc} = |z_x - z{\acute{x}}|_1$ \cite{ZiaWahab2023}.
• Proximity Loss ($\mathcal{L}_{prx}$): Encourages the counterfactual image ($\acute{x}$) to remain close to the original image ($x$) in the image space, defined as $\mathcal{L}{prx} = |x - \acute{x}|{entr}(x, \acute{x}) + \mathcal{L}{smth}(x, \acute{x})$ \cite{ZiaWahab2023}. This implicitly encourages the latent modification to be minimal and targeted to the discrepancy region \cite{ZiaWahab2023}.
• Adversarial Loss ($\mathcal{L}_{adv}$): Guides generated images toward the manifold of the original data using a discriminator \cite{ZiaWahab2023}.
This approach generates a visual attribution map (VA map) by transforming the abnormal latent code into a normal one, capturing the full range of disease-affected regions in the latent space \cite{ZiaWahab2023}.

Disentangling the latent space in Variational Autoencoders (VAEs) is primarily achieved through meticulous design of the loss function, which heavily relies on balancing reconstruction accuracy with regularization constraints enforced by the Kullback-Leibler (KL) divergence and sometimes optimized using principles related to Mutual Information (MI).
1. The Role of KL Divergence and Underlying Probability Distributions
The foundational loss for a VAE is the Evidence Lower Bound (ELBO), which is maximized during training \cite{KomanduriWu2023,ZhouXie2023}. The ELBO formulation dictates the use of KL divergence to enforce regularization based on a specified probability distribution (the prior) \cite{ZhouXie2023,KomanduriWu2023}.
A. VAE Objective and the Standard Prior
The objective function of a standard VAE includes two main terms: the reconstruction loss (likelihood term) and the KL-divergence term \cite{ZhouXie2023}:
$$ L_{VAE} = \mathbb{E}{q{\phi}(z|x)}[\log p_{\theta}(x|z)] - D_{KL}(q_{\phi}(z|x)||p(z)) \quad \cite{ZhouXie2023,KomanduriWu2023} $$
1. Reconstruction Loss ($\mathbb{E}{q{\phi}(z|x)}[\log p_{\theta}(x|z)]$): Ensures the decoder $p_{\theta}(x|z)$ can accurately reconstruct the input $x$ from the latent representation $z$ \cite{ZhouXie2023}.
2. KL Divergence ($D_{KL}(q_{\phi}(z|x)||p(z))$): Regularizes the encoder’s approximate posterior distribution, $\boldsymbol{q_{\phi}(z|x)}$, to match a chosen prior distribution, $\boldsymbol{p(z)}$ \cite{ZhouXie2023,KomanduriWu2023}.
The underlying probability distribution specified for the latent space, the prior $\boldsymbol{p(z)}$, is typically chosen to be a standard isotropic Gaussian distribution ($N(0, I)$) \cite{MonteiroRibeiro2023,ZhouXie2023}. This assumption encourages the latent variables to be mutually independent \cite{MonteiroRibeiro2023,SubramanianAnnadani2022}.
B. Using $\beta$-VAE for Enhanced Disentanglement
To explicitly encourage disentanglement, variations like the $\beta$-VAE modify the ELBO by introducing a scaling factor $\beta$ to the KL term \cite{MonteiroRibeiro2023,ZhouXie2023}:
$$ ELBO_{\beta}(\theta, \omega) = \mathbb{E}{q{\theta}(z|x,pa)}[\log p_{\omega}(x |z,pa)]- \beta D_{KL}[q_{\theta}(z |x,pa)| p(z)] \quad \cite{MonteiroRibeiro2023} $$
Setting $\boldsymbol{\beta > 1}$ enhances disentanglement by placing more emphasis on matching the prior distribution, forcing the latent factors to separate \cite{ZhouXie2023}. This $\beta$ penalty pushes the model toward utilizing any conditioning information and enforcing effectiveness in Conditional VAEs \cite{MonteiroRibeiro2023}.
C. KL Divergence in Causal Representation Learning (CRL)
In advanced models, particularly Deep Structural Causal Models (DSCMs) that aim for disentanglement reflecting causal relationships, the choice of prior $p(z)$ and the use of KL divergence are tightly linked to the assumed Structural Causal Model (SCM) \cite{KomanduriWu2023}.
• Causal Priors: In CausalVAE, the latent variables $z$ are assumed to follow an SCM (e.g., linear Gaussian additive noise) \cite{KomanduriWu2023}. A conditional prior $p(z|y) = \prod_{i=1}^n p(z_i|y_i)$ is used to regularize the posterior, where $y$ represents auxiliary information (e.g., labels corresponding to causal factors) \cite{KomanduriWu2023,ZhouXie2023}. The underlying distributions are often assumed Gaussian, such that $p(z_i|y_i) = N(\lambda_1(y_i), \lambda_2^2(y_i))$ \cite{KomanduriWu2023}.
• Classifier Consistency: KL divergence can also be used as a loss component $L_f$ to enforce consistency with a pre-trained classifier $f$ \cite{SinglaEslami2021}. For instance, in counterfactual generation, $L_f$ may quantify the difference between the classifier's output on the counterfactual image and the desired target outcome, such as $D_{KL}(f(X_{cf}) || 1 - f(X))$ \cite{ShvetsovAriva2024}.
2. The Role of Mutual Information in Loss Design
Mutual Information (MI) measures the statistical dependency or the amount of information shared between two random variables \cite{TianHe2024}. It is primarily used in two ways concerning disentanglement:
A. Maximizing MI to Retain Information
MI can be maximized during a pretraining phase to ensure learned representations retain essential information from the source domain, thus promoting robust data utility for downstream tasks \cite{TianHe2024}.
• Jensen-Shannon MI: The Jensen-Shannon Mutual Information estimator can be used to approximate a lower bound of MI, $I(\tilde{X};E) \geq I(JSD)_{\theta,\omega} (\tilde{X};E)$ \cite{TianHe2024}. The objective is to maximize this bound between the input $\tilde{X}$ and the embedding $E$ \cite{TianHe2024}.
B. Minimizing MI to Achieve Disentanglement
Conversely, MI can be minimized between specific variables to achieve disentanglement by eliminating undesirable dependencies:
• Confounder Minimization: Generative models, including VAEs and GANs, have been employed to minimize the mutual information between an undesired confounding variable (like a site variable) and the image embedding in the latent space \cite{WangChaudhari2021}. This process aims to learn a representation where the confounding factor is disentangled \cite{WangChaudhari2021}.
3. Designing Comprehensive Loss Functions for Disentanglement
Effective disentanglement in VAEs often requires comprehensive loss functions that combine multiple objectives (reconstruction, regularization, and specialized constraints) \cite{HuangWang2024,KomanduriWu2023}.
Loss Component
Purpose in Disentanglement
Underlying Distribution/Metric
Source Examples
Reconstruction Loss ($L_{re}$ or Likelihood)
Ensures image fidelity and semantic information preservation \cite{ZhouXie2023}.
Cross-entropy loss \cite{UnknownAuthor2020}, $L_2$ loss \cite{RasalCastro2022}, or Discretized Gaussian/Bernoulli likelihood \cite{MonteiroRibeiro2023}. \cite{MonteiroRibeiro2023,UnknownAuthor2020}
KL Divergence ($L_{KL}$)
Regularizes the approximate posterior to match the latent prior distribution, facilitating factor independence/separation \cite{KomanduriWu2023}.
KL divergence between $q(z
x)$ and a Gaussian $p(z)$ (standard) or a Causal SCM prior $p(z
$\beta$-Penalty
Scales the KL term ($\beta > 1$) to enforce stronger regularization, enhancing disentanglement \cite{ZhouXie2023}.
N/A (Scaling factor applied to KL divergence) \cite{MonteiroRibeiro2023,ZhouXie2023}
Confounding/Decoupling Loss ($L_{conf}$ or $L_{Dec}$)
Forces redundant or unwanted features (confounders) to be ignored or decorrelated \cite{NieZhang2023,UnknownAuthor2020}.
KL divergence towards a uniform distribution ($D_{KL}(y_{uniform}, z_c)$) \cite{NieZhang2023}; or penalizing off-diagonal elements of the latent space covariance matrix $\Sigma$ (decorrelation loss) \cite{UnknownAuthor2020}. \cite{NieZhang2023,UnknownAuthor2020}
Supervised/Classifier Loss ($L_{cl}$ or $L_{sup}$)
Provides an inductive bias by linking specific latent dimensions to known high-level concepts (labels), enforcing disentanglement in subsets of the latent space \cite{UnknownAuthor2020}.
Binary Cross-Entropy (BCE) or Cross-Entropy loss $\mathcal{L}_{cl}(y, \tilde{y})$ \cite{UnknownAuthor2020,Singla2022}. \cite{KomanduriWu2023,UnknownAuthor2020}
Specific Loss Function Examples:
1. Composite VAE Loss (Conditional VAE): A generalized loss function for VAEs incorporating primary and secondary classification tasks (to enforce disentanglement based on clinical knowledge) is given by: $$ L_{total} = \frac{1}{T} \sum_{t=1}^{T} [L_{re}(x_t, \tilde{x}t) + \beta L{KL}(\mu_t, \sigma_t)] + \gamma L_{cl}(y, \tilde{y}) + \sum_{k=0}^{K} \alpha_k L_{cl}(y_k, \tilde{y}k) \quad \cite{UnknownAuthor2020}$$Here, $\boldsymbol{L{KL}}$ uses the $\beta$ penalty against a unit Gaussian distribution \cite{UnknownAuthor2020}. The secondary classification losses ($\boldsymbol{L_{cl}(y_k, \tilde{y}_k)}$) actively promote disentanglement of specific concepts within selected subsets of the latent space \cite{UnknownAuthor2020}.
2. Causal Disentanglement Loss (Confounding): To disentangle causal features from confounding features, a loss function can combine a supervised classification loss $L_{sl}$ (e.g., cross-entropy) for the causal part, and a confounding loss $L_{conf}$ that uses KL divergence to push confounding features $z_c$ towards a uniform distribution $y_{uniform}$ \cite{NieZhang2023}: $$ L_{conf} = - \frac{1}{|D|} \sum_{d \in D} KL(y_{uniform}, z_c) \quad \cite{NieZhang2023} $$ Minimizing this effectively suppresses the prediction power of the confounding features \cite{NieZhang2023}.
3. Latent Space Decorrelation: To maximize the information capacity of the latent space $Z$, a decorrelation loss $L_{Dec}$ can be used to penalize the off-diagonal elements of the covariance matrix $\Sigma$ of normalized latent features $Z_{norm}$ \cite{UnknownAuthor2020}.
In summary, the best design of loss functions for disentangling VAE latent spaces involves using KL divergence against a suitable prior distribution (often Gaussian or SCM-based) as the main regulator, complemented by specialized MI-related minimization objectives (to eliminate dependencies) or structural constraints (like classification losses and decorrelation losses) to impose desired separation among factors \cite{WangChaudhari2021,UnknownAuthor2020}.

1. Causal Representation Learning (CRL) and Structural Constraints
The most robust approaches for achieving meaningful disentanglement involve explicitly integrating causal models into the deep generative framework, particularly using Structural Causal Models (SCMs) \cite{KomanduriWu2023,ZhouXie2023}.
• SCM-based Priors and Mechanisms: Instead of relying on a simple isotropic Gaussian prior (which assumes mutual independence, often unrealistic \cite{ReinholdCarass2021,KomanduriWu2023}), models like CausalVAE embed an SCM into the VAE architecture \cite{ZhouXie2023}. This approach assumes the latent variables are causally related and regularizes the posterior using a conditional prior $p(z|y)$, where $y$ represents known causal factors (labels) \cite{KomanduriWu2023,ZhouXie2023}. This leverage of auxiliary information helps achieve identifiability and disentanglement of causal factors \cite{KomanduriWu2023}.
• Backtracking Counterfactuals (DeepBC): DeepBC provides a framework for generating causally compliant explanations by solving a constrained optimization problem in the structured latent space of a causal model \cite{KladnyKgelgen2023}. It forces changes in the observed data ($x'$) back to the latent variables ($u$) embedded in the causal model, automatically ensuring causal constraints are met and obviating the need for an additional loss function to enforce them \cite{KladnyKgelgen2023}.
• Learning Latent SCMs from Low-Level Data: This involves Bayesian approaches that learn the posterior over the weighted adjacency matrices ($W$) and noise covariances ($\Sigma$) of a linear Gaussian latent SCM \cite{SubramanianAnnadani2022}. This recovers the true causal structure and variables significantly better than standard VAEs (which rely on marginal independence) or GraphVAEs \cite{SubramanianAnnadani2022}.
2. Eliminating Confounding Variables and Spurious Correlations
Disentanglement often involves explicitly isolating and removing factors that spuriously correlate with the target features (confounders).
• Causality-Aware Confounding Adjustment: This counterfactual approach actively deconfounds the feature representations learned by Deep Neural Networks (DNNs) \cite{Neto2020}. This method offers better stability than merely balancing the training data, particularly under dataset shifts \cite{Neto2020}.
• Confounding Loss ($L_{conf}$): A critical method in architectures aiming to learn causal features (zx) separately from confounding features (zc). The confounding part is suppressed by using KL divergence to push the predicted distribution of the confounder towards a uniform distribution over all categories ($D_{KL}(y_{uniform}, z_c)$) \cite{NieZhang2023}. This minimization effectively removes the predictive power of the confounding features \cite{NieZhang2023}.
• Non-Overlapping Multiple Attentional Guidance Loss ($L_N$): Used to encourage the model to focus its attention map on multiple discriminative regions \cite{HuangWang2024}. In conjunction with a causal-effect loss ($L_C$), this helps prevent the model from focusing only on superficial, spurious correlations (which often plague models combining CNNs and attention mechanisms) and instead guides it toward regions that are truly causally related to the outcome \cite{HuangWang2024}.
• Minimizing Mutual Information (MI) with Confounders: Generative models, including VAEs and GANs, are used to minimize the mutual information between an undesired confounding variable (e.g., site variable) and the image embedding in the latent space to learn a disentangled representation \cite{WangChaudhari2021}.
3. Latent Space Regularization and Conditioning
Beyond the standard KL term, specific regularization terms can enforce structural properties within the latent space, directly aiding disentanglement.
• Decorrelation Loss ($L_{Dec}$): To ensure the latent variables are maximally independent and fully utilize the representation capacity of the latent space $Z$, a decorrelation loss can be introduced. This loss penalizes the off-diagonal elements of the covariance matrix $\Sigma$ of the normalized latent features $Z_{norm}$ \cite{UnknownAuthor2020}.
• Supervised Latent Space Classification: Incorporating secondary classifiers operating directly on subsets of the latent vector encourages disentanglement of specific explanatory concepts (e.g., clinical knowledge factors) within the learned representation \cite{UnknownAuthor2020}. This acts as an inductive bias, linking latent dimensions to known high-level concepts \cite{UnknownAuthor2020}.
• Latent Drifting ($\delta$): In Diffusion Models (which share latent space concepts with VAEs), Latent Drifting (LD), represented by a signed scalar value $\delta$, is introduced to the diffusion process during fine-tuning. This modifies the latent representation ($z_T$) to minimize the distance between the generated distribution and the target data distribution, thereby helping to disentangle the model’s learned representations to accurately reflect a new target distribution \cite{YeganehFarshad2024}.
4. Advanced Generative Architectures and Fine-Tuning
Methods that move beyond the basic VAE structure, especially those related to counterfactual generation, inherently promote better disentanglement or semantic representation within the latent space.
• Counterfactual Fine-Tuning/Augmentation: Training the generative model to produce high-fidelity counterfactuals (where specific factors are altered while others are preserved) requires a highly disentangled latent space \cite{RibeiroXia2023}. Techniques like Augmentation by Counterfactual Explanation (ACE) fine-tune models using counterfactual augmentations to improve uncertainty estimates and implicitly help separate ambiguous or out-of-distribution samples \cite{Singla2022}.
• Conditional HVAE and Parent Conditioning Dropout: High-fidelity counterfactual generation often uses Hierarchical VAEs (HVAEs). In HVAEs, Parent Conditioning Dropout can be used to prevent the model from prioritizing one conditioning path over another, thus improving counterfactual conditioning and adherence to the intended intervention \cite{RibeiroXia2023}.
• Using Non-VAE Generative Models: While VAEs are common, other deep generative models are leveraged for disentanglement, especially in the context of causality:
    ◦ Normalizing Flows (NFs): These are directly amenable to explicit abduction (inverting the function to find the exogenous noise) and ensure bijectivity, which helps in learning identifiable causal mechanisms \cite{PoinsotLeite2024,VigneshwaranOhara2024}.
    ◦ Diffusion Models (Diff-SCM): These leverage the inherent stochasticity of the diffusion process to model uncertainty-aware causal factors and can recover manipulable latent spaces for counterfactual estimation \cite{SanchezTsaftaris2022}.
    ◦ Adversarial Training: GANs or GAN-based components, such as a conditional GAN (cGAN), can be integrated into the loss function to enforce properties like data consistency and the smoother interpolation of the latent space (e.g., using path-length regularization $L_{reg}(G)$ borrowed from StyleGAN) \cite{Singla2022}.
In summary, the trend towards better disentanglement leverages causal inference and structural constraints to ensure that the latent factors are not only statistically independent but also semantically meaningful and causally isolated \cite{KomanduriWu2023,ZhouXie2023}.

############### 
importance of causality 

Importance of Causality in Medical Imaging ML Models
The focus on causality addresses fundamental limitations in traditional deep learning (DL) models used for medical image diagnosis \cite{HuangWang2024,Hambarde2023}.
1. Ensuring Transparency and Trustworthiness Deep neural networks (DNNs) are often criticised for their "black-box" nature, outputting diagnostic results without providing justification or information about the factors guiding the prediction \cite{HuangWang2024,SinglaEslami2021}. Explainability and transparency are extremely significant in disease diagnosis, as a patient requires not only an accurate prediction but also a reasonable explanation of the disease and a clear path for intervention or treatment \cite{HuangWang2024}. Causal inference offers a fresh perspective to medical image diagnosis, exploring the intrinsic causal relationship between key features (like attention maps) and the prediction results to enhance explainability \cite{HuangWang2024}. This is essential for obtaining clinical trust and facilitating the incorporation of AI algorithms into everyday clinical workflows \cite{SinglaEslami2021,Singla2022}.
2. Eliminating Spurious Correlations One of the most critical roles of causality is distinguishing between true causal relationships and spurious correlations (co-occurrence) \cite{HuangWang2024,Hambarde2023}. Traditional attention-based methods often consider only correlation between attention maps and diagnostic results, which can lead them to focus on regions spuriously related to the predicted label, rather than those causally related \cite{HuangWang2024}.
• For example, in gastrointestinal endoscopic images, certain previous works might identify spurious correlation regions (e.g., an endothelial background) as discriminatory, while ignoring regions causally related to the diagnostic result (e.g., polypectomy regions) \cite{HuangWang2024}.
• Causal inference helps eliminate these spurious correlations arising from data selection bias \cite{HuangWang2024,NieZhang2023}. By quantifying the causal effect of features (like attention maps) on diagnostic outcomes, models are encouraged to focus on true causal representations \cite{HuangWang2024,VigneshwaranOhara2024}.
3. Enhancing Robustness and Generalization Causal considerations are crucial for addressing major challenges in medical imaging ML, such as data scarcity and data mismatch (generalization failure across different sites, scanners, or patient cohorts) \cite{CastroWalker2020,VigneshwaranOhara2024}.
• By modelling the assumed causal mechanisms of a system, causal models encode the system’s information more robustly, helping to generalize beyond the training distribution \cite{KomanduriWu2023,ZhouXie2023}.
• This framework provides a principled way to control for known confounders, such as age, sex, or acquisition conditions, which otherwise heighten the risk of biasing findings \cite{CastroWalker2020,ReinholdCarass2021}.
4. Enabling Causal and Interventional Reasoning Causal reasoning provides the necessary language to ask interventional and counterfactual questions, which goes beyond purely statistical association \cite{RasalCastro2022,XiaRoschewitz2024}. This capability is fundamental to advancing clinical decision-making and precision medicine \cite{ReinholdCarass2021,KomanduriWu2023}:
• Precision Medicine: It enables answering highly specific "what-if" questions, such as how a patient's anatomy would change if particular traits were different, or how effective a treatment would be \cite{ReinholdCarass2021,PawlowskiCastro2020}.
• Scientific Inquiry: The tools of causal inference provide a principled basis for testing the effect of interventions outside of a randomized controlled trial (RCT) setting \cite{ReinholdCarass2021}.
How Counterfactuals are Effective for Explaining
Counterfactual explanations (CEs) leverage the principle of causal reasoning to provide intuitive, contrastive, and actionable interpretations of ML models \cite{ShvetsovAriva2024,RossiLopez2024}.
1. Providing Contrastive and Feature-Level Insight A counterfactual explanation is typically defined as a perturbation of the input image (the original query $x$) that flips the classifier's decision to a user-specified hypothesis ($\bar{y}$) \cite{RossiLopez2024,Singla2022}.
• Visualizing Change: CEs show what would have been observed had some precondition been different while everything else stayed the same \cite{NasrEsfahanyKiciman2023,KladnyKgelgen2023}. By comparing the original image with its corresponding counterfactual image, end-users (such as clinicians) can visualize the difference in important image features that led to the change in classification decision \cite{Singla2022}.
• Identifying Decisive Features: Unlike simpler visualization techniques like saliency maps, which only show where a model is looking, counterfactual explanations show what imaging features are present in salient locations and how changing those features modifies the classification decision \cite{Singla2022,SinglaEslami2021}. This allows for the identification of subtle, discernible decisive features that drive predictions \cite{FangJin2024,FangWu2024}.
2. Enhancing Clinical Understandability and Trust Counterfactuals are a preferred form of explanation because they are contrastive and intuitive, aligning closely with human reasoning \cite{ShvetsovAriva2024,GuoDeng2024}.
• Clinical Utility: In medical imaging, CEs are invaluable for providing clinicians with insights into alternative diagnoses through plausible image modifications \cite{AtadSchinz2024}. This capability is critical for enhancing trust in diagnostic models \cite{Singla2022,AtadSchinz2024}.
• Empirical Validation: Human-grounded experiments involving diagnostic radiology residents found that counterfactual explanations significantly improved users' understanding of the classifier’s decision compared to methods like saliency maps or no explanation at all \cite{SinglaEslami2021,Singla2022}. Furthermore, CEs revealed that classifiers rely on clinically relevant radiographic features for diagnostic decisions, making the decision-making process more transparent \cite{SinglaEslami2021,Singla2022}.
3. Enabling Causally Grounded Interpretation (Structural Causal Models) When implemented using frameworks based on Structural Causal Models (SCMs)—often referred to as Deep Structural Causal Models (DSCMs) \cite{PawlowskiCastro2020,RasalCastro2022}—counterfactuals are generated through a formal three-step causal inference procedure:
1. Abduction: Inferring the unobserved exogenous noise variables that explain the factual observation \cite{PawlowskiCastro2020,ReinholdCarass2021}.
2. Action (Intervention): Modifying the causal graph according to the desired intervention (e.g., setting a variable to a counterfactual value) \cite{ReinholdCarass2021,LiShi2023}.
3. Prediction: Recomputing the outcome variables (the counterfactuals) using the modified graph and the inferred noise \cite{ReinholdCarass2021,LiShi2023}.
This process provides causally compliant explanations \cite{KladnyKgelgen2023}. For instance, frameworks like Causal Intervention-based Multi-head Attention network (CaIMA) employ causal intervention to quantify the true causal effect of attention maps on diagnosis results, using the difference between the actual result and the counterfactual result (obtained after intervening on the attention map) as a supervisory signal \cite{HuangWang2024}.
4. Use in High-Dimensional Data While performing counterfactual inference on high-dimensional data like medical images is challenging \cite{PawlowskiCastro2020,SanchezTsaftaris2022}, recent advancements using deep generative models (like Diffusion Autoencoders, VAEs, and Normalizing Flows) allow for the tractable generation of high-fidelity counterfactual images in medical contexts, such as brain MRIs and chest X-rays \cite{RibeiroXia2023,AtadSchinz2024}. These advancements show that counterfactuals can provide meaningful explanations even when dealing with complex data like 3D volumetric images \cite{PengXia2024,LiShi2023}.

#####################
strengths and weeknesses of node in time dependent data in irregular sampling points why it needs to work on      latent spaces rather then full 3d images (performance restrictions )

Strengths and Weaknesses of NODE in Time-Dependent Data with Irregular Sampling Points
Neural Ordinary Differential Equations (NODEs) offer a framework based on continuous-time dynamics, which is uniquely suited for handling irregular time series data common in fields like medicine and physics \cite{ChenLiu2024,GwakSim2020}.
Strengths
1. Handling Irregular Sampling: NODEs model the continuous transformation of the hidden state over time, allowing them to naturally incorporate data that arrives at arbitrary or unevenly spaced time points \cite{GwakSim2020,JohnsonBulgarelli2023}. This provides a continuous-time representation that overcomes the limitations of discrete-time recurrent neural networks (RNNs) that usually require fixed sampling rates or discrete time steps \cite{BelogolovskyGreenberg2023,HabibaPearlmutter2020}.
2. Prediction and Interpolation Flexibility: The continuous nature of NODEs enables them to perform multi-step prediction at arbitrary time points \cite{GaoYang2022,BahdanauCho2014}. They can infer values and model continuous dynamics between observed data points, a feature often leveraged in interpolation and extrapolation tasks \cite{BahdanauCho2014,ZappalaFonseca2022}.
3. Dynamic System Modeling: NODEs parameterise the derivative of the hidden state using a neural network, enabling the model to learn the underlying dynamics of the system \cite{KhoshsiratKambhamettu2022,YuMiao2022}. This approach allows the model to infer the dependency relationship between time steps without explicitly memorising historical information, making them more robust to missing data and noise compared to RNN-based models \cite{ChangLiu2023}.
4. Parameter and Memory Efficiency: NODEs can achieve performance similar to deep Residual Networks (ResNets) but often with a reduced number of parameters \cite{AnumasaSrijith2020,XieWu2023}. Crucially, when trained using the adjoint sensitivity method, NODEs have a constant memory cost regardless of the network depth, addressing a major bottleneck in deep model training \cite{Li2023,GaoYang2022}.
Weaknesses and Challenges
1. Computational Cost: The primary limitation is high computational cost during both training and inference \cite{JohnsonBulgarelli2023,ZhuGuo2023}. Solving the ODE requires iteratively using a numerical ODE solver (such as Runge-Kutta) for integration \cite{BelogolovskyGreenberg2023,HuYu2023}, which leads to a significant computational overhead and slower processing compared to conventional discrete deep neural networks (DNNs) \cite{BahdanauCho2014,HuYu2023}. This overhead limits applications where timely results are essential \cite{BelogolovskyGreenberg2023}.
2. Training Complexity and Data Needs: Training NODEs can be challenging \cite{ZeghlacheConze2023}. Since they learn a non-linear dynamics model, the training can be difficult and sensitive to noise, often requiring large datasets (data-hungry) to stabilise predictions \cite{BelogolovskyGreenberg2023,LosadaTerranova2024}. Overfitting is a frequently encountered technical limitation, particularly with limited dataset sizes \cite{LosadaTerranova2024}.
3. Sensitivity to Sparsity: While NODEs handle irregularity well, their performance can suffer when dealing with intermittent series characterised by long gaps and numerous unobserved values \cite{AbushaqraXue2022}. The performance of ODE-based models has an inverse relationship with the level of data unavailability \cite{AbushaqraXue2022}.
4. Representation Limitations: Standard autonomous NODEs face limitations in their expressive power, particularly their inability to model dynamical systems where trajectories in the phase space intersect \cite{DavisChoromanski2020,ZhuGuo2021}. This restriction stems from the uniqueness property of ODE solutions \cite{ZhuGuo2021,ZhuGuo2023}. This can be addressed by techniques like Augmented NODEs, which introduce additional dimensions (padding with zeros) \cite{ChenLiu2024,LosadaTerranova2024}.

--------------------------------------------------------------------------------
Working on Latent Spaces vs. Full 3D Images (Performance Restrictions)
The preference for working with latent spaces rather than full 3D images (or high-dimensional data in general) when using NODEs is primarily driven by severe computational and memory restrictions associated with processing high-dimensional volumetric data, even despite the memory efficiency inherent to NODEs.
The Challenge of High-Dimensional/3D Data
High-resolution 3D medical images, videos, or spatio-temporal dynamics exhibit strong temporal and spatial changes but impose high memory demands \cite{WiewelBecher2018,DavisChoromanski2020}.
1. Volumetric Complexity: Processing volumetric (3D) data, such as high-resolution medical images or fluid simulations, scales poorly. For instance, the complexity of a 3D problem is estimated as $O(n^3)$ compared to $O(n^2)$ for 2D \cite{LervgLowengrub2015}. Working with 3D models (e.g., for tumor modelling) significantly reduces the number of available training and test samples due to resource constraints \cite{LiuFusterGarcia2025}.
2. Memory Footprint of Operations: Training deep models on large 3D/video datasets is challenging because the tensor activations must contain an additional spatial or time dimension that scales linearly, making it difficult to parameterise powerful models \cite{DavisChoromanski2020}. For example, in Neural Architecture Search (NAS) for 3D medical image segmentation, training mixed operations requires extremely large memory usage \cite{UnknownAuthor2019}. Similarly, Convolutional Neural Networks (CNNs) used in imaging often face GPU memory constraints \cite{UnknownAuthor2020}.
3. NODE on Full Grids (Memory Intensive): Although NODEs benefit from constant memory cost for depth (using the adjoint method) \cite{BergHasenclever2018,DavisChoromanski2020}, when directly applied to high-resolution data grids, methods like NODEO (Neural ODE based optimization for registration) require the input of the whole grid coordinates and predict entire deformations in every iteration, leading to a large memory footprint \cite{SunHan2022}. To reduce this memory consumption, models must limit the spatial size or the channel number of the feature maps, which hinders the representation of fine deformations \cite{SunHan2022}.
The Necessity of Latent Spaces
The use of latent spaces addresses these challenges by transforming the high-dimensional data into a low-dimensional representation that is computationally feasible \cite{AshmanSo2020}.
1. Dimensionality Reduction: Latent representation learning encodes high-dimensional data (like 3D images or complex temporal trajectories) into a low-dimensional manifold or latent space \cite{AshmanSo2020,KberKalisch2023}. This dimension reduction is essential for making the temporal prediction problem feasible for dense three-dimensional samples \cite{WiewelBecher2018}.
2. Feasibility for Complex Dynamics: For highly complex systems, such as 3D fluid simulations involving millions of degrees of freedom, employing a reduced latent space representation is necessary to make the temporal prediction computationally viable \cite{WiewelBecher2018}.
3. Specialised Latent ODEs: Models like Latent Neural ODEs explicitly aim to learn and approximate the underlying ODE by deriving latent representation of the longitudinal input data, creating latent trajectories at a low-dimensional level for each patient \cite{LosadaTerranova2024}. The use of low-dimensional NODEs simplifies the complexity of the ODE dynamics, which is beneficial in applications like Pharmacokinetics (PK) modeling \cite{LosadaTerranova2024}.
4. Continuous Evolution on Latent Features: Continuous-depth models (like NODEs) are implemented to evolve latent space features before the decoder module \cite{JainGupta2022}. Working in this low-dimensional space allows for evolution to be integrated over arbitrary periods of time \cite{JainGupta2022}. However, sometimes using a simple global latent space can limit the ability to resolve spatially varying growth for a single tumour \cite{PetersenJger2019,UnknownAuthor2019}.
In summary, while NODEs inherently offer memory efficiency concerning depth due to the adjoint method, the absolute dimensionality of 3D data still incurs massive computational and memory costs during forward/backward passes, making the projection onto a lower-dimensional latent space a practical necessity for performance and scalability \cite{SunHan2022,WiewelBecher2018}.

The benefits of Neural Ordinary Differential Equations (NODEs) from the perspective of encoding knowledge in clinical models revolve around their unique structure as continuous dynamical systems, which enables the integration of biological, physical, and pharmacological expertise directly into deep learning architectures.
Here are the key benefits of NODEs in encoding knowledge within clinical models:
1. Integration of Expert/Mechanistic Knowledge (Hybrid Models)
NODEs provide a framework for creating hybrid models that merge the strengths of data-driven machine learning (ML) with well-established mechanistic domain knowledge, which is crucial in clinical domains where models must be explainable and reliable \cite{QianZame2021,LosadaTerranova2024}.
• Bridging the Gap: Traditional pharmacological models often describe dynamics using ODEs based on specialised knowledge, but they typically involve a limited set of variables, which may not be observable in routine clinical environments, and the relationship between expert variables and clinical variables is often unknown \cite{QianZame2021}. NODEs, particularly in a Latent Hybridisation Model (LHM), integrate a system of expert-designed ODEs with machine-learned NODEs to fully describe the system's dynamics and link the expert (latent) variables to observable clinical quantities \cite{QianZame2021}.
• Incorporating Physical Laws: NODEs approximate unknown ODEs using a neural network, which allows the incorporation of physics-based models or physical concepts (such as generalized homogeneity) to enhance interpretability and enable making physically consistent predictions, especially in temporal extrapolations beyond the training set \cite{SunZhang2019,ZhuLio2021}. This blending is sometimes referred to as a pharmacology-informed neural network \cite{LaurieLu2023,ClaretJin2018}.
• Addressing Data Scarcity: Pure ML approaches often fail when the sample size is small \cite{QianZame2021}. By integrating expert domain knowledge, hybrid NODE models (like LHM) consistently outperform previous works, particularly when few training samples are available \cite{QianZame2021}. This is highly relevant in medical fields where high-quality annotated data is often scarce or expensive \cite{ZhangCheng2024,UnknownAuthor2020}.
• Specific Clinical Applications: In clinical pharmacology, mechanistic behaviours are often translated into ODEs based on multiple variables \cite{LosadaTerranova2024}. NODEs facilitate the creation of pharmacology-informed DL models for applications like Pharmacokinetics (PK) modeling \cite{LosadaTerranova2024} and predicting disease progression under medication \cite{QianZame2021}. Similarly, in medical image analysis, integrating biophysics-informed regularisation (such as tumour growth Partial Differential Equations) into deep learning models enhances accuracy and robustness, especially in data-scarce scenarios, by enforcing alignment with actual biological behaviour \cite{ZhangCheng2024}.
2. Enhanced Interpretability and Explainable AI (XAI)
In clinical decision-making, understanding the underlying mechanisms (interpretability) is paramount for increasing clinician trust and facilitating clinical adoption \cite{QianZame2021,LaurieLu2023}. NODEs contribute significantly to explainability:
• Mechanistic Interpretation of Dynamics: The dynamics of latent variables in NODEs can be interpreted as explainable variables that effectively underline the intricate relationship between covariates and clinical outcomes \cite{LosadaTerranova2024}.
• Deriving Actionable Metrics: In tumor dynamic modeling (TDNODE), NODEs define an underlying dynamical law and produce an encoder output that can be interpreted as kinetic rate metrics (with the physical unit of inverse time) \cite{LaurieLu2023,ClaretJin2018}. These generated metrics, which represent patient-specific kinetic parameters, have been shown to be superior predictors of Overall Survival (OS) compared to existing metrics derived from traditional models \cite{LaurieLu2023,ClaretJin2018}. This methodology enables a direct connection between salient aspects of tumor trajectories and their impact on the predicted OS \cite{LaurieLu2023,ClaretJin2018}.
• Visualizing Internal Dynamics: A variant of NODE, the Neural Memory Ordinary Differential Equation (nmODE), demonstrates strong explainability of the internal representation. Visualising the internal representation of the ODE shows that samples belonging to the same class display high similarity, indicating that the status of the sample in the ODE is explainable \cite{BahdanauCho2014}. Furthermore, nmODE has been shown to contribute to rectifying and localising features extracted by conventional networks, making the features more confident and closer to the true label \cite{HuYu2023}.
3. Improved Robustness and Stability
The mathematical properties of ODEs lend NODEs intrinsic advantages concerning robustness, which is critical for clinical models dealing with noisy or perturbed data:
• Robustness against Perturbations/Noise: The non-intersecting property of ODE integral curves implies that the trajectories of the hidden state are topologically preserved \cite{ChenLiu2024,YanDu2019}. This intrinsic regularization helps increase robustness against random Gaussian perturbations and adversarial attacks compared to conventional Convolutional Neural Networks (CNNs) \cite{YanDu2019,BahdanauCho2014}. The fact that the output prediction of a perturbed sample would be bounded alleviates the impact of noise or attacks contained in the input [491, 496 NODEs introduce stochasticity to support the modeling of data that exhibits random noise or biological variability among individuals \cite{LosadaTerranova2024}.
• Addressing Limitations in Existing Models: Latent Neural ODEs are particularly robust in dealing with sparse and irregularly sampled time series data \cite{LosadaTerranova2024}, which is ubiquitous in real-world clinical applications \cite{LosadaTerranova2024,ZhuSabuncu2018}. They naturally handle missing or irregularly sampled observations due to the continuous nature of the differential equations, taking all available information at the precise time into account \cite{LosadaTerranova2024,KberKalisch2023}.
4. Mathematical Foundation and Flexibility
NODEs establish a deep connection between neural network architectures and continuous dynamical systems theory \cite{ZhangYao2019,ZhuGuo2021}, offering profound theoretical advantages:
• Foundation for New Architectures: The recognition that Residual Networks (ResNets) can be viewed as discrete-time approximations of Neural ODEs has allowed researchers to design new and more effective deep architectures by selecting certain discrete approximations of ODEs, drawing upon the rich theoretical knowledge available in the field of differential equations \cite{ZhangYao2019,ZhuGuo2021}.
• Generalizing Dynamic Systems: NODEs model a general ODE system \cite{XieWu2024,XieWu2023} which can be learned directly from training data without requiring human intervention or expertise in explicitly formulating mathematical equations \cite{XieWu2024,XieWu2023}. This flexibility makes NODEs a potential candidate for a universal differential equation capable of modeling complex systems solely from observed data \cite{FronkPetzold2023}.
• Optimal Control Framework: The training of a neural network can be conceptualized as solving an optimal control problem on differential equations, where the network parameters act as a controller aimed at finding an optimal solution to minimize the loss function \cite{ZhuGuo2021,ZhuGuo2023}. The NODE framework naturally formulates this as an optimal control problem on ODEs, leveraging established theories like the calculus of variations \cite{ZhuGuo2021,ZhuGuo2023}.
#############################
Structured reporting 
 
 
 1. Enhanced Quality and Standardization
Structured reporting inherently leads to higher quality and more reliable clinical documentation:
• Improved Quality and Clarity SR improves report quality, clarity, and standardization \cite{JorgHalfmann2023,WonickiLaqua2024}. Studies show that structured reports are consistently rated better than free-text reports by both radiologists and referring physicians across various attributes, including clarity and completeness \cite{JorgHalfmann2023}.
• Completeness and Detail SR ensures that all relevant clinical information is systematically documented \cite{GuptaMalhotra2024}. They lead to more detailed content \cite{JorgHalfmann2023} and often include more key features, such as those necessary for accurate pancreatic cancer staging \cite{SacoranskyKwan2024,JorgHalfmann2023}.
• Reduced Errors and Variability SR is shown to reduce reporting errors \cite{BuschHoffmann2024,YousefiriziDecazes2021} and decrease inter-reporter variability \cite{SacoranskyKwan2024}. The use of consistent, standardized terminology is emphasised as a way to improve overall report quality \cite{WonickiLaqua2024,BuschHoffmann2024}.
• Compliance with Guidelines SR enhances comprehensiveness and improves compliance with national guidelines \cite{BuschHoffmann2024,SacoranskyKwan2024}. The systematic nature of SR also promotes adherence to specialized classification systems, such as the Liver Imaging Reporting and Data System (LI-RADS) \cite{WuWu2023,DazGonzlezForner2024}.
2. Improved Efficiency and Workflow
SR streamlines the reporting process for radiologists and enhances efficiency for subsequent clinical reviews:
• Time and Resource Savings SR offers the potential to save radiologists valuable time \cite{GuptaMalhotra2024,SacoranskyKwan2024} and optimize healthcare resources \cite{SacoranskyKwan2024}. The shift from unstructured data into structured templates can be accelerated using AI, further boosting reporting efficiency \cite{SacoranskyKwan2024,HartsockAraujo2024}.
• Faster Information Retrieval The organized structure makes it intuitive and predictable for readers to quickly locate necessary information \cite{HartsockAraujo2024}. This facilitates the faster identification of critical findings by referring physicians \cite{HartsockAraujo2024}.
• Reduced Interpretation Time Structured reporting reduces interpretation time, as demonstrated in studies concerning multiple sclerosis reports \cite{SacoranskyKwan2024}.
• Consistency Processing reports into a structured format can lead to improved consistency in report length, with decreased standard deviations observed after conversion \cite{HartsockAraujo2024}.
3. Better Clinical Decision-Making and Communication
Structured reporting improves how findings are communicated and acted upon:
• Enhanced Communication SR improves communication of diagnostic findings \cite{WonickiLaqua2024,BuschHoffmann2024} between radiologists and referring physicians \cite{JorgHalfmann2023,HartsockAraujo2024}. Referring physicians generally report higher satisfaction with structured reports compared to free-text reports \cite{JorgHalfmann2023}.
• Facilitates Decision Support SR improves the utility of reports for clinical decision-making and patient care \cite{SacoranskyKwan2024}. It facilitates clinical decision-making \cite{JorgHalfmann2023} and guides treatment planning \cite{GuptaMalhotra2024}. In oncology, SR aids in accurate staging, surgical planning \cite{SacoranskyKwan2024,GuptaMalhotra2024}, and follow-up (e.g., using NI-RADS in head and neck cancer) \cite{GuptaMalhotra2024}.
• Specialty Optimization Reports can be optimized according to the specialty of the clinician receiving them (e.g., generating specific details on lesion margins for a surgeon), increasing efficiency for the care team \cite{MoawadFuentes2022}.
• Training Tool The clarity and precision provided by structured reports can serve as valuable training tools for radiology residents \cite{HartsockAraujo2024}.
4. Data Utilization for Research and AI
Structured data are highly valuable for secondary uses, such as research and the training of artificial intelligence (AI) models:
• Data Acquisition and Mining SR enables the automated acquisition of large quantities of structured data \cite{JorgHalfmann2023} and facilitates the secondary use of data \cite{JorgHalfmann2023}. It offers enormous potential for data mining \cite{GuptaMalhotra2024,BuschHoffmann2024} and harmonizing data across different healthcare systems \cite{BuschHoffmann2024}.
• AI Training and Validation Structured data support research by simplifying the process of extracting well-organized labels for AI models \cite{WonickiLaqua2024}. They are crucial for ensuring consistent quality and reproducibility of reporting when findings are used in research and clinical trials \cite{ArtibaniPorcaro2017}.
• Advanced Analytics Structured data allows for the automated creation of analytical tools, such as developing new disease-scoring systems or performing epidemiological research \cite{JorgHalfmann2023}.
• Information Extraction Even when radiologists use FTR, extracting structured information using tools allows existing databases of unstructured reports to be used for clinical research without losing diagnostic details \cite{ReichenpfaderKnupp2024}.
Overall, structured reports enhance accuracy and standardization \cite{SacoranskyKwan2024} while improving the flow of information for diagnostic accuracy and influencing clinical decisions and treatments \cite{SacoranskyKwan2024}.



############### 
metrics for counterfactuals 

The quality of counterfactuals is evaluated using a wide array of metrics, often categorized by the aspect of quality they measure, such as adherence to causal axioms, fidelity to the original input (minimality/proximity), realism, and efficacy in achieving the desired outcome (validity) \cite{KomanduriWu2023,VigneshwaranOhara2024}.
Here is a comprehensive breakdown of metrics for evaluating the quality of counterfactuals, particularly in the context of deep learning and imaging:
I. Axiomatic Soundness Metrics
A theoretically grounded framework for evaluating counterfactual image models relies on Pearl’s axiomatic definition of counterfactuals, which includes properties that must hold true in all causal models: composition, reversibility, and effectiveness \cite{KomanduriWu2023,MonteiroRibeiro2023}.
1. Effectiveness: This assesses how well the generated counterfactual obeys the intervention \cite{MonteiroRibeiro2023,RibeiroXia2023}. It measures whether intervening on a variable causes that variable to take on the specified counterfactual value \cite{RibeiroXia2023,MonteiroRibeiro2023}.
    ◦ Effectiveness is often quantified by training separate machine learning models, referred to as 'pseudo-oracles' or attribute predictors, on real data to measure how accurately they predict the intervened attribute's value from the generated counterfactual image \cite{RibeiroXia2023,MonteiroRibeiro2023}.
    ◦ For categorical variables, accuracy or AUROC is used, while for continuous variables, $\ell_1$ distance or Mean Absolute Error (MAE) might be employed \cite{MonteiroRibeiro2023,RibeiroXia2023}.
2. Composition: This ensures that performing a null intervention (an intervention where the variable takes a value it would have had anyway) does not affect the other variables in the system \cite{MonteiroRibeiro2023,RibeiroXia2023}.
    ◦ It is measured by calculating the distance (e.g., $L_1$ distance) between the original observation and the result of a null transformation (trivial intervention) \cite{RibeiroXia2023,MonteiroRibeiro2023}. In the context of generative models, this can be understood as assessing the distortion induced by the mechanism upon null-interventions \cite{RibeiroXia2023}.
3. Reversibility: This property relates to cycle-consistency, stating that if the underlying mechanism is invertible, cycling back from the counterfactual image to the original observation through abduction and re-prediction should recover the original observation \cite{MonteiroRibeiro2023,RibeiroXia2023}.
    ◦ Reversibility is measured by calculating the distance between the original observation and the observation recovered after one or more intervention cycles \cite{MonteiroRibeiro2023,KomanduriWu2023}.
II. Efficacy and Validity Metrics
These measure whether the counterfactual successfully achieves the desired predictive outcome, such as flipping a classification decision.
1. Counterfactual Validity (CV) Score or Success Rate (SR): This measures the fraction of counterfactual explanations that successfully flipped the classification decision \cite{SinglaEslami2021,Singla2022}.
    ◦ A high CV score is desired \cite{Singla2022,ThiagarajanThopalli2022}. If the classification decision does not flip, the explanation is inconclusive \cite{Singla2022}.
    ◦ The CV score is often calculated as the fraction of generated counterfactuals whose predicted outcome is opposite to the original input image's prediction \cite{Singla2022,SinglaEslami2021}.
2. Confidence: For categorical outcomes, this measures the confidence (e.g., softmax probability) of the model assigning the desired target class to the counterfactual image \cite{ThiagarajanThopalli2022}.
3. Average Treatment Effect (ATE): Used to quantify the total change in the classification outcome (or other variable) resulting from the counterfactual perturbation \cite{Singla2022,Hambarde2023}.
III. Visual Quality and Realism Metrics
These metrics quantify how realistic and plausible the generated counterfactuals are visually \cite{VigneshwaranOhara2024,Singla2022}.
1. Fréchet Inception Distance (FID) Score: This quantifies the visual similarity between the real images and the synthetic counterfactuals by computing the distance between their activation distributions in a pre-trained neural network feature space \cite{VigneshwaranOhara2024,Singla2022}.
    ◦ An ideal counterfactual explanation has a low FID score \cite{Singla2022}.
2. Structural Similarity Index Metric (SSIM): Used to evaluate the structural similarity between the original image and the counterfactual image, sometimes used alongside FID and MMD \cite{LiShi2023,MoroSantinha2024}.
3. Maximum Mean Discrepancy (MMD): Assesses the divergence between the distribution of synthesized images and real images; lower MMD indicates more realistic simulations \cite{LiLi2024,MoroSantinha2024}.
4. Learned Perceptual Image Patch Similarity (LPIPS): Used to evaluate image quality and fidelity, comparing the generated counterfactuals to real images; lower LPIPS values indicate higher quality \cite{RossiLopez2024}.
5. Realism Score: A high realism score indicates that the generated image is close to the true data manifold \cite{ThiagarajanThopalli2022}.
IV. Minimality and Proximity Metrics
These metrics quantify how small the change is between the factual image and the counterfactual image, reflecting the preference for minimal and sparse perturbations \cite{GuoDeng2024}.
1. Counterfactual Latent Divergence (CLD): This metric estimates the minimality and proximity of counterfactual samples in a latent space \cite{KomanduriWu2023,SanchezTsaftaris2022}.
    ◦ CLD measures the distance between the observation and the generated counterfactual relative to distances between the factual observation and samples from the counterfactual and factual classes \cite{SanchezTsaftaris2022}. A lower CLD value is better \cite{SanchezTsaftaris2022}.
2. Sparsity: Computed as the ratio of the number of pixels altered to the total number of pixels \cite{ThiagarajanThopalli2022}. Sparser changes are generally preferred as they are more likely to preserve the inherent characteristics of the query image \cite{ThiagarajanThopalli2022}.
3. Proximity: Measures the average $\ell_2$ distance of a counterfactual to its $K$-nearest training samples in the latent space \cite{ThiagarajanThopalli2022}. A lower proximity score is better \cite{ThiagarajanThopalli2022}.
4. Vertex Euclidean Distance (VED): Used in the context of shape models to quantify generalization ability by measuring the distance between an input mesh and its reconstruction \cite{RasalCastro2022}. Reconstruction VEDs can also indicate the quality of generated counterfactuals, which should preserve vertex-level details \cite{RasalCastro2022}.
V. Domain-Specific and Clinical Metrics
In domains like medical imaging, customized metrics are used to ensure the generated counterfactuals are clinically relevant and meaningful \cite{SinglaEslami2021,Singla2022}.
1. Clinical Metrics: Quantitative metrics based on clinical definitions of diseases are used to quantify statistical differences between real and corresponding counterfactual images \cite{SinglaEslami2021,Singla2022}. Examples include:
    ◦ Cardio Thoracic Ratio (CTR) for cardiomegaly \cite{SinglaEslami2021,Singla2022}.
    ◦ Score of normal Costophrenic recess (SCP) for pleural effusion \cite{SinglaEslami2021,Singla2022}.
2. Foreign Object Preservation (FOP) Score: Measures the fidelity of generated images by assessing the fraction of real images where foreign objects (e.g., pacemakers) successfully detected are also detected in the counterfactual explanation \cite{Singla2022,SinglaEslami2021}.
3. Intersection over Union (IoU): Used in methods that generate counterfactuals for segmentation tasks (e.g., counterfactual inpainting pipelines) to assess segmentation accuracy \cite{ShvetsovAriva2024}.
4. Counterfactual Medical Image Generation (CMIG) Score: A composite score that balances accuracy (how well the generated image reflects prescribed pathology changes, measured by AUC) and feature retention (how well invariant features like race and age are retained, measured by AUC or Pearson correlation) \cite{GuYang2023}.
5. Attribute Amplification Assessment: Evaluates whether intervening on one attribute (e.g., sex or race) spuriously affects an independent, unintervened attribute (e.g., disease status), violating the assumed causal graph \cite{XiaRoschewitz2024}. This is measured using the attribute predictor's performance (e.g., AUC) on unintervened attributes when evaluating counterfactuals \cite{XiaRoschewitz2024}.
VI. Human Evaluation Metrics
Human-grounded experiments are critical for evaluating interpretability, usability, and perceived quality \cite{SinglaEslami2021,Singla2022}.
1. Understandability: Measures how well the user understood the classifier’s decision when presented with the counterfactual explanation \cite{SinglaEslami2021,Singla2022}.
2. Classifier’s Decision Justification: Assesses whether the explanation provided good evidence supporting the classifier's decision \cite{SinglaEslami2021,Singla2022}.
3. Visual Quality (Perceived): Subjective evaluation of how visually similar the counterfactuals look to the query image \cite{SinglaEslami2021,Singla2022}.
4. Identity Preservation: Evaluates whether the core identity or style of the original subject/image is maintained in the counterfactual \cite{SinglaEslami2021,Singla2022}.
5. Overall Helpfulness/Utility: Measures the perceived usefulness of the explanation to the user \cite{SinglaEslami2021,Singla2022}.
VII. Identifiability and Error Bounds
Since counterfactual identifiability can be impossible in the general case, estimating prediction errors serves as a practical quality metric \cite{NasrEsfahanyKiciman2023,MonteiroRibeiro2023}.
• Worst-Case Errors/Error Bounds: A practical approach involves calculating different error metrics to quantify the counterfactual ambiguity of learned generation mechanisms \cite{NasrEsfahanyKiciman2023}. The size of this error can be a critical metric for practitioners to decide if a DSCM approach is viable for their specific problem \cite{NasrEsfahanyKiciman2023}.
The evaluation metrics generally fall into several distinct categories based on the properties they assess: Realism and Quality (Data Consistency), Effectiveness and Validity (Classifier Consistency), Minimality and Proximity, Identity Preservation, Causal Axiomatic Soundness, and Clinical Relevance.
1. Realism and Image Quality Metrics (Data Consistency/Plausibility)
These metrics assess whether the generated counterfactual instance (CI) is visually plausible, realistic-looking, and lies close to the original data manifold \cite{ThiagarajanNarayanaswamy2021,Singla2022}.
Metric
Definition and Calculation
Purpose and Context
Fréchet Inception Distance (FID) Score
Quantifies the visual similarity between real images ($X$) and synthetic counterfactuals ($X_c$) \cite{SinglaEslami2021,Singla2022}. It calculates the distance between the mean ($\mu$) and covariance ($\Sigma$) of activation distributions derived from the penultimate layer of a pre-trained Inception v3 network \cite{SinglaEslami2021,MelistasSpyrou2024}. A lower FID indicates higher realism and closer semantic similarity to the original data distribution \cite{SinglaEslami2021,Singla2022}.
Essential for assessing the visual quality and realism of generated images \cite{Singla2022,CabitzaCampagner2019}. FID is generally considered the most reliable metric for Generative Adversarial Network (GAN) evaluation \cite{FerreiraLi2024}.
Structural Similarity Index Measure (SSIM) / Multi-scale SSIM (MS-SSIM)
Evaluates image quality by considering changes in luminance, contrast, and structural information, often correlating better with human visual perception than pixel-level metrics \cite{FerreiraLi2024,FolcoBercea2023}. MS-SSIM is a metric used to indicate the realism and diversity of synthetic images \cite{DhinagarThomopoulos2024}.
Used to assess subject-specific faithfulness (high structural similarity to the input image) \cite{KumarHu2022} and reconstruction quality \cite{FolcoBercea2023,igutytLenz2024}. A higher SSIM is desired for valid counterfactuals \cite{KumarHu2022,KumarFathi2023}.
Learned Perceptual Image Patch Similarity (LPIPS)
Quantifies perceptual similarity by measuring the distance between feature representations extracted by a pre-trained network (e.g., VGG-16) \cite{FolcoBercea2023,MelistasSpyrou2024}. It is used to address limitations of PSNR/SSIM which may not fully capture nuances of human perception \cite{FolcoBercea2023}.
Lower LPIPS values indicate higher quality and closer perceptual similarity to real images \cite{RossiLopez2024}. It is also used in measuring composition (null-intervention consistency) \cite{MelistasSpyrou2024}.
Peak Signal-to-Noise Ratio (PSNR)
A pixel-level metric measuring the difference between generated and original images based on signal noise \cite{FerreiraLi2024,FolcoBercea2023}.
Used to objectively evaluate reconstruction quality and fidelity \cite{FerreiraLi2024,FolcoBercea2023}.
Root Mean Squared Error (RMSE)
A pixel-level metric gauging the average differences between image pixels \cite{YoonLee2024}. Also used to evaluate the accuracy of counterfactual simulations over time (e.g., Mean Squared Error (MSE)) \cite{LiShahn2020,Purohit2023}.
Used in time-series analysis for evaluating accuracy and calibration of counterfactual trajectories \cite{LiShahn2020}.
Non-Resemblance Measure
Measures the non-resemblance between a tumorous input image and the generated normal counterfactual instance (CI), typically computed separately for tumorous and normal regions using ground truth segmentation \cite{ZiaNisar2023}.
Used specifically for medical image analysis (e.g., BraTS dataset) to evaluate CI quality when generating healthy counterparts \cite{ZiaNisar2023}.
2. Effectiveness and Validity Metrics (Classifier Consistency)
These metrics ensure that the generated counterfactual successfully achieves the desired objective, typically flipping the predictive model's classification decision, thereby ensuring functional or classifier consistency \cite{Singla2022}.
Metric
Definition and Calculation
Purpose and Context
Counterfactual Validity (CV) Score / Flip Ratio (FR)
The fraction of counterfactual explanations that successfully flip the classification decision compared to the query image \cite{SinglaEslami2021,Singla2022}. The decision flip is considered successful if the difference in predictions $
f(X) - f(X_{cf})
Effectiveness (Axiomatic)
Determines if the intervention was successful by checking if the intervened variable takes on the target value \cite{MelistasSpyrou2024,RibeiroXia2023}. Quantitatively evaluated using anti-causal predictors (separate classifiers/regressors trained on real data) which predict the value of the intervened variable based on the counterfactual image \cite{VigneshwaranOhara2024,MelistasSpyrou2024}.
Measures the success of the causal intervention in altering the target attribute in the image \cite{VigneshwaranOhara2024,XiaRoschewitz2024}.
Counterfactual Prediction Gain (CPG)
Measures the magnitude of change in the classifier’s decision, defined as $
f(x) - f(x_{cf})
Bounded Remapping of KL Divergence (BKL)
Measures the similarity between the counterfactual’s prediction and the desired one-hot target label \cite{WengPegios2023,PegiosLin2024}.
Used to confirm that the counterfactual sample maximizes the probability of the target class \cite{PegiosLin2024,WengPegios2023}.
Mean Absolute Difference (MAD) / Mean Confidence Difference (MD)
Measures the difference in confidence prediction between the original image and the counterfactual image \cite{WengPegios2023}.
Used to quantify the strength of the shortcut learning effect resulting from counterfactually flipping a shortcut feature \cite{WengPegios2023}.
Confidence
For categorical targets, this is the softmax probability $P(\bar{y}_i
\bar{x}_i; F)$ of assigning the desired class $\bar{y}_i$ for a counterfactual $\bar{x}_i$ \cite{CabitzaCampagner2019}.
3. Minimality, Proximity, and Sparsity Metrics (Achievability)
These metrics ensure that the counterfactual perturbation is small, minimal, and close to the original input, making the changes interpretable and actionable \cite{ChouMoreira2021,YeganehFarshad2024}.
Metric
Definition and Calculation
Purpose and Context
Proximity
Measures the distance between the original input ($x$) and the generated counterfactual ($x'$) \cite{ChouMoreira2021,ZhouIslam2023}. Commonly measured using Euclidean distance \cite{ZhouIslam2023,DombrowskiGerken2022} or the $\ell 592]. It can also be the ratio of altered pixels to total pixels \cite{CabitzaCampagner2019}.
Focuses on generating the minimum necessary changes for interpretability \cite{ChouMoreira2021,ZhouIslam2023}. Lower sparsity is generally preferred \cite{ZhouIslam2023,Bedelukur2023}.
Actionability (L1 distance)
Defined as the expected $L_1$ distance between the factual and counterfactual images, $E[|x - x_{cf}|_{L1}]$ \cite{KumarFathi2023,WengPegios2023}.
A lower value indicates minimal changes have been made to the original image \cite{KumarFathi2023,WengPegios2023}.
Counterfactual Latent Divergence (CLD)
Calculates the "distance" between the factual and counterfactual images in a latent space, aiming for a counterfactual sufficiently distant from the factual class prediction but not arbitrarily far from the data manifold \cite{MelistasSpyrou2024}.
Assesses minimality by evaluating proximity in latent space while respecting classifier separation \cite{MelistasSpyrou2024}.
4. Identity Preservation and Context Preservation Metrics
These metrics confirm that essential, often immutable, characteristics of the input subject or context are preserved during the modification process.
Metric
Definition and Calculation
Purpose and Context
Foreign Object Preservation (FOP) Score
The fraction of real images where a foreign object (FO) was successfully detected, in which the FO was also detected in the corresponding counterfactual explanation \cite{SinglaEslami2021,Singla2022}.
Used specifically in medical imaging (e.g., chest X-rays) to ensure that clinically irrelevant features or objects (like foreign devices) are not erroneously changed by the counterfactual process \cite{Singla2022,SinglaEslami2021}.
Face Verification Accuracy (FVA) / Face Similarity (FS)
Metrics used to measure whether a counterfactual changed the face identity \cite{WengPegios2023,Singla2022}.
Relevant when identity preservation is a crucial requirement, such as in face image counterfactual generation \cite{WengPegios2023,Singla2022}.
Composition (Axiomatic)
Guarantees that the image and its attributes do not change when performing a null-intervention (i.e., intervening on a variable to have the value it would have had without intervention) \cite{MelistasSpyrou2024,RibeiroXia2023}. Measured via the distortion induced by repeated null-interventions \cite{MelistasSpyrou2024,RibeiroXia2023}.
Confirms the fidelity of the generative mechanism in preserving information when no meaningful change is introduced \cite{MelistasSpyrou2024,RibeiroXia2023}.
5. Causal and Domain-Specific Metrics
These specialized metrics are essential when evaluating counterfactuals generated under a causal framework or in high-stakes domains like medicine, where domain expertise is critical.
Metric
Definition and Calculation
Purpose and Context
Spurious Correlation Latching Score (SCLS)
Defined as $
d(x) - d(x_{cf})
Clinical Quantitative Metrics
Metrics defined based on clinical relevance to quantify changes between normal and abnormal populations identified by the classifier \cite{SinglaEslami2021,Singla2022}. Examples include Cardiothoracic Ratio (CTR) for cardiomegaly and the Score for detecting a normal Costophrenic recess (SCP) for pleural effusion \cite{SinglaEslami2021,Singla2022}.
Verifies that the change in classification decision is associated with a corresponding change in clinically relevant metrics, assuring the classifier uses clinically sound information \cite{Singla2022}.
Clinical Assessment/Human Evaluation
Qualitative assessment by domain experts (e.g., radiologists or pathologists) rating generated counterfactuals based on criteria like realism, fidelity, adherence to desired pathological change, and whether indirect pathological changes are modeled accurately \cite{AtadDmytrenko2022,IlanchezianBoreiko2023}.
Overcomes limitations of purely quantitative metrics, providing validation that aligns with human intuition and medical expertise \cite{AlayaLang2024,YoonLee2024}.
Pathology Classifier AUC / Feature Retention Metrics
Used in multimodal systems (e.g., image-report) to calculate the geometric mean of accuracy measurements (e.g., pathology AUC) and feature retention measurements (e.g., race AUC, age Pearson correlation) \cite{GuYang2023}.
Provides a balanced score (e.g., Counterfactual Medical Image Generation, CMIG score) reflecting both pathological fidelity and retention of invariant features \cite{GuYang2023}.
Axiomatic Soundness Metrics
Based on the mathematical formulation of Structural Causal Models (SCMs), assessing properties like Effectiveness, Composition, and Reversibility \cite{MelistasSpyrou2024,RibeiroXia2023}.
Ensures the generated counterfactuals adhere to fundamental causal principles \cite{MelistasSpyrou2024,RibeiroXia2023}.
QuAC Score
Calculates the area under the curve representing the change in classifier output as a function of the normalized size of the binary mask highlighting important changes \cite{AdjavonEckstein2024}.
Used to rank the informativeness of features by quantifying the effect of minimal changes on the classifier's decision \cite{AdjavonEckstein2024}.
6. Temporal and Trajectory Evaluation Metrics
For counterfactual inference involving time-varying treatments or outcomes (e.g., patient outcome trajectories), specific metrics are used to evaluate the accuracy of prediction and policy effectiveness \cite{LiShahn2020}.
Metric
Definition and Calculation
Purpose and Context
Mean Squared Error (MSE)
Used to evaluate the accuracy and calibration of counterfactual simulations or outcomes generated by models \cite{LiShahn2020,Purohit2023}.
Assesses the prediction accuracy of counterfactual outcome trajectories ${E[Y_t(\bar{A}_{m-1}, g^m)
Precision in Estimation of Heterogeneous Effect (PEHE)
Conventionally used for evaluating Conditional Average Treatment Effect (CATE) predictions \cite{VollenweiderSchrch2024}.
Measures the precision of estimated individualized treatment effects \cite{VollenweiderSchrch2024}.
Assignment Precision (Prec $\pi_{Ass}$)
Measures the ratio of treatment options proposed correctly by a policy $\pi$ \cite{VollenweiderSchrch2024}.
Evaluates whether the predicted optimal treatment leads to a higher outcome than the alternative \cite{VollenweiderSchrch2024}.
CF RMSE
Root Mean Squared Error specifically for counterfactual outcomes \cite{VollenweiderSchrch2024}.
Evaluates how accurately outcomes were predicted for alternative treatment options \cite{VollenweiderSchrch2024}.
Mean Distance and 1-Wasserstein Distance
Used to measure discrepancies between the approximated and true counterfactual distributions \cite{WuZhou2024}.
Assesses the quality of the generative model in capturing the full counterfactual distribution, which is particularly useful for high-dimensional outcomes \cite{WuZhou2024}.

###########################
jump 

The combination of a Neural Ordinary Differential Equation (NODE), often referred to as a "classic node" due to its foundational role, and a "jump node" mechanism (such as the Neural Jump Differential Equation framework) is specifically designed to model systems that exhibit both continuous evolution and rapid, discrete changes \cite{GwakSim2020}. This hybrid approach is highly relevant for scenarios like disease progression (continuous evolution) interrupted by medical interventions (rapid changes like surgery or drug administration).
1. The Role of the Classic NODE (Continuous Evolution)
The foundation of this modelling paradigm is the Neural Ordinary Differential Equation (NODE) \cite{BergHasenclever2018}.
• NODEs model continuous transformations of a state (or hidden representation, $h$) by parameterising the derivative of the hidden state using a neural network, treating the system evolution as the solution to an Initial Value Problem (IVP) \cite{BergHasenclever2018,CuchieroLarsson2019}. $$\frac{dh(t)}{dt} = f_{\theta}(h(t), t)$$ \cite{BergHasenclever2018,WuJiahao2021}
• NODEs are inherently continuous-time models \cite{BergHasenclever2018,LaiLiu2022}, which makes them a natural framework for modelling system dynamics over a continuous time domain \cite{GwakSim2020,KanaaVoleti2021}.
• In the context of disease, NODEs are used to model the smooth, continuous disease progression (e.g., Alzheimer’s disease or tumour growth) between observations \cite{ZeghlacheConze2024,BahdanauCho2014}. For instance, one model uses a system of ODEs to jointly model the rate of change of an individual's biomarkers and cognitive tests in Alzheimer's disease \cite{BossaSahli2023,MulyadiJung2022}.
2. Incorporating Rapid Changes via Jumps
To account for rapid, discrete events like surgery or administering medication, the continuous NODE dynamics must be interrupted by a jump mechanism. This approach is generally formalized as a Neural Jump Differential Equation (NJDE) \cite{GwakSim2020}.
• The NJDE framework describes the system state ($h$) as evolving according to continuous dynamics ($\dot{h} = f_{\theta}(t, h(t))$) between time points ($t \neq t_k$), but undergoing a discrete jump ($h^+$) at specific observation times ($t_k$) \cite{GwakSim2020}.
• This hybrid dynamic is expressed mathematically as an impulsive differential equation \cite{GwakSim2020}: $$\dot{h} = f_{\theta}(t, h(t)) \quad \text{for } t \neq t_k$$ $$h^+ = g_{\phi}(h(t), x_k) \quad \text{for } t = t_k$$ \cite{GwakSim2020} where $h^+$ is the value after the discrete jump, determined by a function $g_{\phi}$ (often a neural network or RNN cell) based on the current state and the new observation $x_k$ \cite{GwakSim2020}.
3. Specific Architectures for Combining NODE and Jumps
Several architectures leverage the continuous nature of NODE combined with discrete updates ("jumps"):
ODE-RNN/GRU-ODE-Bayes
• Models like ODE-RNN and GRU-ODE-Bayes combine NODEs with Recurrent Neural Networks (RNNs) to handle irregularly observed time series \cite{CuchieroLarsson2019,AbushaqraXue2022}.
• The Neural ODE models the continuous evolution of the hidden state between two observations \cite{CuchieroLarsson2019}.
• The RNN cell (or GRU cell) is applied at the time of a new observation ($t_{i+1}$), causing the hidden state to jump to a new value \cite{CuchieroLarsson2019,AbushaqraXue2022}. The sequence is computed by iteratively solving an ODE followed by applying an RNN \cite{CuchieroLarsson2019}.
• This process results in a càdlàg process, meaning the state evolves continuously but experiences jumps at the observation times \cite{CuchieroLarsson2019,HerreraKrach2020}.
Neural Jump ODE (NJ-ODE)
• The Neural Jump ODE (NJ-ODE) framework, similar to ODE-RNN/GRU-ODE-Bayes, models the continuous conditional expectation of a stochastic process using a Neural ODE between observations \cite{CuchieroLarsson2019}.
• When a new observation is made, the hidden state instantaneously jumps \cite{CuchieroLarsson2019}.
• In the NJ-ODE architecture, the traditional RNN cell update (which incorporates history) is replaced by a simpler feed-forward network, called jumpNN, which defines the new hidden state solely from the current observation (assuming a Markovian process) \cite{CuchieroLarsson2019}. This architecture models the continuous part with a neural ODE ($f_{\theta}$) and the jump part with the jumpNN \cite{CuchieroLarsson2019}.
4. Modelling Interventions (Disease Progression and Surgery)
While standard ODE-RNN or NJDE models can handle general observations that perturb the continuous dynamics, systems involving external interventions (such as surgery, radiation, or drug dosing) often require a more sophisticated mechanism, as they need to separate the effect of passive observations from external forces \cite{GwakSim2020}.
The Intervention Modeling ODE (IMODE) framework is specifically designed to accommodate various types of intervention effects \cite{GwakSim2020}.
• IMODE separates the system state into multiple latent components to distinguish between autonomous dynamics (continuous disease progression) and intervention effects (rapid changes/surgery) \cite{GwakSim2020}.
• The latent state is broken down into:
    ◦ $z_x$: The autonomous latent state (representing the disease's natural course/evolution).
    ◦ $z_a$: The intervention effect latent state (representing the rapid, external change, like surgery) \cite{GwakSim2020}.
    ◦ $h$: The main latent state, which evolves continuously based on both $z_x$ and $z_a$ \cite{GwakSim2020}.
In this framework, the dynamics are structured as follows \cite{GwakSim2020}:
1. Continuous Dynamics (Disease Progression): The main state $\dot{h}$ evolves continuously, often as a function of $h$, $z_x$, and $z_a$. Additionally, $z_x$ and $z_a$ may have their own continuous flows ($\dot{z}_x$ and $\dot{z}_a$) \cite{GwakSim2020}. This part models the slow, continuous disease progression.
2. Discrete Jumps (Surgery/Intervention): When an observation or intervention occurs at time $t_k$, the autonomous and intervention latent states undergo discrete jumps, $z_x^+$ and $z_a^+$, determined by specific jump functions ($g_{x\theta}$ and $g_{a\phi}$) \cite{GwakSim2020}. This models the rapid, instantaneous change caused by, for example, a surgical procedure or drug administration.
    ◦ For external interventions, the jump function $g_{a\phi}$ is explicitly triggered \cite{GwakSim2020}.
    ◦ For a switching intervention effect (analogous to a major event like surgery that permanently alters the course), the intervention effect $z_a$ abruptly changes based on the event, and this effect remains constant until the next intervention \cite{GwakSim2020}.
    ◦ For a decaying intervention effect (analogous to medication whose effect wears off), the intervention latent state $z_a$ is modelled with a negative continuous flow ($\dot{z}_a = - \alpha z_a$), meaning it jumps up at administration (the rapid change) and then continuously decays (the lasting but fading evolution) \cite{GwakSim2020}.
By employing the NODE principle for continuous time evolution and the jump mechanism (via specialized jump functions) for discrete events, models like IMODE can effectively separate the slow, continuous progression of a disease from the rapid, external impacts of clinical interventions \cite{GwakSim2020}.
######
vae for uncertanity quantification 

Step 1: Understanding the VAE Encoder and Latent Representation
A VAE consists of an encoder ($E_\phi$) and a decoder ($D_\theta$) \cite{FriedrichFrisch2024,AbbasiMonadjemi2018}. The encoder maps an input datum $x$ (e.g., a 3D medical image) into a latent representation $Z$ \cite{FriedrichFrisch2024}.
1. Probabilistic Encoding: Instead of mapping the input $x$ to a single point $z$, the encoder in a VAE maps $x$ to the parameters of a conditional probability distribution, $q_\phi(Z|x)$, which approximates the true posterior distribution $p(Z|X)$ \cite{AbbasiMonadjemi2018,GautierBousse2024}. Typically, $q_\phi(Z|x)$ is assumed to be a multivariate Gaussian distribution defined by a mean vector $\mu = E_\mu(x)$ and a variance vector $\sigma^2 = E_\sigma(x)$ \cite{FriedrichFrisch2024,GautierBousse2024}.
2. Latent Space Regularization: The VAE is trained by minimizing a combined loss function that maximizes the Evidence Lower Bound (ELBO) on the log-likelihood of the data \cite{FriedrichFrisch2024,GautierBousse2024}. This loss includes a regularization term, the Kullback-Leibler (KL) divergence, which forces the encoded latent distribution $q_\phi(Z|x)$ to be close to a predefined prior distribution $p(Z)$ (usually a standard normal distribution $\mathcal{N}(0, I)$) \cite{FriedrichFrisch2024,GautierBousse2024}.
3. Impact on UQ: The resultant latent space $Z$ has desirable properties, such as continuity (nearby points decode to similar images) and completeness (a random point drawn from the latent space yields a plausible result) \cite{GautierBousse2024}. Crucially, the encoded variance ($\sigma^2$) captures the model’s uncertainty regarding the compressed representation of the input sample \cite{FriedrichFrisch2024}.
Step 2: Utilizing VAEs for Uncertainty Quantification via Latent Space Sampling (Method a)
Method (a) involves leveraging the probabilistic definition of the latent space to perform Monte Carlo-style sampling, enabling the estimation of epistemic uncertainty—the uncertainty related to the model's knowledge or representation \cite{BustinMeyer2025}.
1. Encoding the Input: Given an input image $X$, the VAE encoder computes the mean $\mu$ and variance $\sigma^2$ defining the approximate posterior $q_\phi(Z|X)$ \cite{FriedrichFrisch2024}.
2. Reparameterization Trick and Sampling: To sample a latent vector $z$ while maintaining differentiability for training, the reparameterization trick is used: $z = \mu + \sigma \odot \epsilon$, where $\epsilon \sim \mathcal{N}(0, I)$ \cite{FriedrichFrisch2024,AbbasiMonadjemi2018}. For uncertainty estimation, this sampling procedure is performed multiple times for the fixed input $X$, yielding a set of related but distinct latent vectors ${z_1, z_2, \dots, z_N}$.
3. Generating Multiple Outputs: Each sampled latent vector $z_i$ is then either fed directly into the downstream task model (if it operates on latent features) or passed through the VAE decoder $D_\theta$ to reconstruct slightly varied images ${X'_1, X'_2, \dots, X'_N}$ \cite{LiuSanchez2022,FriedrichFrisch2024}.
4. Uncertainty Quantification: These multiple outputs or predictions ${Y_1, Y_2, \dots, Y_N}$ corresponding to the set of latent samples ${z_i}$ quantify the uncertainty. The dispersion (e.g., standard deviation or variance) across these predictions reflects the epistemic uncertainty inherent in the model's latent representation of the input. This method is analogous to Monte Carlo Dropout or Deep Ensembles in calculating uncertainty \cite{BustinMeyer2025}.
Step 3: Utilizing Latent Variance Features for Uncertainty Quantification (Method b)
Method (b) focuses on directly utilizing the variance or standard deviation parameters ($\sigma^2$ or $\sigma$) generated by the VAE encoder as inherent indicators of representation uncertainty.
1. Direct Variance Extraction: The VAE encoder explicitly calculates the predicted variance $\sigma^2$ (or log variance) for every dimension of the latent space \cite{FriedrichFrisch2024}. This variance represents the inherent spread or uncertainty the model associates with that feature, given the input image \cite{BustinMeyer2025}.
2. Variance as a Regularizer/Constraint: The KL divergence term in the VAE loss function, $L_{KL} = \beta D_{KL}(q_\phi(Z|X) || p(Z))$, acts as a regularization coefficient ($\beta$) that constrains the capacity of the latent information channel $Z$ \cite{PintonBousse2024}. High variance in a latent dimension suggests that this dimension is less constrained by the input data or less informative for reconstruction, effectively acting as noise or a measure of non-confidence by the encoder in that feature dimension.
3. Integrating Variance into Downstream Tasks: Instead of relying on empirical sampling, the variance metrics associated with the latent features can be explicitly incorporated into the downstream task calculation:
    ◦ Uncertainty Score: The magnitude of $\sigma^2$ for the combined latent vector $Z$ can be used directly as a proxy for the uncertainty in the representation feeding the downstream task.
    ◦ Weighted Processing: The downstream task (e.g., a classifier or regressor) can be designed to weight the importance of each latent feature $\mu_i$ inversely proportional to its associated variance $\sigma^2_i$. Features with higher variance are seen as less reliable.

The therapy involving Lutetium-177 Prostate-Specific Membrane Antigen-617 (${}^{177}\text{Lu-PSMA-617}$, also known as lutetium Lu 177 vipivotide tetraxetan or Pluvicto™) is considered revolutionary for metastatic castration-resistant prostate cancer (mCRPC) primarily due to its combination of targeted delivery, significant clinical efficacy (especially survival prolongation), and a favorable safety profile compared to traditional chemotherapy \cite{HennrichEder2022,ChandranFigg2022}.
Why Lutetium PSMA Therapy is Revolutionary
The success of ${}^{177}\text{Lu-PSMA-617}$ stems from its targeted approach to treating mCRPC:
1. Targeted Mechanism of Action:
    ◦ ${}^{177}\text{Lu-PSMA-617}$ is a small molecule radioligand therapy (RLT) designed to target the Prostate-Specific Membrane Antigen (PSMA) \cite{FizaziHerrmann2023,ChandranFigg2022}. PSMA is a transmembrane enzyme highly overexpressed on the surface of prostate cancer cells, often upregulated up to a thousand times more than normal tissue \cite{HennrichEder2022,LingBlois2022}.
    ◦ The compound links a PSMA-specific peptidomimetic (PSMA-617) to a therapeutic radionuclide, Lutetium-177 (${}^{177}\text{Lu}$) \cite{HennrichEder2022}.
    ◦ Upon binding to the PSMA receptor, ${}^{177}\text{Lu-PSMA-617}$ is internalized into the tumor cells, where the beta-minus emission from ${}^{177}\text{Lu}$ delivers ionizing radiation \cite{HennrichEder2022,Keam2022}.
    ◦ The ${}^{177}\text{Lu}$ radionuclide is a short-range beta-particle emitter (maximal range 2.2 mm, average range 0.67 mm), which limits radiation damage to nearby healthy tissue while enabling the particle to penetrate and kill several adjacent PSMA-positive cells \cite{HennrichEder2022,SadaghianiSheikhbahaei2022}. This targeted delivery is highly specific to the disease, minimizing damage to surrounding tissue compared to conventional chemotherapy \cite{HennrichEder2022}.
2. Demonstrated Survival Benefit and Efficacy:
    ◦ The Phase 3 VISION trial demonstrated a significant clinical breakthrough by being the first phase 3 trial to prove an overall survival (OS) benefit for ${}^{177}\text{Lu-PSMA-617}$ in post-chemotherapy mCRPC patients \cite{ChandranFigg2022,RamnaraignSartor2023}.
    ◦ In the VISION trial, ${}^{177}\text{Lu-PSMA-617}$ plus standard of care significantly prolonged overall survival (OS) (median 15.3 months vs 11.3 months) and radiographic progression-free survival (rPFS) (median 8.7 months vs 3.4 months) compared with standard of care alone \cite{TschanBorgna2022,HatanoNonomura2023}.
    ◦ In the Phase 2 TheraP trial, ${}^{177}\text{Lu-PSMA-617}$ demonstrated a substantially higher PSA response rate (PSA decline of $\ge 50\\\\%$) compared to cabazitaxel (66\\\\% vs 37\\\\%) \cite{HofmanEmmett2024,HatanoNonomura2023}. It also led to better progression-free survival and objective response rates than cabazitaxel \cite{HofmanEmmett2024,LingBlois2022}.
3. Favorable Safety and Tolerability:
    ◦ The therapy generally has a favorable safety profile and is well tolerated \cite{ChandranFigg2022,GeorgeSamuel2023}.
    ◦ In the TheraP trial, ${}^{177}\text{Lu-PSMA-617}$ was associated with fewer Grade 3 or 4 adverse events compared to cabazitaxel (33\\\\% vs 53\\\\%) \cite{HofmanEmmett2024,PatellKurian2023}.
    ◦ Common adverse reactions include fatigue, dry mouth, nausea, and hematological toxicities (anemia, thrombocytopenia, leukopenia) \cite{ChandranFigg2022,HennrichEder2022}. Crucially, significant treatment-related nephrotoxicity has been rare in large studies \cite{ChandranFigg2022,HartrampfWeinzierl2022}.
4. Regulatory Impact and Future Applications:
    ◦ The robust results of the VISION trial led to the FDA approval of ${}^{177}\text{Lu-PSMA-617}$ (Pluvicto™) in March 2022, solidifying its place as a standard of care for patients with heavily pretreated PSMA-positive mCRPC \cite{HennrichEder2022,JangKendi2023}.
    ◦ The success has generated intense research interest in evaluating its use in earlier lines of therapy (e.g., pre-chemotherapy mCRPC or metastatic hormone-sensitive prostate cancer) and in combination therapies \cite{HennrichEder2022,PatellKurian2023}.

--------------------------------------------------------------------------------
Explanation of Theranostics
Theranostics is a combined concept derived from combining "thera" (therapy) and "nostic" (diagnostic) \cite{HennrichEder2022}. This approach utilizes a similar molecule (a radioligand) for both imaging and targeted therapy, resulting in a personalized and highly specific treatment strategy \cite{GaagBartelink2022,HennrichEder2022}.
Key components of the theranostic concept include:
• Diagnostic Step (Imaging): The patient is initially imaged using a targeted radiopharmaceutical labeled with a diagnostic radionuclide (like a positron emitter for PET or gamma emitter for SPECT) \cite{HennrichEder2022}. This tracer (e.g., ${}^{68}\text{Ga-PSMA-11}$) binds specifically to the target structure (PSMA) to determine its distribution and accumulation in the tumor and metastases \cite{HennrichEder2022}.
• Personalized Selection: The initial diagnostic step is essential because it quantifies the PSMA expression in the tumor, ensuring that the patient is suitable to be treated with the corresponding therapeutic radiopharmaceutical \cite{HennrichEder2022,KaewputVinjamuri2022}. Patients whose tumors do not show sufficient uptake of the labeled biomarker (e.g., low PSMA expression or discordant lesions) are typically excluded, maximizing the likelihood of efficacy for treated patients \cite{HennrichEder2022,HofmanEmmett2024}.
• Therapeutic Step (Treatment): If the diagnostic scan confirms adequate PSMA expression, the patient proceeds to treatment using a corresponding radiotherapeutic tracer that has the same or a very similar chemical structure as the diagnostic tracer, but is labeled with a therapeutic radionuclide (like the beta emitter ${}^{177}\text{Lu}$ or the alpha emitter ${}^{225}\text{Ac}$) \cite{GaagBartelink2022,HennrichEder2022}.
• Monitoring: The patient can subsequently be imaged using a PET or SPECT tracer for therapy monitoring \cite{HennrichEder2022}. In the case of ${}^{177}\text{Lu}$, the radionuclide itself is considered an intrinsic theranostic radiometal because it emits both therapeutic beta particles and low-energy gamma rays, which can be used for SPECT imaging and dosimetry measurements post-injection \cite{HennrichEder2022,AlamSingh2022}.
The goal of the theranostic approach is to deliver ionizing radiation selectively to tumor cells while minimizing exposure to healthy tissue, allowing for better monitoring and individualized dosing \cite{GeorgeSamuel2023,HennrichEder2022}. ${}^{177}\text{Lu-PSMA-617}$ is a prominent example of a radiolabeled drug suitable for use within this theranostic framework for prostate cancer \cite{HennrichEder2022}.
########################

security 
The best way to secure a multimodal health AI application—which handles inputs and outputs involving both text (e.g., Electronic Health Records or EHRs) and images (e.g., medical scans)—requires a multi-layered, comprehensive security strategy that addresses AI-specific threats, ensures patient data privacy, and enforces strict regulatory compliance \cite{AlAttar2023,AlkanZakariyya2025}.
The integration of image diagnostics and clinical text analytics in AI models introduces complex vulnerabilities, as Convolutional Neural Networks (CNNs) are susceptible to image-based adversarial attacks \cite{AlAttar2023,GoodfellowShlens2014}, while models processing textual EHR data can also be manipulated \cite{ChangLiu2024}.
Here are the critical strategies for securing such a multimodal AI application, drawing from the provided sources:
1. Enhancing AI Model Robustness and Integrity
To defend the integrity and reliability of the machine learning models against malicious inputs (whether image or text) and training manipulations:
• Implement Adversarial Defense Mechanisms: Adopting defensive strategies significantly increases model resilience \cite{AlAttar2023,GoodfellowShlens2014}.
    ◦ Adversarial Training: This involves feeding adversarial examples into the model during the training phase. It is considered one of the most effective defenses against adversarial attacks, providing a considerable degree of recovery in model accuracy \cite{AlAttar2023,GoodfellowShlens2014}.
    ◦ Defensive Distillation: This technique increases model robustness and was specifically shown to increase adversarial accuracy, particularly for image-based diagnostic tasks handled by CNN models \cite{AlAttar2023}.
    ◦ Hybrid Defenses: Since no single defense technique is completely successful against all adversarial attacks, future efforts should focus on hybrid solutions, combining methods like adversarial training with feature squeezing or ensemble methods \cite{GoodfellowShlens2014}.
• Mitigate Data Poisoning: Data poisoning occurs when attackers contribute harmful data to databases, severely impairing the accuracy and dependability of AI models \cite{AlAttar2023,QayyumQadir2020}. Proactive scans should be implemented to identify corrupted data and protect training pipelines \cite{KhadkaEpiphaniou2025}.
• Stress Testing and OOD Detection: Conduct rigorous stress tests to validate the model's robustness under adversarial inputs \cite{KhadkaEpiphaniou2025}. Implement Out-of-Distribution (OOD) detection to proactively flag inputs that fall outside the model's expected data range, preserving reliability and resisting novel inputs \cite{KhadkaEpiphaniou2025}.
• Data Quality Assessment: Perform thorough checks on training datasets and operational cases for completeness, consistency, uniqueness, and correctness to avoid low performance or improper use, especially concerning input features like images and text records \cite{GarcaGmezBlanesSelva2023}.
2. Ensuring Data Confidentiality and Privacy
Given that the application handles sensitive patient text (EHRs) and image data, robust measures must be in place to prevent privacy violations and data leakage \cite{AlAttar2023,QayyumQadir2020}:
• Federated Learning (FL): Utilize FL frameworks to allow collaborative training of AI models across distributed healthcare nodes or institutions without requiring the transfer of raw, sensitive patient data \cite{AlkanZakariyya2025,JamesIjiga2024}. FL helps ensure compliance with regulations like HIPAA and GDPR \cite{JamesIjiga2024}.
• Differential Privacy (DP): Integrate DP mechanisms, such as Differentially Private Stochastic Gradient Descent (DP-SGD), to introduce calculated noise into computations. This provides a guaranteed maximum privacy loss, enhancing data protection during model training \cite{AlkanZakariyya2025,JamesIjiga2024}.
• Encryption and Secure Protocols: Employ end-to-end encryption (for data-at-rest and in-transit) and use secure cloud storage solutions that adhere to standards like HIPAA and GDPR \cite{AlAttar2023,GarcaGmezBlanesSelva2023}. Furthermore, homomorphic encryption allows data processing without decryption, offering strong privacy guarantees, although it can be computationally complex \cite{JamesIjiga2024,AlkanZakariyya2025}.
• Minimize Data Leakage: Address the inherent vulnerability of deep learning models to memorise and inadvertently expose sensitive training data \cite{AlkanZakariyya2025}. Strategies include disentangling latent representations to separate key features from identity information \cite{AlkanZakariyya2025}.
3. Operational, Transparency, and Regulatory Frameworks
Securing the application also requires comprehensive governance to ensure accountability, usability, and long-term reliability in a clinical setting \cite{GarcaGmezBlanesSelva2023,AlkanZakariyya2025}:
• Multi-layered Security Architecture: Adopt a holistic strategy across the system architecture, integrating layers such as the Edge (for lightweight, real-time detection on devices), Fog (for hybrid DL/DRL models), and Cloud (for global model training, aggregation via FL, and explainability) \cite{AlAttar2023,PadalaSundar2025}.
• Continuous Monitoring and Anomaly Detection: Implement continuous model monitoring based on logging and pattern recognition to identify anomalous or aberrant model behaviours in real-time, aiding in prompt threat response \cite{AlAttar2023,GarcaGmezBlanesSelva2023}. This should include detecting unusual activity patterns or unauthorized data flows \cite{JamesIjiga2024}.
• eXplainable Artificial Intelligence (XAI): Mechanisms such as SHAP or LIME should be integrated to explain how the AI model generates its output for a specific patient \cite{GarcaGmezBlanesSelva2023,JamesIjiga2024}. This transparency is crucial for clinicians' trust, accountability, identifying sources of AI errors, and debugging potential biases \cite{GarcaGmezBlanesSelva2023,AlkanZakariyya2025}. However, XAI must also be secured, as explanations themselves can be susceptible to adversarial attacks \cite{ChangLiu2024,AlkanZakariyya2025}.
• Audit Trail: Maintain a complete audit trail that logs every user action, system access, and prediction, including inputs, outputs, and confidence scores \cite{GarcaGmezBlanesSelva2023,KhadkaEpiphaniou2025}. This ensures traceability and accountability, which is vital for compliance \cite{GarcaGmezBlanesSelva2023}.
• Human Oversight (Clinicians Double-Check): Implement mechanisms that require confirmation by the healthcare professional (user) before sending a clinical case to the AI system \cite{GarcaGmezBlanesSelva2023}. This ensures the clinician is aware of using an AI system and acknowledges its limitations \cite{GarcaGmezBlanesSelva2023}.
• Bias Check and Fairness: Explicitly check for and mitigate algorithmic bias that may be inherited from training datasets (which may include imbalanced image or text records) \cite{GarcaGmezBlanesSelva2023}. The limitations due to training dataset bias should be reported in the system documentation \cite{GarcaGmezBlanesSelva2023}.
• Regulatory Compliance and AI Passport: Ensure the application adheres strictly to standards like the NIST Cybersecurity Framework, HIPAA, and GDPR \cite{JamesIjiga2024,AlAttar2023}. Furthermore, maintain an AI Passport—a detailed statement documenting the AI system's purpose, context of use, training, evaluation details, and potential biases, dynamically updated with continuous performance results \cite{GarcaGmezBlanesSelva2023}.


####################
late stage 
Late-stage prostate cancer, typically referred to as metastatic castration-resistant prostate cancer (mCRPC), is an incurable and fatal disease, despite substantial therapeutic advances \cite{FizaziHerrmann2023,HatanoNonomura2023}. Managing mCRPC is complex, focusing on extending life, delaying disease progression, and maintaining or improving health-related quality of life (HRQOL) \cite{FizaziHerrmann2023}.
The systemic therapy options available for patients with mCRPC include established agents, newer targeted agents, and radioligand therapies:
1. Established Systemic Therapies
Several classes of therapy have been approved and shown to provide a survival benefit in patients with mCRPC since 2010 \cite{FizaziHerrmann2023}.
Class of Therapy
Specific Agents Mentioned
Key Context/Role
Citations
Androgen Receptor Pathway Inhibitors (ARPIs) / Second-Generation Hormonal Therapy
Abiraterone acetate
Used to treat mCRPC, sometimes before chemotherapy \cite{FizaziHerrmann2023,HatanoNonomura2023}. \cite{FizaziHerrmann2023,HatanoNonomura2023}
Enzalutamide
Used to treat mCRPC, sometimes before chemotherapy \cite{FizaziHerrmann2023,HatanoNonomura2023}. \cite{FizaziHerrmann2023,HatanoNonomura2023}
Apalutamide and Darolutamide
Also listed among new treatment options for mCRPC \cite{HatanoNonomura2023,MaLi2022}. \cite{HatanoNonomura2023,MaLi2022}
Chemotherapy (Taxanes)
Docetaxel
Historically became the standard therapy for mCRPC, demonstrating prolonged survival \cite{FizaziHerrmann2023,HatanoNonomura2023}. \cite{FizaziHerrmann2023,HatanoNonomura2023}
Cabazitaxel
Used for mCRPC progressing after docetaxel treatment \cite{FizaziHerrmann2023,HatanoNonomura2023}. It is considered a suitable treatment option for patients who progressed after docetaxel and an ARSI \cite{HatanoNonomura2023}. \cite{FizaziHerrmann2023,HatanoNonomura2023}
Immunotherapy
Sipuleucel-T
Approved therapy shown to provide a survival benefit in mCRPC \cite{FizaziHerrmann2023,HatanoNonomura2023}. \cite{FizaziHerrmann2023,HatanoNonomura2023}
Pembrolizumab
A PD-1 inhibitor approved to treat prostate cancer \cite{MaLi2022,RamnaraignSartor2023}. \cite{MaLi2022,RamnaraignSartor2023}
2. Prostate-Specific Membrane Antigen (PSMA)-Targeted Radioligand Therapy (RLT)
Radioligand therapy (RLT) selectively targets cancer cells that overexpress Prostate-Specific Membrane Antigen (PSMA) \cite{FizaziHerrmann2023,MaLi2022}. PSMA is highly expressed in mCRPC cells, making it an ideal therapeutic target \cite{FizaziHerrmann2023,MaLi2022}.
Lutetium-177 [$\text{^{177}Lu}$]Lu-PSMA-617 (Pluvicto$\text{^{TM}}$)
$\text{^{177}Lu}$Lu-PSMA-617 is a small molecule radioligand therapy that delivers $\beta$ particle radiation specifically to PSMA-expressing cells \cite{FizaziHerrmann2023}. It received FDA approval in March 2022 for adult patients with PSMA-positive mCRPC who have previously been treated with androgen receptor pathway inhibition and taxane-based chemotherapy \cite{Keam2022,HennrichEder2022}.
• Efficacy and Survival: The phase 3 VISION trial demonstrated that the addition of $\text{^{177}Lu}$Lu-PSMA-617 to protocol-permitted standard of care (SoC) significantly prolonged radiographic progression-free survival (rPFS) (median 8.7 months vs 3.4 months) and overall survival (OS) (median 15.3 months vs 11.3 months) compared with SoC alone \cite{FizaziHerrmann2023,HatanoNonomura2023}.
• Comparison to Cabazitaxel: The phase 2 TheraP trial showed that $\text{^{177}Lu}$Lu-PSMA-617 (compared to cabazitaxel) resulted in a higher PSA response rate (66\\\\% vs 37\\\\%), longer progression-free survival, better patient-reported outcomes (PROs) and fewer grade 3–4 adverse events \cite{HatanoNonomura2023,SathekgeBruchertseifer2022}. TheraP data supports $\text{^{177}Lu}$Lu-PSMA-617 as a viable alternative to cabazitaxel in eligible patients with mCRPC \cite{SathekgeBruchertseifer2022,HofmanEmmett2024}.
Other Lutetium-177 Agents
• $\text{^{177}Lu}$Lu-PSMA-I&T is another PSMA ligand demonstrating promise for therapy in mCRPC \cite{SadaghianiSheikhbahaei2022,KarimzadehHeck2022}. Clinical experience suggests good antitumor activity in late-stage mCRPC \cite{KarimzadehHeck2022,PatellKurian2023}.
Targeted Alpha Therapy (TAT)
• Actinium-225 [$\text{^{225}Ac}$]PSMA-617 is a novel alpha-emitter RLT showing substantial antitumour effect and representing a viable therapy option, including in patients previously treated with approved agents (e.g., taxane chemotherapy, ARPIs, $\text{^{177}Lu}$-PSMA RLT, and radium-223 dichloride) \cite{ChandranFigg2022,SadaghianiSheikhbahaei2022}.
• $\text{^{225}Ac}$-PSMA-617 is often considered for tumors resistant to standard treatments and has shown better responses than $\text{^{177}Lu}$-PSMA in some settings \cite{AlamSingh2022}.
• Tandem/Augmented Therapy: Tandem therapy combining $\text{^{225}Ac}$-PSMA-617 and $\text{^{177}Lu}$-PSMA-617 has been investigated, particularly for mCRPC patients who progressed on $\text{^{177}Lu}$-PSMA-617 monotherapy \cite{AlamSingh2022,LingBlois2022}.
Emerging Radionuclides
• Terbium-161 [$\text{^{161}Tb}$]-PSMA-617 is being explored as a promising alternative to standard $\text{^{177}Lu}$-based RLT \cite{RosarMaus2023}. $\text{^{161}Tb}$ has physical properties that may be superior to $\text{^{177}Lu}$ (e.g., providing more coemitted Auger- and conversion electrons resulting in higher tumor-absorbed doses), especially in disseminated metastatic disease \cite{RosarMaus2023}.
3. Precision/Targeted Therapies
• PARP Inhibitors: Agents like olaparib and rucaparib are used for mCRPC that harbors gene alterations affecting homologous recombination repair (HRR), such as mutations in BRCA1 and BRCA2 \cite{HatanoNonomura2023,MaLi2022}. Companion diagnostics are used to identify eligible patients \cite{HatanoNonomura2023}.
• Ipatasertib in combination with abiraterone was studied, although clinical data showed no significant OS difference in the intention-to-treat population in one trial \cite{HatanoNonomura2023}.
• Cabozantinib has been studied and shown to delay the time to first symptomatic skeletal event in patients with mCRPC versus prednisone \cite{FizaziHerrmann2023}.
4. Bone-Targeted Radionuclide and Modifying Agents
Given that up to 90\\\\% of mCRPC patients have bone metastases \cite{FizaziHerrmann2023}, therapies aimed at controlling skeletal complications are essential.
• Radium-223 ($\text{^{223}Ra}$)-dichloride: This is an alpha emitter and bone-targeted radionuclide therapy \cite{FizaziHerrmann2023,ChandranFigg2022}. It is approved for mCRPC patients with symptomatic bone metastases \cite{MaLi2022}. It improves overall survival and quality of life in patients with bone-predominant mCRPC \cite{RamnaraignSartor2023,RahbarEssler2022}.
• Bone-Targeted Therapies: Bisphosphonates (e.g., zoledronic acid) and denosumab are key for preventing symptomatic skeletal events (SSEs), such as fracture, spinal cord compression, and pain, which severely impair HRQOL \cite{HatanoNonomura2023,SathekgeBruchertseifer2022}.
5. Emerging Combination Strategies
Ongoing clinical trials are actively investigating the use of PSMA-RLT earlier in the treatment sequence or in combination with other systemic therapies for mCRPC \cite{RamnaraignSartor2023,FizaziHerrmann2023}.
• Combination with ARPIs: The ENZA-p trial (NCT04419402) is a randomized phase II trial combining $\text{^{177}Lu}$-PSMA-617 with enzalutamide \cite{PatellKurian2023,RamnaraignSartor2023}.
• Combination with Chemotherapy: Trials are exploring combining $\text{^{177}Lu}$-PSMA-617 with cabazitaxel (LuCAB, NCT05340374) \cite{PatellKurian2023,RamnaraignSartor2023}.
• Combination with Bone-Targeted Agents: The AlphaBet trial (NCT05383079) is a phase I/II study combining the alpha emitter $\text{^{223}Ra}$ with $\text{^{177}Lu}$Lu-PSMA-I&T \cite{PatellKurian2023,KostosButeau2022}.
• Combination with PARP Inhibitors: The LuPARP trial (NCT03874884) is a phase I trial combining $\text{^{177}Lu}$-PSMA-617 with olaparib \cite{PatellKurian2023,RamnaraignSartor2023}.
• Combination with Immunotherapy: Trials are combining $\text{^{177}Lu}$-PSMA with immunotherapy agents like pembrolizumab (NCT03805594, NCT03658447) or ipilimumab and nivolumab (EVOLUTION, NCT05150236) \cite{RamnaraignSartor2023,PatellKurian2023}.
• PSMA RLT in Earlier Settings: Other phase 3 trials are assessing $\text{^{177}Lu}$Lu-PSMA-617 efficacy earlier in the sequence, such as PSMAfore (NCT04689828) comparing it to a change in ARPI in taxane-naïve mCRPC patients \cite{FizaziHerrmann2023,PatellKurian2023}.