\documentclass[11pt, a4paper]{article}

% --- ESSENTIAL PACKAGES ---

% Font Encoding and Input
\usepackage[T1]{fontenc} % Use 8-bit T1 fonts to ensure proper character rendering
\usepackage[utf8]{inputenc} % Allows direct use of UTF-8 characters (e.g., é, ö, à)
\usepackage{amsmath} % For \text{} in math mode

% Page Layout and Margins
\usepackage{geometry}
\geometry{
    a4paper,
    left=2.5cm,
    right=2.5cm,
    top=3cm,
    bottom=3cm
}

% Professional Fonts (Latin Modern)
\usepackage{lmodern}
\usepackage{helvet} % For Helvetica font, used for the main title

% --- COLOR AND STYLING ---

% Color Management
\usepackage[dvipsnames]{xcolor} % Use dvipsnames for a wider range of predefined colors

% Define a professional color palette
\definecolor{primary}{HTML}{0A369D}  % A deep, professional blue
\definecolor{secondary}{HTML}{4472CA} % A lighter, complementary blue
\definecolor{darkgray}{HTML}{333333}  % For body text, better than pure black
\definecolor{customgreen}{HTML}{5E8B7E} % A muted green for accents
\definecolor{titleblue}{HTML}{082A75} % A darker, rich blue for the main title

\color{darkgray} % Set the default text color

% Section and Title Styling
\usepackage{titlesec}
\titleformat{\section}
  {\normalfont\Large\bfseries\color{primary}} % Format for the section title
  {\thesection}{1em}{} % Section number, spacing, and the title itself
\titleformat{\subsection}
  {\normalfont\large\bfseries\color{secondary}}
  {\thesubsection}{1em}{}
\titleformat{\subsubsection}
  {\normalfont\bfseries\color{customgreen}}
  {\thesubsubsection}{1em}{}

% --- IMAGES AND GRAPHICS ---

% Standard package for including images
\usepackage{graphicx}
\graphicspath{{images/}} % Optional: specify a folder for your images
\usepackage{float} % Improved control over figure placement with [H] option

% --- LISTS AND ENUMERATIONS ---

% Customize list environments
\usepackage{enumitem}
% The 'textcolor' option sets the color for the item's text
\setlist[itemize,1]{label=\textcolor{primary}{\textbullet}}
\setlist[itemize,2]{label=\textcolor{secondary}{\textendash}}

% --- HYPERLINKS ---

% Hyperlink styling for URLs and cross-references
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=primary,
    filecolor=magenta,
    urlcolor=secondary,
    citecolor=customgreen,
    pdftitle={My Professional Document},
    pdfpagemode=FullScreen,
}

% --- TYPOGRAPHY AND MICRO-ADJUSTMENTS ---

% Improves the justification and spacing of text for a cleaner look
\usepackage{microtype}

% --- DOCUMENT CONTENT EXAMPLE ---

% For placeholder text
\usepackage{lipsum}

% --- TABLE AND CURRENCY PACKAGES ---
\usepackage{booktabs} % For professional looking tables
\usepackage{longtable} % For tables that may span multiple pages
\usepackage{siunitx} % For aligning numbers in tables
\usepackage{eurosym} % For the EUR symbol
\usepackage{float} % to use [H]

\title{A Causal AI Framework for Longitudinal Modelling of Prostate Cancer}
\author{Project Acronym: CausalPCa}
\date{}

\begin{document}

\maketitle

\section{Excellence}

\subsection{Vision}
The management of prostate cancer is at a tipping point. Clinicians are inundated with a deluge of multimodal data—from advanced imaging like MRI and PET/CT to genomic profiles and longitudinal clinical records. While Artificial Intelligence has shown promise in processing this information, current models operate as sophisticated but opaque "black boxes." They excel at identifying statistical correlations but fundamentally lack a true understanding of the underlying causal biology of the disease. This critical gap fosters mistrust and creates a barrier to clinical adoption, as models can be easily misled by spurious correlations, such as scanner artifacts or site-specific protocols, leading to predictions that are brittle, unexplainable, and potentially unsafe.

This project puts forward a radical new vision: to move beyond simple prediction and pioneer a new generation of Causal AI that can reason about prostate cancer. We aim to build not just a predictive tool, but a dynamic, interactive "digital twin" of a patient's disease trajectory. Our goal is to create a model that understands the intricate cause-and-effect relationships driving cancer progression, can simulate future outcomes under different treatment scenarios, and can explain its reasoning through clinically intuitive counterfactuals. By asking "what if...?"—what if this tumour were benign? what if this patient had not received therapy?—we empower clinicians with a tool that augments, rather than replaces, their own reasoning process.

This project does not aim to incrementally improve existing methods; it aims to define the technology-to-come.

\subsection{Consortium and Clinic Expertise}
Our consortium is uniquely positioned to succeed in this high-risk, high-gain endeavor. The applicant clinic, the Universitätsklinik für Radiologie und Nuklearmedizin, possesses not only the requisite multimodal data but also a proven track record in developing and deploying advanced AI models in a clinical setting. Our team has successfully executed projects involving:
\begin{itemize}
    \item \textbf{Synthetic Image Generation:} We have hands-on experience in generating synthetic CT scans from PET data, a foundational skill for the generative components of this proposal.
    \item \textbf{Predictive Modeling:} Our team has developed and validated models for predicting disease progression by fusing clinical and imaging data, directly relevant to the core of this project.
    \item \textbf{Clinical Application Development:} We have created a user-friendly GUI for structured reporting and developed an LLM-based support application for thyroid cancer guidelines, demonstrating our ability to translate research into practical clinical tools.
\end{itemize}
Crucially, the project will be led by a Principal Investigator who possesses a rare dual expertise in both clinical radiology and artificial intelligence. This unique leadership ensures a seamless bridge between the complex technical development and the real-world clinical needs and validation requirements, a critical success factor for a project of this ambition. The collaboration with the Abteilung für Nuklearmedizin at Universitätsmedizin Halle and the private practice of Dr. Christian Wybrański further strengthens our consortium, providing diverse data and clinical perspectives.

\subsection{Objectives}
This project is guided by a set of clear, ambitious, and interconnected objectives designed to realize our vision of a causal AI for prostate cancer, directly aligning with the Pathfinder's goal of developing foundational, high-impact technologies. The primary objectives are:
\begin{enumerate}
    \item \textbf{To Pioneer a Causal, Longitudinal Model of Prostate Cancer:} The core scientific objective is to develop and validate a novel Causal AI framework, built upon a Neural Jump Ordinary Differential Equation (NJDE) architecture. This model will be capable of learning the underlying dynamics of disease progression from sparse, irregularly-sampled, multi-modal data, while explicitly modeling the impact of clinical interventions like surgery and therapy. This foundational technology will establish a new European standard for clinical AI.

    \item \textbf{To Achieve True Explainability through Counterfactual Reasoning:} We will move beyond opaque "black-box" models by building a system that can generate clinically plausible, visual counterfactuals. This will enable clinicians to ask "what-if" questions and receive intuitive, visual explanations for the model's predictions, fostering the clinical trust necessary for widespread adoption and establishing a new paradigm for trustworthy AI.

    \item \textbf{To Master Heterogeneity through Principled Disentanglement:} A key technical objective is to develop a robust Variational Autoencoder (VAE) framework that can disentangle the core components of medical imaging data. The model will learn to separate true disease signals from patient-specific anatomy, age-related changes, and technical confounders (e.g., scanner type, site-specific artifacts), ensuring the model is robust, generalizable, and ready for deployment across diverse European healthcare systems.

    \item \textbf{To Create a Dynamic "Digital Twin" for Personalized Prognosis:} We aim to deliver a tool that can simulate a patient's future disease trajectory under various scenarios. The model will generate predictions not only of future scans but also of key clinical endpoints and structured radiological reports, providing a comprehensive, personalized prognostic tool that has the potential to revolutionize patient management.

    \item \textbf{To Validate the Framework in a Real-World Clinical Context:} The project will culminate in a rigorous evaluation of the model's performance, using both quantitative metrics (e.g., predictive accuracy, counterfactual quality) and a qualitative, clinician-in-the-loop study to assess its real-world clinical plausibility, utility, and impact on diagnostic workflows, thereby paving the way for its integration into the European healthcare ecosystem.
\end{enumerate}

\subsection{Concept and Methodology}
Our methodology is a direct answer to the profound challenges of building trustworthy clinical AI. We have designed a novel, four-stage causal framework that deconstructs the immense complexity of prostate cancer progression into a series of well-defined, manageable tasks. This modular approach is the key to our project's feasibility: it ensures training stability, enhances model interpretability, and allows us to systematically embed clinical domain knowledge as strong inductive biases. This guides the model to learn the true underlying causal mechanisms of the disease, rather than superficial correlations. This design leverages our consortium's extensive experience in synthetic image generation (CT from PET) and predictive modeling, and is illustrated in Figure \ref{fig:ml_framework}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{ml.png}
    \caption{Data flow diagram of the proposed multi-stage causal AI model. The process begins with comprehensive patient data, which is used to train foundational supervisor models. These guides inform a per-modality VAE to learn a disentangled latent space. A Neural Jump ODE then models the patient's temporal disease trajectory from these latent representations, culminating in generative outputs like prognostic images and structured reports.}
    \label{fig:ml_framework}
\end{figure}

\subsubsection{Stage 1: Building the Bedrock of Clinical Validity with Supervisor Models}
The first stage builds a suite of specialized "supervisor" models. These models act as expert guides, providing strong, clinically-validated signals that will enforce a valid structure on the more complex generative models in subsequent stages. Our team's prior success in developing predictive models from fused clinical and imaging data provides a strong foundation for this work package.
\begin{itemize}
    \item \textbf{Ordinal Classifiers:} For clinical scores with an inherent order (e.g., PI-RADS, TNM stage), standard categorical classifiers are suboptimal. We will implement a \textbf{differential ordinal learning framework} that explicitly encodes the ordered structure by combining a standard categorical loss with a differential ordinal loss, ensuring the model understands that a higher grade implies a worse prognosis \cite{LeeByeon2025, GrisiKartasalo2025}.
    \item \textbf{Censored Survival Regressor:} To predict time-to-progression (TTP), we will train a survival model that properly handles right-censored data. This will be achieved using a censored regression loss (e.g., Logistic Hazard) combined with a ranking loss regularizer (e.g., SurvRNC) to ensure correct risk ordering in the learned feature representation \cite{GaoLi2019, RivailVogl2023, ShahinZhao2023}.
    \item \textbf{Anatomical and Confounder Models:} We will fine-tune a pre-trained TotalSegmentator model to provide anatomical ground truth. Furthermore, we will train dedicated regressors and classifiers to predict patient age, BMI, and technical confounders (e.g., scanner type, dosage), allowing us to explicitly model and isolate these non-disease-related sources of variation \cite{PuglisiAlexander2025, ZhangHager2025}.
\end{itemize}

\subsubsection{Stage 2: Mastering Heterogeneity through Principled Disentanglement}
At the heart of our solution to data heterogeneity is a hierarchical Variational Autoencoder (VAE) trained for each imaging modality to learn a disentangled latent space. The key innovation is partitioning this space into four independent, semantically meaningful components: Anatomy ($Z_A$), Disease ($Z_D$), Patient State ($Z_P$), and Style/Confounders ($Z_S$). This separation is enforced through a composite loss function:
$$ \mathcal{L}_{\text{total}} = \mathcal{L}_{\text{VAE}} + \lambda_A \mathcal{L}_{\text{Anatomy}} + \lambda_D \mathcal{L}_{\text{Disease}} + \lambda_I \mathcal{L}_{\text{Disentangle}} $$
The disentanglement is achieved by moving beyond simple $\beta$-VAE approaches. Our loss function will explicitly penalize the \textbf{Total Correlation (TC)} between latent dimensions and minimize the \textbf{Mutual Information (MI)} between causally independent subspaces (e.g., Disease $Z_D$ and Style $Z_S$) \cite{FragemannArdizzone2022, AbbasiMonadjemi2018, FayCobos2023}. This ensures the learned disease representation is invariant to scanner-specific artifacts while preserving reconstruction quality. The entire data curation and preprocessing pipeline is visualized in Figure \ref{fig:data_curation}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{dc.png}
    \caption{An infographic summarizing the data acquisition, curation, and preprocessing framework for the study cohort. It details the inclusion and exclusion criteria for patient selection and outlines the multi-step pipeline for processing clinical, histopathological, and imaging data.}
    \label{fig:data_curation}
\end{figure}

\subsubsection{Stage 3: Capturing Disease Dynamics with Neural Jump ODEs}
This stage confronts the critical challenge of modeling disease evolution from sparse and irregularly-sampled clinical data. Our solution is a \textbf{Neural Jump Differential Equation (NJDE)} framework \cite{GwakSim2020}. While Neural Ordinary Differential Equations (NODEs) are powerful for modeling continuous-time dynamics, their computational cost is prohibitive for high-dimensional 3D images \cite{WiewelBecher2018, DavisChoromanski2020}. Our approach mitigates this by operating exclusively on the low-dimensional, disentangled disease latent space ($Z_D$) from Stage 2. The NJDE learns the rules of disease evolution by modeling two phenomena:
\begin{itemize}
    \item \textbf{Continuous Evolution (The NODE):} Between clinical events, the disease state evolves smoothly, modeled by a classic NODE that learns the underlying dynamics \cite{BergHasenclever2018}.
    \item \textbf{Discrete Jumps (The Interventions):} At the time of a clinical intervention (e.g., prostatectomy), the continuous evolution is interrupted by a discrete "jump," modeled by a separate neural network \cite{CuchieroLarsson2019, AbushaqraXue2022}.
\end{itemize}
This hybrid approach, illustrated in the context of the natural history of prostate cancer in Figure \ref{fig:prostate_evolution}, is critical for accurately modeling a patient's journey.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{pe.png}
    \caption{The natural history of prostate cancer, illustrating the stages our model will learn.}
    \label{fig:prostate_evolution}
\end{figure}

\subsubsection{Stage 4: Translating Insight into Action: Generative Synthesis and Structured Reporting}
The final stage translates the model's learned representations into clinically actionable outputs. This includes generating high-fidelity images for any time point (past, present, or future) and for any counterfactual scenario. Crucially, the model will generate structured radiological reports and tumor board recommendations using a Transformer-based decoder. This directly addresses the clinical need for clear, consistent, and efficient documentation, a major benefit of structured reporting \cite{JorgHalfmann2023, SacoranskyKwan2024}. Our consortium's experience in creating LLM-based support apps and GUIs from structured reports ensures the successful implementation of this stage. The entire clinical workflow is depicted in Figure \ref{fig:workflow}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{wf.png}
    \caption{The Multidisciplinary Workflow of Prostate Cancer Diagnosis: A complex, iterative process requiring multimodal data fusion and expert collaboration.}
    \label{fig:workflow}
\end{figure}

\subsection{Compliance with the EU Artificial Intelligence Act}
The proposed framework is designed from the ground up to align with the principles of trustworthy AI and to comply with the requirements for high-risk AI systems as laid down in the Regulation (EU) 2024/1689 (the "AI Act"). As a system intended for use in medical diagnosis and to guide treatment, it is classified as a \textbf{high-risk AI system} under Annex III of the Act. Our methodology directly addresses the core obligations for such systems:

\begin{itemize}
    \item \textbf{Risk Management System (Article 9):} Our project management (WP7) includes a continuous, iterative risk management process that will be maintained throughout the AI system's lifecycle. This involves identifying, analyzing, and mitigating known and reasonably foreseeable risks to health, safety, and fundamental rights.

    \item \textbf{Data and Data Governance (Article 10):} WP1 is entirely dedicated to establishing data governance practices that meet the quality criteria of Article 10. We will use relevant, representative, and error-free datasets. We will proactively implement measures to detect and mitigate potential biases. For the purpose of bias detection and correction, we will process special categories of personal data only where strictly necessary and with the appropriate safeguards as permitted under Article 10(5).

    \item \textbf{Transparency and Provision of Information (Article 13):} A cornerstone of our project is to overcome the "black box" problem. The framework's ability to generate counterfactual explanations is a direct implementation of the transparency requirements of Article 13. The system is designed so that its operations are sufficiently transparent to enable deployers to interpret its output and use it appropriately.

    \item \textbf{Human Oversight (Article 14):} The system is designed to augment, not replace, clinical experts. It functions as a decision support tool, ensuring that a natural person can oversee its functioning at all times. The design ensures that the user can understand the system's capabilities, monitor its operation, and decide to disregard, override, or reverse its output, fulfilling the requirements of Article 14.

    \item \textbf{Accuracy, Robustness, and Cybersecurity (Article 15):} WP5 is dedicated to rigorous validation of the model's accuracy and robustness. The system will be designed to be resilient against errors and inconsistencies. We will implement robust cybersecurity measures to protect against vulnerabilities specific to AI, including data poisoning and adversarial attacks, as mandated by Article 15.

    \item \textbf{Technical Documentation and Record-Keeping (Articles 11 \& 12):} We commit to creating and maintaining comprehensive technical documentation as specified in Annex IV of the AI Act and implementing logging capabilities to ensure traceability, in compliance with Article 12.
\end{itemize}

This principled approach ensures that our innovative framework is not only technologically advanced but also safe, trustworthy, and fully compliant with the Union's legal framework for artificial intelligence.

\subsection{Ambition}
The ambition of this project extends far beyond advancing the state-of-the-art in predictive modeling. We aim to establish a new paradigm for trustworthy AI in clinical medicine, shifting the focus from correlation to causation. By developing a model that can reason, simulate, and explain, we are creating a foundational technology with the potential for profound impact. This project will not only deliver a powerful tool for prostate cancer management but will also provide a blueprint for developing causal AI models in other complex disease areas. Our work will pioneer new methods for disentanglement, longitudinal modeling, and counterfactual reasoning that will be of immense value to the wider AI research community. The successful completion of this project will represent a significant step towards the realization of truly intelligent clinical decision support systems, paving the way for a future of more personalized, more effective, and more explainable medicine.

\section{Impact}
The successful execution of this project will generate significant and lasting impact across multiple domains, from advancing the frontiers of science and technology to delivering tangible benefits for patients, clinicians, and the European innovation ecosystem. Our focus is not merely on creating a tool, but on establishing a new technological paradigm for clinical AI that is trustworthy, explainable, and directly aligned with the goals of the EU Cancer Mission.

\subsection{Scientific and Technological Impact}
This project is poised to make fundamental contributions to the field of Artificial Intelligence and its application in medicine.
\begin{itemize}
    \item \textbf{A New Paradigm for Clinical AI:} We will pioneer a shift away from correlational "black-box" models towards truly causal and explainable AI. The development of a robust, generalizable framework for learning causal models from observational clinical data will represent a landmark achievement. This provides a blueprint for future research in a wide range of diseases and establishes a new European standard for the development and deployment of trustworthy AI systems in high-stakes environments.
    \item \textbf{Advancing the Frontier of Generative AI:} Our work on principled disentanglement, counterfactual generation, and longitudinal modeling with Neural Jump ODEs will push the boundaries of generative AI. By creating a model that can reason about cause and effect, we are developing a foundational technology with applications far beyond medicine, including in climate science, economics, and engineering. The novel techniques developed will be of immense value to the broader AI community.
    \item \textbf{Fostering an Open European AI Ecosystem:} We are deeply committed to open science. We will make our code publicly available under a permissive open-source license. Crucially, we will contribute our curated, anonymized, and harmonized datasets to public repositories, with a specific focus on contributing to the \textbf{European Cancer Imaging (EUCAIM)} platform. This will not only foster further research and innovation across the EU but will also ensure that our work directly supports the development of a world-leading European data ecosystem for cancer research.
\end{itemize}

\subsection{Societal and Clinical Impact}
The primary impact of this project will be the profound improvement in the management of prostate cancer, leading to better patient outcomes and more efficient, resilient healthcare systems across Europe.
\begin{itemize}
    \item \textbf{Enhanced Diagnostic Accuracy and Personalised Treatment:} By providing clinicians with a "digital twin" that can simulate disease trajectories and treatment responses, our framework will enable more accurate staging, better risk stratification, and truly personalized treatment planning. This will help to reduce both over- and under-treatment—a critical issue in prostate cancer—thereby minimizing treatment-related side effects and significantly improving patient quality of life.
    \item \textbf{Empowering Clinicians and Reducing Workload:} The model's ability to generate intuitive, counterfactual explanations ("what if this lesion were benign?") and automated structured reports will empower clinicians, augmenting their decision-making process and freeing up valuable time from tedious documentation. This will improve workflow efficiency, reduce burnout, and allow clinicians to focus on what matters most: patient care.
    \item \textbf{A Foundation for a New Era in Oncology:} While focused on prostate cancer, the foundational technology developed in this project is modality-agnostic and disease-agnostic. It has the potential to be adapted to other cancers (e.g., breast, lung) and complex chronic diseases, paving the way for a new era of data-driven, causal medicine that is more personalized, more effective, and more explainable.
\end{itemize}

\subsection{Dissemination, Communication, and Exploitation}
We are committed to maximizing the impact of this project through a comprehensive dissemination, communication, and exploitation strategy designed to engage stakeholders at all levels.
\begin{itemize}
    \item \textbf{High-Impact Scientific Publications:} We will publish our methodological advancements and clinical validation results in leading peer-reviewed journals (e.g., Nature Machine Intelligence, The Lancet Digital Health, Medical Image Analysis) and present at premier international conferences (e.g., MICCAI, NeurIPS, RSNA).
    \item \textbf{Open Source and Open Data:} As stated, all code will be open-sourced. Our curated, anonymized datasets will be contributed to public repositories, including a dedicated contribution to the \textbf{European Cancer Imaging (EUCAIM)} platform, to ensure our data legacy strengthens the European research community.
    \item \textbf{Engagement with the Clinical and Patient Community:} We will actively engage with clinical societies (e.g., EAU, ESMO) and patient advocacy groups (e.g., Europa Uomo) through workshops, webinars, and presentations. This ensures our work is aligned with real-world clinical needs and facilitates its translation into clinical practice.
    \item \textbf{Commercial Exploitation and Standardization:} We will explore pathways for commercial exploitation through partnerships with medical imaging companies and health-tech startups. Furthermore, we will actively participate in standardization bodies to promote the adoption of our structured reporting and causal AI frameworks as a new European standard for trustworthy clinical AI.
\end{itemize}

\section{Implementation}

\subsection{Work Plan and Consortium}
The project will be executed over 36 months, organized into seven interconnected Work Packages (WPs). The detailed timeline, deliverables (D), and milestones (M) are visualized in the Gantt chart (Figure \ref{fig:gantt}).

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{gantt.png}
    \caption{Project Gantt Chart illustrating the timeline, work packages, milestones, and deliverables.}
    \label{fig:gantt}
\end{figure}

\begin{itemize}
    \item \textbf{WP1: Data Curation and Harmonization (Months 1-9).} Led by Universitätsklinik für Radiologie und Nuklearmedizin. This WP involves aggregating the proprietary multi-center cohort, integrating public datasets (TCGA-PRAD, ProstateNET), and performing rigorous data harmonization, including DICOM to NIFTI conversion, pseudonymization, and image normalization. \textit{(D1.1: Curated, harmonized dataset)}.
    \item \textbf{WP2: Foundational Supervisor Model Training (Months 4-15).} This WP will focus on developing and validating the suite of expert supervisor models (ordinal classifiers, survival regressor, confounder models) that will provide the strong inductive biases for the main generative framework.
    \item \textbf{WP3: Causal VAE Development (Months 10-24).} The core of this WP is the training of the disentangled Variational Autoencoder, leveraging the supervisors from WP2 to enforce causal separation of anatomy, disease, and confounder latent spaces.
    \item \textbf{WP4: Temporal Trajectory Modeling (Months 18-30).} This WP will implement and train the Neural Jump ODE on the disentangled disease vectors from WP3 to model longitudinal patient trajectories, including the impact of interventions.
    \item \textbf{WP5: Validation and Clinical Integration (Months 25-36).} This WP will conduct the comprehensive evaluation of the final model, including quantitative metrics, uncertainty quantification, and the clinician-in-the-loop study to assess real-world utility and impact on workflow.
    \item \textbf{WP6: Dissemination, Communication, and Exploitation (Months 1-36).} This continuous WP covers all project outreach, including publications, conference presentations, open-source code releases, and engagement with clinical and patient communities.
    \item \textbf{WP7: Project Management (Months 1-36).} This WP ensures the smooth execution of the project, managing timelines, resources, and reporting. The project will be led by a principal investigator with dual expertise in clinical radiology and artificial intelligence, ensuring a seamless bridge between the technical and clinical aspects of the project.
\end{itemize}

\subsection{Budget and Resources}
\input{budget.tex}

\subsection{Data Sources and Cohort}
The foundation of this project is a unique, rich, and heterogeneous dataset that combines extensive proprietary clinical data with publicly available resources. This multi-pronged approach ensures the development of robust, generalizable models that are trained on real-world clinical diversity and validated against established international benchmarks.

\subsubsection{Proprietary Multi-Center Clinical Cohort}
Our core dataset will be a retrospective cohort assembled from the clinical partners in this consortium, representing a diverse patient population from different care settings across Germany. This provides a unique opportunity to capture variability in imaging protocols, patient demographics, and treatment patterns, which is essential for building AI models that are resilient to real-world heterogeneity. The cohort will comprise:
\begin{itemize}
    \item \textbf{Universitätsklinik für Radiologie und Nuklearmedizin:} Approximately 100 studies of paired PSMA PET/CT with MRI, and 100 studies of paired Lutetium-177 SPECT/CT with PSMA PET/CT. This dataset is particularly rich in advanced molecular imaging and theranostic data, which is crucial for modeling response to innovative treatments like radioligand therapy.
    \item \textbf{Abteilung für Nuklearmedizin | Universitätsmedizin Halle:} A similar volume of data to the Universitätsklinik, providing approximately 100 paired PSMA PET/CT with MRI and 100 paired Lutetium-177 SPECT/CT with PSMA PET/CT. This second university hospital site strengthens the cohort's academic rigor and diversity.
    \item \textbf{Private Practice of Dr. Christian Wybrański (Magdeburg):} Approximately 200 paired MRI studies. This data from a private practice setting will introduce further variability, ensuring our models are not overfitted to academic medical center protocols and are generalizable to a wider range of clinical environments.
\end{itemize}
In total, our proprietary cohort will consist of approximately 400 paired MRI studies and 200 paired molecular imaging studies, all linked to detailed longitudinal clinical data, including PSA values, biopsy results, and treatment histories.

\subsubsection{Integration of Public Datasets}
To further enhance the scale, diversity, and validation of our models, we will integrate data from leading public archives. This aligns our project with international standards and initiatives like the European Cancer Imaging (EUCAIM) platform.
\begin{itemize}
    \item \textbf{TCGA-PRAD (The Cancer Genome Atlas):} We will leverage the multi-modal imaging (MRI, CT, PET) and rich genomic data from TCGA-PRAD to explore the link between imaging phenotypes and underlying molecular drivers, providing a deeper biological grounding for our causal models.
    \item \textbf{ProstateNET (via EUCAIM):} To align with European data ecosystems, we will utilize datasets from the ProstateNET platform, such as the UC8 active surveillance cohort. This will provide an external validation set and ensure our models perform well on data curated within the EUCAIM framework.
\end{itemize}
This combined data strategy provides an unparalleled foundation for this high-risk, high-gain project, mitigating the risk of data scarcity and ensuring the developed technology is robust, validated, and ready for broader clinical application. All data will be handled in strict compliance with GDPR and ethical guidelines, managed within a secure, federated learning-ready environment.

\subsection{Illustrative Clinical Workflow}
To make the vision concrete, consider the following illustrative workflow of a clinician using the fully trained CausalPCa tool for a new patient:
\begin{enumerate}
    \item \textbf{Automated Patient Summary:} The model ingests the patient's entire record—including scans, lab results, and notes—and generates a concise summary, including a draft structured report for the latest scan. This saves the clinician significant pre-reading time.
    \item \textbf{Prognostic Inquiry:} The clinician, concerned about a suspicious lesion, asks the system via a simple interface, \textit{"Show prognosis in 1 year without treatment."}
    \begin{itemize}
        \item \textbf{Model Action:} The NJDE integrates the patient's history and solves its learned continuous differential equation forward in time to predict the disease state ($Z_D$) at $t+1$ year.
        \item \textbf{Model Output:} The tool generates a future MRI showing likely tumor progression, a predicted PSA of 18.0 ng/mL, and an accompanying prognostic report highlighting the increased risk.
    \end{itemize}
    \item \textbf{Explainable Reasoning Inquiry:} To understand the basis for the high-risk prediction, the clinician probes the model's reasoning by asking, \textit{"What if the primary lesion were benign?"}
    \begin{itemize}
        \item \textbf{Model Action:} The model performs a targeted intervention on the latent space, setting the disease component corresponding to the lesion to a "healthy" state while keeping all other patient factors constant.
        \item \textbf{Model Output:} It generates a new, counterfactual image where the lesion appears benign, along with a revised, low-risk prognostic report and a PI-RADS 2 classification. This visual and textual explanation gives the clinician confidence in the model's assessment.
    \end{itemize}
    \item \textbf{Treatment Planning Inquiry:} The clinician now considers surgery and asks, \textit{"Simulate a post-prostatectomy PET scan and predict the 6-month PSA."}
    \begin{itemize}
        \item \textbf{Model Action:} The model applies a "prostatectomy" intervention. This triggers a learned discrete \textbf{jump} in the NJDE to an immediate post-operative disease state. Simultaneously, a transformation is applied to the anatomy vector $Z_A$ to model the physical removal of the prostate. The NJDE then evolves this new state forward for 6 months.
        \item \textbf{Model Output:} It generates a realistic post-operative PET/CT scan and provides a predicted 6-month PSA value of <0.1 ng/mL, offering a comprehensive simulation of a positive treatment outcome.
    \end{itemize}
\end{enumerate}

\subsection{Evaluation and Validation}
The project's success will be measured through a rigorous, multi-faceted evaluation plan that combines quantitative metrics with qualitative, clinician-in-the-loop studies to assess real-world utility and trustworthiness.

\subsubsection{Quantitative Metrics}
Model performance will be assessed using a comprehensive suite of metrics tailored to each sub-task:
\begin{itemize}
    \item \textbf{Supervisor Model Performance:}
        \begin{itemize}
            \item \textbf{Classification:} Accuracy, Area Under the Curve (AUC), F1-Score, and Quadratic Weighted Kappa for ordinal tasks.
            \item \textbf{Survival Regression:} Concordance Index (C-index) and Mean Absolute Error on censored data.
        \end{itemize}
    \item \textbf{Generative Model Performance:}
        \begin{itemize}
            \item \textbf{Image Generation Quality:} Fréchet Inception Distance (FID), Structural Similarity Index (SSIM), and Learned Perceptual Image Patch Similarity (LPIPS) to measure realism and fidelity \cite{VigneshwaranOhara2024, Singla2022}.
            \item \textbf{Counterfactual Quality:} We will use a comprehensive suite of metrics to assess axiomatic soundness (effectiveness, composition, reversibility) \cite{KomanduriWu2023, MonteiroRibeiro2023}, validity (success rate of flipping a classifier’s decision) \cite{SinglaEslami2021, Singla2022}, proximity (distance to the original), and realism (FID) \cite{GuoDeng2024}.
        \end{itemize}
\end{itemize}

\subsubsection{Uncertainty Quantification}
A key feature for clinical trust is the model's ability to quantify its own uncertainty. Our VAE-based architecture is intrinsically probabilistic and allows for robust uncertainty quantification. We will employ two complementary methods:
\begin{itemize}
    \item \textbf{Latent Space Sampling:} For a given input, we will draw multiple samples from its learned latent distribution. The variance in the resulting predictions will serve as a robust measure of the model's epistemic uncertainty \cite{BustinMeyer2025}.
    \item \textbf{Direct Variance Utilisation:} The variance vector $\sigma^2$ produced by the VAE encoder is a direct indicator of feature-level uncertainty. We will concatenate this variance vector to the mean vector as a direct input to downstream models, allowing them to learn to depend more on high-confidence features \cite{FriedrichFrisch2024}.
\end{itemize}

\subsubsection{Clinical Plausibility and Workflow Integration Study}
Beyond quantitative metrics, we will conduct a human-grounded study with radiologists and oncologists to assess the model's real-world utility.
\begin{itemize}
    \item \textbf{Assessing Counterfactual Plausibility:} Clinicians will score model-generated counterfactuals on Likert scales for clinical plausibility and usefulness for explanation \cite{GuoDeng2024, RossiLopez2024}.
    \item \textbf{Measuring Workflow Improvement:} We will perform a comparative study measuring efficiency (time-to-task), accuracy, and user satisfaction when clinicians use the system's automated structured reports versus traditional methods \cite{UnknownAuthor2020}.
\end{itemize}

\subsection{Risk Analysis and Mitigation}
This is an ambitious, high-risk project at the frontier of AI research. We have identified the primary risks and have developed clear mitigation strategies, leveraging our consortium's unique strengths and prior experience.
\begin{itemize}
    \item \textbf{Risk 1: Training Instability and Data Scalability.} The complexity of the proposed model presents a risk of training instability, especially given the multi-modal, multi-stage nature of the framework.
    \item \textbf{Mitigation:} Our primary mitigation is the \textbf{sequential, multi-stage training framework}. By decomposing a single, intractable optimization problem into a series of manageable sub-problems, we enhance stability and improve data efficiency. This modularity, a cornerstone of our design, allows us to isolate and troubleshoot issues at specific stages, a process our team has successfully employed in past projects involving synthetic image generation and predictive modeling.

    \item \textbf{Risk 2: Generalizability and Overfitting to Spurious Correlations.} AI models are prone to learning shortcuts from site-specific or technical artifacts in the data, limiting their real-world performance and clinical trustworthiness.
    \item \textbf{Mitigation:} Our framework is built on \textbf{principled disentanglement}. By explicitly separating style and confounder variables ($Z_S$) from disease variables ($Z_D$) and embedding strong domain knowledge as inductive biases (e.g., ordinal losses), we will guide the model to learn the true causal factors of the disease. The multi-center nature of our proprietary dataset is a key mitigation strategy, and our experience with developing robust, multi-source models will be critical in managing this risk.

    \item \textbf{Risk 3: Performance with Incomplete and Heterogeneous Data.} Real-world clinical data is inherently "messy," with missing modalities and irregular time points, which can severely hamper model performance.
    \item \textbf{Mitigation:} Our framework directly confronts this through its \textbf{Neural Jump ODE architecture}, which is inherently designed to handle sparse, irregularly sampled data. The use of a \textbf{masked loss function} during NJDE training is a key technique that allows the model to learn from all available data without being penalized for missingness, thereby turning the heterogeneity of the data from a weakness into a strength.

    \item \textbf{Risk 4: Clinical Trustworthiness and the "Black Box" Problem.} For any AI tool to be adopted, clinicians must trust its outputs and understand its reasoning.
    \item \textbf{Mitigation:} Our primary strategy for building trust is \textbf{explainability through counterfactuals}. This mechanism allows clinicians to probe the model's reasoning by asking "what-if" questions, transforming it from an opaque oracle into an interactive and verifiable partner in the diagnostic process. This, combined with our experience in building intuitive GUIs for clinical applications, will ensure the final tool is both powerful and usable. The clinical validation study (WP5) is the final step in confirming this trust.
\end{itemize}


\bibliographystyle{unsrt}
\bibliography{bibl}

\end{document}